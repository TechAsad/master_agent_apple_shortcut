{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21e597f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ASAD\\AppData\\Roaming\\Python\\Python311\\site-packages\\~iktoken'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.0.5 requires langchain-core<0.2,>=0.1.16, but you have langchain-core 0.2.20 which is incompatible.\n",
      "langchain-openai 0.0.5 requires tiktoken<0.6.0,>=0.5.2, but you have tiktoken 0.7.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain-nomic langchain_community tiktoken langchainhub langchain langgraph tavily-python langchain-text-splitters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e0b44e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U fuzzywuzzy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd42c79",
   "metadata": {},
   "source": [
    "### Tracing (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2096d49c-d3dc-4329-ada7-aff56d210198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "\n",
    "### LLM\n",
    "local_llm = \"llama3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78f0b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from collections import Counter\n",
    "\n",
    "# Replace with your Reddit app credentials\n",
    "CLIENT_ID = 'Q1q19TyBK8h519ZjBEXjUA'\n",
    "CLIENT_SECRET = 'CHulvUzsOoddZl5PGf30b5bigw8U-A'\n",
    "USER_AGENT = 'test'  # You can use any descriptive user agent\n",
    "\n",
    "# Initialize PRAW with credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=CLIENT_ID,\n",
    "    client_secret=CLIENT_SECRET,\n",
    "    user_agent=USER_AGENT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b211677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get subreddits\n",
    "\n",
    "import pandas as pd\n",
    "def search_subreddits(query, limit_per_word=5):\n",
    "    words = query.split(',')\n",
    "    all_subreddits = []\n",
    "    \n",
    "    for word in words:\n",
    "        try:\n",
    "            subreddits = reddit.subreddits.search(word, limit=limit_per_word)\n",
    "            all_subreddits.extend([subreddit.display_name for subreddit in subreddits])\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching subreddits with query '{word}': {e}\")\n",
    "\n",
    "    return list(set(all_subreddits))\n",
    "\n",
    "\n",
    "#query_text = \"email marketing, coldemail, business leads, marketing \"  # Replace with your query text\n",
    "#subreddits = search_subreddits(query_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "267c63e1-4c2f-439d-8d95-4c6aa01f41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get comments\n",
    "\n",
    "import pandas as pd\n",
    "def get_top_posts(subreddit_name, limit=3):\n",
    "    try:\n",
    "        subreddit = reddit.subreddit(subreddit_name)\n",
    "        # Check if the subreddit exists by attempting to access its posts\n",
    "        if subreddit.display_name != subreddit_name:\n",
    "            raise Exception(f\"Subreddit {subreddit_name} does not exist.\")\n",
    "        top_posts = subreddit.top(limit=limit)\n",
    "        return list(top_posts)  # Convert to list\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching top posts from {subreddit_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_comments_from_post(post):\n",
    "    try:\n",
    "        post.comments.replace_more(limit=100)\n",
    "        comments = [comment.body for comment in post.comments.list()]\n",
    "        return comments\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching comments from post {post.id}: {e}\")\n",
    "        return []\n",
    "\n",
    "def scrape_reddit_comments(subreddits):\n",
    "    all_comments = []\n",
    "    failed_subreddits = []\n",
    "    \n",
    "    for subreddit_name in subreddits:\n",
    "        print(f\"Scraping subreddit: {subreddit_name}\")\n",
    "        top_posts = get_top_posts(subreddit_name)\n",
    "        if not top_posts:  # Skip if no posts were retrieved\n",
    "            failed_subreddits.append(subreddit_name)\n",
    "            continue\n",
    "        for post in top_posts:\n",
    "            comments = get_comments_from_post(post)\n",
    "            sub_comments= comments[:100]\n",
    "            all_comments.extend(sub_comments)\n",
    "    \n",
    "    if failed_subreddits:\n",
    "        print(f\"Failed to retrieve data from these subreddits: {', '.join(failed_subreddits)}\")\n",
    "    \n",
    "    return all_comments\n",
    "\n",
    "def reddit_comments(sub_reddits):\n",
    "    output_file=f\"{sub_reddits}_comments.csv\"\n",
    "    subreddits = sub_reddits.split(',')\n",
    "    subreddits = [sub.strip() for sub in subreddits]\n",
    "    \n",
    "    comments = scrape_reddit_comments(subreddits)\n",
    "    print(comments)\n",
    "    print(f\"Total comments scraped: {len(comments)}\")\n",
    "    \n",
    "    #if comments:\n",
    "    #    df = pd.DataFrame(comments, columns=['Comment'])\n",
    "    #    df.to_csv(output_file, index=False)\n",
    "    #    print(f\"Comments for {subreddits} scraped and saved to {output_file}\")\n",
    "    #else:\n",
    "    #    print(\"No comments scraped from {subreddits}.\")\n",
    "    return comments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c58481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping subreddit: SaaS_Email_Marketing\n",
      "Scraping subreddit: ColdEmailAndSales\n",
      "['Looks like a cold email strategy so the problem is not content, it’s because unwanted emails. PS Remember there is no such thing as long or short content, only boring content.', '[deleted]', 'exactly!', '+1', 'How can these templates enhance customer service efficiency?', 'Save time and improve service quality with ready-made email templates.', 'Experiment with using templates to ensure consistent and accurate responses.', \"I would say, for start-ups who don't have templates already saved on hand or part of their workflows, snippets, etc. This is a great jump start to ensure you have some verbiage ready to go for those first customers when they read out. Definitely basic, but there are a ton of companies starting up each day. \\n\\nMissing a CTA on the blog though, even just sign up for the newsletter!\", '[removed]', 'Yet another new learning. Thanks for sharing the knowledge and up skilling us.', 'Hi, do you have any learning videos on scraping data from Linkedin sales Navigator', 'Hi, do you have any learning videos on scraping data from Linkedin sales Navigator', 'Thrilled to have you here', 'Thanks Rakesh for joining! This open forum should help everyone to connect.', 'Here you go: [https://www.youtube.com/watch?v=t6VJGB-Haa4](https://www.youtube.com/watch?v=t6VJGB-Haa4)', \"First off, kudos for putting in the grind on your cold email campaign. It’s clear you’ve got a solid foundation and you’re doing many things right. Sometimes, though, it’s the small tweaks that can make a big difference.\\n\\n**Subject Lines Matter**, crafting subj lines that spark curiosity or directly address a pain point can boost open rates. Maybe A/B test a few variations?\\n\\n**Value Proposition**, Emails aren't just about what you offer, but how you cn solve their specific problems. The more targeted, the better.\\n\\n**Social Proofs**, Include a brief mention of past successes or client testimonials. It builds credibility.\\n\\n**Less is more:** Keep your follow ups short and sweet. AA quick reminder with touch of new value cn work wonder. \\n\\n**Human Touch**, Sometimes, a bit of humor or a light-hearted comment can make your email stand out in a crowded inbox. *Just keep it professional.* \\n\\ndon't get discouraged. Every no gets you closer to a yes. Good luck!!!!\", 'Did you find any help with this?  I was about to post the same question', 'Thanks for the reply!! I appreciate you.', 'Maybe a little help but not really. We decided to make a lead magnet in order to collect emails first.']\n",
      "Total comments scraped: 19\n",
      "Comments for ['SaaS_Email_Marketing', 'ColdEmailAndSales'] scraped and saved to SaaS_Email_Marketing, ColdEmailAndSales_comments.csv\n"
     ]
    }
   ],
   "source": [
    "sub_reddits = \"SaaS_Email_Marketing, ColdEmailAndSales\"  # Provide subreddits here\n",
    "    \n",
    "comments= reddit_comments(sub_reddits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "987cceb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Looks like a cold email strategy so the problem is not content, it’s because unwanted emails. PS Remember there is no such thing as long or short content, only boring content.',\n",
       " '[deleted]',\n",
       " 'exactly!',\n",
       " '+1',\n",
       " 'How can these templates enhance customer service efficiency?',\n",
       " 'Save time and improve service quality with ready-made email templates.',\n",
       " 'Experiment with using templates to ensure consistent and accurate responses.',\n",
       " \"I would say, for start-ups who don't have templates already saved on hand or part of their workflows, snippets, etc. This is a great jump start to ensure you have some verbiage ready to go for those first customers when they read out. Definitely basic, but there are a ton of companies starting up each day. \\n\\nMissing a CTA on the blog though, even just sign up for the newsletter!\",\n",
       " '[removed]',\n",
       " 'Yet another new learning. Thanks for sharing the knowledge and up skilling us.',\n",
       " 'Hi, do you have any learning videos on scraping data from Linkedin sales Navigator',\n",
       " 'Hi, do you have any learning videos on scraping data from Linkedin sales Navigator',\n",
       " 'Thrilled to have you here',\n",
       " 'Thanks Rakesh for joining! This open forum should help everyone to connect.',\n",
       " 'Here you go: [https://www.youtube.com/watch?v=t6VJGB-Haa4](https://www.youtube.com/watch?v=t6VJGB-Haa4)',\n",
       " \"First off, kudos for putting in the grind on your cold email campaign. It’s clear you’ve got a solid foundation and you’re doing many things right. Sometimes, though, it’s the small tweaks that can make a big difference.\\n\\n**Subject Lines Matter**, crafting subj lines that spark curiosity or directly address a pain point can boost open rates. Maybe A/B test a few variations?\\n\\n**Value Proposition**, Emails aren't just about what you offer, but how you cn solve their specific problems. The more targeted, the better.\\n\\n**Social Proofs**, Include a brief mention of past successes or client testimonials. It builds credibility.\\n\\n**Less is more:** Keep your follow ups short and sweet. AA quick reminder with touch of new value cn work wonder. \\n\\n**Human Touch**, Sometimes, a bit of humor or a light-hearted comment can make your email stand out in a crowded inbox. *Just keep it professional.* \\n\\ndon't get discouraged. Every no gets you closer to a yes. Good luck!!!!\",\n",
       " 'Did you find any help with this?  I was about to post the same question',\n",
       " 'Thanks for the reply!! I appreciate you.',\n",
       " 'Maybe a little help but not really. We decided to make a lead magnet in order to collect emails first.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "542a5137",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import time\n",
    "import random\n",
    "from requests.exceptions import RequestException\n",
    "from langchain.tools import tool\n",
    "from fake_useragent import UserAgent\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import asyncio\n",
    "\n",
    "\n",
    "def get_random_user_agent():\n",
    "    ua = UserAgent()\n",
    "    return ua.random\n",
    "\n",
    "def extract_url(web_str):\n",
    "    # Use regular expression to find the URL\n",
    "    url_match = re.search(r'http[s]?://\\S+', web_str)\n",
    "    if url_match:\n",
    "        return url_match.group()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def scrape_new_website(url: str, base_domain: str, max_retries: int = 3, backoff_factor: float = 0.3, timeout: int = 10) -> dict:\n",
    "    headers = {'User-Agent': get_random_user_agent()}\n",
    "    session = requests.Session()\n",
    "    # Extract the URL\n",
    "    url = extract_url(url)\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = session.get(url, headers=headers, timeout=timeout)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Remove script and style elements\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.decompose()\n",
    "            \n",
    "            # Get text content\n",
    "            text = soup.get_text(separator=' ', strip=True)\n",
    "            \n",
    "            # Basic content cleaning\n",
    "            lines = (line.strip() for line in text.splitlines())\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "            text = 'joined '.join(chunk for chunk in chunks if chunk)\n",
    "            \n",
    "            # Extract links within the same domain\n",
    "            links = [urljoin(url, a.get('href')) for a in soup.find_all('a', href=True)]\n",
    "            sublinks = [link for link in links if urlparse(link).netloc == base_domain]\n",
    "            \n",
    "            print(len(sublinks))\n",
    "            return {\n",
    "                \"source\": url,\n",
    "                \"content\": text,\n",
    "                \"links\": sublinks[:1]\n",
    "            }\n",
    "        \n",
    "        except requests.RequestException as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                return {\n",
    "                    \"source\": url,\n",
    "                    \"error\": f\"Failed to scrape website after {max_retries} attempts: {str(e)}\"\n",
    "                }\n",
    "            else:\n",
    "                time.sleep(backoff_factor * (2 ** attempt))\n",
    "                continue\n",
    "\n",
    "def get_links_and_text(url: str, max_depth: int = 1, max_retries: int = 3, backoff_factor: float = 0.3, timeout: int = 10):\n",
    "    visited_urls = set()\n",
    "    results = []\n",
    "\n",
    "    def scrape_recursive(url: str, depth: int):\n",
    "        if depth > max_depth or url in visited_urls:\n",
    "            return\n",
    "\n",
    "        visited_urls.add(url)\n",
    "        base_domain = urlparse(url).netloc\n",
    "        result = scrape_new_website(url, base_domain, max_retries, backoff_factor, timeout)\n",
    "        \n",
    "        if \"error\" not in result:\n",
    "            results.append({\"source\": result[\"source\"], \"content\": result[\"content\"]})\n",
    "            for link in result.get(\"links\", []):\n",
    "                scrape_recursive(link, depth + 1)\n",
    "\n",
    "    scrape_recursive(url, 0)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdd787d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2024, 9, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0ddbd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://influencermarketinghub.com/ai-automation-agencies/', 'content': '3. AI Automation Agency\\nAI Automation Agency, a paradigm of innovation and efficiency in the competitive landscape of artificial intelligence growth, specializes in a myriad of services, including AI development and CRM automation. While these tools cover...\\nMaximizing Business Growth With The Top 10 Marketing Automation...\\nMarketing automation tools have become indispensable for businesses aiming to thrive...\\nEvaluating The Top 10 Automation Agencies for Future Growth\\nNavigating the diverse world of automation agencies is no small feat, especially as 91%... Automation Agency’s distinction is echoed by their clientele, attesting to the transformative impact of automated lead generation and nurture processes and the efficacy of AI solutions in providing round-the-clock support.\\n Sales and marketing automation, conversational AI, and predictive analytics are among the highlighted services, reflecting the agency’s comprehensive approach to utilizing AI for enhancing operational excellence and strategic decision-making.\\n Each engagement commences with a strategy workshop, ensuring that the AI and automation solutions are tailored to the specific needs and objectives of the business.'}, {'url': 'https://codeornocode.com/generative-ai/top-8-ai-automation-agencies/', 'content': 'With an emphasis on speed, communication, and a customer-first approach, Idea Link embodies a modern software development agency for AI automation. #2 Winter Marketing. Navigating comfortably in the bustling tech world, Winter Marketing is renowned as a leading AI Automation agency.'}, {'url': 'https://codeless.co/best-ai-automation-agencies/', 'content': 'Best for Process Automation. Axe Automation is an AI and automation agency that helps businesses streamline operations by integrating AI with automation to replace manual, repetitive tasks. Their services include process mapping, AI and automation integration, custom coding, and continuous management and iteration.'}, {'url': 'https://www.copilot.com/blog/ai-automation-agency', 'content': \"Features\\nPlatform\\nSolutions\\nCompany\\nResources\\nBlog\\nFeatures\\nPlatform\\nSolutions\\nCompany\\nResources\\nBlog Beyond these core services, many AI automation agencies offer specialized solutions in areas such as:\\nBy partnering with an AI automation agency and harnessing the power of AI, you can transform your business operations, boost efficiency, and achieve your strategic objectives. Let's take a closer look at some of the key areas where AI automation agencies can deliver significant value:\\nWorkflow optimization\\nAt the heart of many AI automation agencies lies the service of workflow optimization. 1. AI Automation Agency\\nAI Automation Agency is an automation agency that empowers businesses to harness the full potential of artificial intelligence (AI) and automation. This commitment to customization and alignment sets them apart in the realm of AI automation agencies — and it’s something you should consider if you go out to start your own AI automation agency.\\n\"}]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result_json)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result_json\n\u001b[0;32m---> 37\u001b[0m web_text \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_and_scrape_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(web_text)\n",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m, in \u001b[0;36mdetect_and_scrape_url\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m     10\u001b[0m url_pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(https?://[^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]+)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Search for URLs in the message\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m match \u001b[38;5;241m=\u001b[39m \u001b[43murl_pattern\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Check if a URL was found\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match:\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "### Search\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import json\n",
    "web_search_tool = TavilySearchResults(k=2, max_results=4)\n",
    "results =web_search_tool.invoke({\"query\": \"3 links of new startups websites related to AI Automation Agency \"})\n",
    "print(results)\n",
    "\n",
    "def detect_and_scrape_url(message):\n",
    "    # Regular expression to detect URLs\n",
    "    url_pattern = re.compile(r'(https?://[^\\s]+)')\n",
    "    \n",
    "    # Search for URLs in the message\n",
    "    match = url_pattern.search(message)\n",
    "\n",
    "    # Check if a URL was found\n",
    "    if match:\n",
    "        url = match.group(0)\n",
    "        \n",
    "        \n",
    "        # Check if the URL has already been scraped\n",
    "        \n",
    "        print(f\"\\nScraping {url}\")\n",
    "        website_text = get_links_and_text(url)\n",
    "        # Store the scraped content\n",
    "        \n",
    "    \n",
    "        result = {\"URL\": url, \"text\": website_text}\n",
    "    else:\n",
    "        result = {}\n",
    "\n",
    "    # Convert to JSON format\n",
    "    result_json = json.dumps(result)\n",
    "    print(result_json)\n",
    "    return result_json\n",
    "\n",
    "\n",
    "web_text = detect_and_scrape_url(results)\n",
    "print(web_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "166983ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How to start an AI Automation Agency? | by Manthan Patel | Medium\n",
      "Link: https://medium.com/@manthan2024/how-to-start-an-ai-automation-agency-149f245ecc8e\n",
      "Snippet: Design a visually appealing logo, website, and marketing materials that reflect your brand's personality and expertise in AI automation.\n",
      "---\n",
      "Title: Best Examples of AI Automation Agency Services - AI Scale Up\n",
      "Link: https://www.ai-scaleup.com/ai-agency/automation-services/\n",
      "Snippet: The best AI automation agency services examples you can easily design to help businesses improve productivity at the beginning of your enterprise.\n",
      "---\n",
      "Title: How to Start an AI Automation Marketing Agency - DesignStripe\n",
      "Link: https://designstripe.com/blog/automation-marketing-agency\n",
      "Snippet: How to Start an AI Automation Marketing Agency · 1. Identify Your Niche · 2. Build a Strong Knowledge Base · 3. Develop a Robust Tech Stack · 4.\n",
      "---\n",
      "Title: Has anyone running an AI automation agency? - Reddit\n",
      "Link: https://www.reddit.com/r/agency/comments/198xcw8/has_anyone_running_an_ai_automation_agency/\n",
      "Snippet: I run a bespoke software development agency https://modernlaunch.co/bespoke-software-development/ and work quite a bit with AI/Automation.\n",
      "---\n",
      "Title: Top AI Agency Owners Discuss First Client Strategies, Personal ...\n",
      "Link: https://www.youtube.com/watch?v=9JpP9IuppoE\n",
      "Snippet: Top AI Agency Owners Discuss First Client Strategies, Personal Branding & MORE ... I ...\n",
      "---\n",
      "Title: Agency AI guide for marketers - Think with Google\n",
      "Link: https://www.thinkwithgoogle.com/marketing-strategies/automation/agency-ai-guide/\n",
      "Snippet: 1. The value of AI · 2. Multiply expertise · 3. Optimize AI · 4. Rethink budget and bidding · 5. Reimagine audiences and creative · 6. Surface insights.\n",
      "---\n",
      "Title: How do you use AI in your digital marketing agency? - Reddit\n",
      "Link: https://www.reddit.com/r/agency/comments/1c4gshb/how_do_you_use_ai_in_your_digital_marketing_agency/\n",
      "Snippet: I've created my own internal software where I add information about my clients like their product/service, target audience, and tone of voice.\n",
      "---\n",
      "Title: What is Ai automation agency? Is it profitable business? & How can I ...\n",
      "Link: https://www.quora.com/What-is-Ai-automation-agency-Is-it-profitable-business-How-can-I-start-an-Ai-automation-agency\n",
      "Snippet: AI Automation Agency offers automation solutions using AI tools for small to medium businesses such as Startups, Rental Real Estate, AirBnB ...\n",
      "---\n",
      "Title: AI Marketing Automation Agency\n",
      "Link: https://www.modernmarketingpartners.com/ai-marketing-automation-agency/\n",
      "Snippet: From designing sophisticated AI algorithms for targeted customer engagement to automating repetitive marketing tasks with precision and efficiency.\n",
      "---\n",
      "Title: How to join a AI automation Agency - Quora\n",
      "Link: https://www.quora.com/How-can-I-join-a-AI-automation-Agency\n",
      "Snippet: Deploy a state-of-the-art agency marketing automation tool. · Identify high-quality leads. · Send personalized email messages. · Streamline social ...\n",
      "---\n",
      "\n",
      "Scraping https://medium.com/@manthan2024/how-to-start-an-ai-automation-agency-149f245ecc8e\n",
      "27\n",
      "0\n",
      "{\"URL\": \"https://medium.com/@manthan2024/how-to-start-an-ai-automation-agency-149f245ecc8e\", \"text\": [{\"source\": \"https://medium.com/@manthan2024/how-to-start-an-ai-automation-agency-149f245ecc8e\", \"content\": \"How to start an AI Automation Agency? | by Manthan Patel | Medium Open in app Sign up Sign in Write Sign up Sign in How to start an AI Automation Agency? Manthan Patel \\u00b7 Follow 4 min read \\u00b7 Mar 11, 2024 -- Listen Share Don\\u2019t miss out on the ultimate AI chatbot mastery course! Join now: Chatbots and AI Automation Agency Automation has become a crucial element for businesses looking to streamline processes, increase efficiency, and stay ahead of the competition. Artificial Intelligence (AI) plays a significant role in this realm, offering advanced solutions for tasks that were once time-consuming and labor-intensive. If you\\u2019re considering venturing into the realm of entrepreneurship and starting your AI automation agency, this comprehensive guide will walk you through the essential steps to set you on the path to success. Course Glimpse Understanding the Market Demand for AI Automation Before diving headfirst into establishing your AI automation agency, it\\u2019s crucial to have a clear understanding of the market demand. Research the current trends in AI automation, identify areas where businesses are looking to optimize their processes, and determine the potential client base for your services. Conducting market research will provide valuable insights into the competition, pricing strategies, and the specific needs of your target audience. Defining Your Niche and Services One of the keys to success in the AI automation industry is defining your niche and clearly outlining the services you will offer. Will your agency focus on chatbot development, automated data analysis, predictive analytics, or a combination of services? Understanding your strengths and expertise will help you carve out a unique positioning in the market and attract clients looking for specialized solutions. Consider conducting a SWOT analysis to identify your agency\\u2019s strengths, weaknesses, opportunities, and threats in the competitive landscape. Key Services Offered by AI Automation Agencies Chatbot Development Automated Data Analysis Predictive Analytics Process Automation Machine Learning Solutions Building a Strong Team of Experts Assembling a team of skilled professionals is crucial for the success of your AI automation agency. Look for individuals with expertise in AI development, data science, machine learning, and software engineering. Having a diverse team with complementary skills will enable you to offer a wide range of services to your clients and deliver top-notch solutions tailored to their specific needs. Invest in training and upskilling your team to stay abreast of the latest developments in AI technology. Establishing Strategic Partnerships Collaborating with strategic partners can help boost the credibility and reach of your AI automation agency. Partnering with technology companies, AI software providers, or industry experts can open up new avenues for business development, knowledge sharing, and client referrals. Identify potential partners who align with your agency\\u2019s values and goals, and explore mutually beneficial opportunities for collaboration and growth. Developing a Strong Brand Identity Creating a strong brand identity is essential for effectively positioning your AI automation agency in the market. Develop a compelling brand story that communicates your agency\\u2019s mission, values, and unique selling proposition. Design a visually appealing logo, website, and marketing materials that reflect your brand\\u2019s personality and expertise in AI automation. Consistency in branding across all touchpoints will help build trust and credibility with potential clients. Marketing and Lead Generation Strategies Implementing robust marketing and lead generation strategies is key to attracting clients to your AI automation agency. Leverage digital marketing channels such as social media, content marketing, email campaigns, and search engine optimization to increase your agency\\u2019s visibility and reach your target audience. Consider attending industry events, workshops, and conferences to network with potential clients and showcase your expertise in AI automation. Effective Marketing Strategies for AI Automation Agencies Social Media Marketing Content Marketing Email Campaigns Search Engine Optimization Networking at Industry Events Delivering Exceptional Customer Service Providing exceptional customer service is paramount in building long-lasting relationships with your clients and securing repeat business. Ensure that your team is responsive, attentive, and proactive in addressing client inquiries, concerns, and feedback. Take the time to understand your clients\\u2019 unique challenges and tailor your AI automation solutions to meet their specific needs. Going the extra mile to deliver exceptional service will set your agency apart from the competition and foster loyalty among clients. Scaling Your AI Automation Agency As your AI automation agency grows, it\\u2019s essential to implement strategies for scalability and expansion. Evaluate your operational processes, team structure, and technology infrastructure to ensure they can accommodate increased demand and growth. Consider expanding your service offerings, entering new markets, or targeting larger clients to scale your agency and maximize its potential impact in the AI automation industry. Conclusion Launching your AI automation agency requires careful planning, strategic decision-making, and a deep understanding of the market demand for AI solutions. By defining your niche, building a strong team of experts, establishing strategic partnerships, developing a strong brand identity, implementing effective marketing strategies, delivering exceptional customer service, and focus. www.vectorshift.ai Ai Automation Agency Step By Step Guide Chatbots Chatbot Development Ai Automation -- -- Follow Written by Manthan Patel 38 Followers An architect of AI-driven chatbots and virtual assistants, @Udemy Instructor with 45k+ Students, contact: manthan2024@gmail.com Follow Help Status About Careers Press Blog Privacy Terms Text to speech Teams\"}, {\"source\": \"https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40manthan2024%2Fhow-to-start-an-ai-automation-agency-149f245ecc8e&source=post_page---two_column_layout_nav-----------------------global_nav-----------\", \"content\": \"Medium\"}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"URL\": \"https://medium.com/@manthan2024/how-to-start-an-ai-automation-agency-149f245ecc8e\", \"text\": [{\"source\": \"https://medium.com/@manthan2024/how-to-start-an-ai-automation-agency-149f245ecc8e\", \"content\": \"How to start an AI Automation Agency? | by Manthan Patel | Medium Open in app Sign up Sign in Write Sign up Sign in How to start an AI Automation Agency? Manthan Patel \\\\u00b7 Follow 4 min read \\\\u00b7 Mar 11, 2024 -- Listen Share Don\\\\u2019t miss out on the ultimate AI chatbot mastery course! Join now: Chatbots and AI Automation Agency Automation has become a crucial element for businesses looking to streamline processes, increase efficiency, and stay ahead of the competition. Artificial Intelligence (AI) plays a significant role in this realm, offering advanced solutions for tasks that were once time-consuming and labor-intensive. If you\\\\u2019re considering venturing into the realm of entrepreneurship and starting your AI automation agency, this comprehensive guide will walk you through the essential steps to set you on the path to success. Course Glimpse Understanding the Market Demand for AI Automation Before diving headfirst into establishing your AI automation agency, it\\\\u2019s crucial to have a clear understanding of the market demand. Research the current trends in AI automation, identify areas where businesses are looking to optimize their processes, and determine the potential client base for your services. Conducting market research will provide valuable insights into the competition, pricing strategies, and the specific needs of your target audience. Defining Your Niche and Services One of the keys to success in the AI automation industry is defining your niche and clearly outlining the services you will offer. Will your agency focus on chatbot development, automated data analysis, predictive analytics, or a combination of services? Understanding your strengths and expertise will help you carve out a unique positioning in the market and attract clients looking for specialized solutions. Consider conducting a SWOT analysis to identify your agency\\\\u2019s strengths, weaknesses, opportunities, and threats in the competitive landscape. Key Services Offered by AI Automation Agencies Chatbot Development Automated Data Analysis Predictive Analytics Process Automation Machine Learning Solutions Building a Strong Team of Experts Assembling a team of skilled professionals is crucial for the success of your AI automation agency. Look for individuals with expertise in AI development, data science, machine learning, and software engineering. Having a diverse team with complementary skills will enable you to offer a wide range of services to your clients and deliver top-notch solutions tailored to their specific needs. Invest in training and upskilling your team to stay abreast of the latest developments in AI technology. Establishing Strategic Partnerships Collaborating with strategic partners can help boost the credibility and reach of your AI automation agency. Partnering with technology companies, AI software providers, or industry experts can open up new avenues for business development, knowledge sharing, and client referrals. Identify potential partners who align with your agency\\\\u2019s values and goals, and explore mutually beneficial opportunities for collaboration and growth. Developing a Strong Brand Identity Creating a strong brand identity is essential for effectively positioning your AI automation agency in the market. Develop a compelling brand story that communicates your agency\\\\u2019s mission, values, and unique selling proposition. Design a visually appealing logo, website, and marketing materials that reflect your brand\\\\u2019s personality and expertise in AI automation. Consistency in branding across all touchpoints will help build trust and credibility with potential clients. Marketing and Lead Generation Strategies Implementing robust marketing and lead generation strategies is key to attracting clients to your AI automation agency. Leverage digital marketing channels such as social media, content marketing, email campaigns, and search engine optimization to increase your agency\\\\u2019s visibility and reach your target audience. Consider attending industry events, workshops, and conferences to network with potential clients and showcase your expertise in AI automation. Effective Marketing Strategies for AI Automation Agencies Social Media Marketing Content Marketing Email Campaigns Search Engine Optimization Networking at Industry Events Delivering Exceptional Customer Service Providing exceptional customer service is paramount in building long-lasting relationships with your clients and securing repeat business. Ensure that your team is responsive, attentive, and proactive in addressing client inquiries, concerns, and feedback. Take the time to understand your clients\\\\u2019 unique challenges and tailor your AI automation solutions to meet their specific needs. Going the extra mile to deliver exceptional service will set your agency apart from the competition and foster loyalty among clients. Scaling Your AI Automation Agency As your AI automation agency grows, it\\\\u2019s essential to implement strategies for scalability and expansion. Evaluate your operational processes, team structure, and technology infrastructure to ensure they can accommodate increased demand and growth. Consider expanding your service offerings, entering new markets, or targeting larger clients to scale your agency and maximize its potential impact in the AI automation industry. Conclusion Launching your AI automation agency requires careful planning, strategic decision-making, and a deep understanding of the market demand for AI solutions. By defining your niche, building a strong team of experts, establishing strategic partnerships, developing a strong brand identity, implementing effective marketing strategies, delivering exceptional customer service, and focus. www.vectorshift.ai Ai Automation Agency Step By Step Guide Chatbots Chatbot Development Ai Automation -- -- Follow Written by Manthan Patel 38 Followers An architect of AI-driven chatbots and virtual assistants, @Udemy Instructor with 45k+ Students, contact: manthan2024@gmail.com Follow Help Status About Careers Press Blog Privacy Terms Text to speech Teams\"}, {\"source\": \"https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40manthan2024%2Fhow-to-start-an-ai-automation-agency-149f245ecc8e&source=post_page---two_column_layout_nav-----------------------global_nav-----------\", \"content\": \"Medium\"}]}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google_serper import serper_search\n",
    "\n",
    "agency_type=\"AI Automation Agency\"\n",
    "\n",
    "def google_search(agency_type):\n",
    "\n",
    "    results=serper_search(f\"branding stratergies for {agency_type} agency \")\n",
    "    print(results)\n",
    "    web_text = detect_and_scrape_url(results)\n",
    "    return web_text\n",
    "\n",
    "google_search(agency_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "553fc6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "### info collector Chain\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama, ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# LLM\n",
    "#llm = ChatOllama(model=local_llm, temperature=0.1)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "info_collector_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "### **Agent Role:**\n",
    "You are the Startup Information Collector. Your role is to gather key details about the user's startup and ensure all essential information is provided before passing it on for the next steps.\n",
    "\n",
    "### **Agent Mission:**\n",
    "Ask the user questions to collect details about their startup. Your goal is to output responses with one sigle key \"product\" or \"question\":\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions:**\n",
    "\n",
    "1. Questions to Ask the User:\n",
    "   - What is the name of your agency? (Required)\n",
    "   - What product or service does your business offer? (Required)\n",
    "   - What industry does your business operate in? (Required)\n",
    "   - What problem does your startup solve for its clients? (Required)\n",
    "   - Please attach any competion website url if you know.\n",
    "   \n",
    "\n",
    "2. Logic for Responses:\n",
    "   - If all required fields (name, product, industry, and problem) are provided, output with key 'product':\n",
    "     ```json\n",
    "     {\n",
    "       \"product\": {\n",
    "         \"name\": \"[Startup Name]\",\n",
    "         \"product_service\": \"[Product or Service]\",\n",
    "         \"industry\": \"[Industry]\",\n",
    "         \"problem_solved\": \"[Problem]\"\n",
    "         \"Competition Website\": \"[url]\"\n",
    "       }\n",
    "     }\n",
    "     ```\n",
    "\n",
    "   If some required information is missing, ask 'question' the user to provide it by stating what is missing:\n",
    "    \n",
    "     \"Please provide more information about {missing field(s)}.\"\n",
    "    \n",
    "\n",
    "   Once the missing information is provided, re-check and either proceed with \"product_details\" or ask again until all required fields are filled.\n",
    "\n",
    "3. JSON Output Format (if all required fields are complete):\n",
    "   ```json\n",
    "   {\n",
    "       \"product\": {\n",
    "         \"name\": \"[Startup Name]\",\n",
    "         \"product_service\": \"[Product or Service]\",\n",
    "         \"industry\": \"[Industry]\",\n",
    "         \"problem_solved\": \"[Problem]\"\n",
    "         \"Competition Website\": \"[url]\"\n",
    "       }\n",
    "     }\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "Key Considerations:\n",
    "- Be polite and guide the user in a friendly manner.\n",
    "- Ask one question at a time and ensure the user’s answers are clear.\n",
    "- Loop back to the missing questions if any required information is incomplete.\n",
    "\n",
    "---\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    \n",
    "    previously: {chat_history}\n",
    "    \n",
    "    USER: \\n\\n {prompt} \\n\\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[ \"prompt\", \"chat_history\"],\n",
    ")\n",
    "\n",
    "\n",
    "info_collector_chain = info_collector_prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2b892e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## router chain\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama, ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# LLM\n",
    "#llm = ChatOllama(model=local_llm, temperature=0.1)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "\n",
    "router_prompt = PromptTemplate(\n",
    "    template=\"\"\" you are a decision maker.\n",
    "    \n",
    "   given the product details from the user, please decide if the details are complete or incomplete.\n",
    "   \n",
    "   {\n",
    "       \"product_details\": {\n",
    "         \"name\": \"[Startup Name]\",\n",
    "         \"product_service\": \"[Product or Service]\",\n",
    "         \"industry\": \"[Industry]\",\n",
    "         \"problem_solved\": \"[Problem]\"\n",
    "         \"Competition Website\": \"[url]\"\n",
    "       }\n",
    "     }\n",
    "   \n",
    "   if they are complete, pass 'yes'. If incomplete, pass 'no' with single key \"status\" as json with no preamble or explanation.\n",
    "    \n",
    "    \n",
    "    product details: \\n\\n {info_collector_agent} \\n\\n \n",
    "    \"\"\",\n",
    "    input_variables=[ \"product\"],\n",
    ")\n",
    "\n",
    "\n",
    "router_chain = router_prompt | llm | JsonOutputParser()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "477eeda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## subreddit name chain\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama, ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# LLM\n",
    "#llm = ChatOllama(model=local_llm, temperature=0.1)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "product = \"AI personalized cold Email writer for business leads. Writes emaiil for every lead by researching on them using their website and linkedin \"\n",
    "# LLM\n",
    "#llm = ChatOllama(model=local_llm,temperature=0.1)\n",
    "\n",
    "subreddit_name_prompt = PromptTemplate(\n",
    "    template=\"\"\" you are market researcher.\n",
    "    \n",
    "    Given the product information, understand the core product and the problem it solves.\n",
    "    your task is to write five search words from the product that closely relates to the core product.\\n\\n\n",
    "    \n",
    "    \n",
    "    such as:\n",
    "    \n",
    "    dog trainer\n",
    "    medical billing\n",
    "    ai chatbot\n",
    "    \n",
    "    \n",
    "    \n",
    "    Provide the keywords separated by comma and no preamble or explanation.\n",
    "    \n",
    "    \n",
    "    \n",
    "    product details: \\n\\n {product} \\n\\n \n",
    "    \"\"\",\n",
    "    input_variables=[ \"product\"],\n",
    ")\n",
    "\n",
    "\n",
    "subreddit_name_chain = subreddit_name_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "\n",
    "#google_search=web_search_tool.invoke({\"query\": \"latest {location} \"})\n",
    "#subreddit_name_agent= subreddit_name_chain.invoke({\"product\": product})\n",
    "#print(subreddit_name_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd1c7aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reddit Searcher Chain\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama, ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# LLM\n",
    "#llm = ChatOllama(model=local_llm, temperature=0.1)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "reddit_searcher_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a reddit expert. you have been given some subreddits.\n",
    "    \n",
    "    only provide best 3 (three) subreddits that closely relates with the product information. Choose the sub reddits where we may find product users.\n",
    "    do not create any name from yourself. \n",
    "    you have been given available subreddits from reddit search.\n",
    "    choose only closely match with keywords of our product.\n",
    "    \n",
    "    Provide the subbreddits separated by comma without 'r/'. and no preamble or explanation.\n",
    "    \n",
    "    \n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    available subreddits:{sub_reddits}\\n\\n\n",
    "    product: \\n\\n {product} \\n\\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[ \"product\", \"sub_reddits\"],\n",
    ")\n",
    "\n",
    "\n",
    "subreddit_searcher_chain = reddit_searcher_prompt | llm | StrOutputParser()\n",
    "#sub_reddits = search_subreddits(subreddit_name_agent)\n",
    "#print(sub_reddits)\n",
    "\n",
    "#google_search=web_search_tool.invoke({\"query\": \"latest {location} \"})\n",
    "#subreddit_searcher_agent= subreddit_searcher_chain.invoke({\"product\": product, \"sub_reddits\":sub_reddits})\n",
    "#print(subreddit_searcher_agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6440699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### web summary Chain\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama, ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# LLM\n",
    "#llm = ChatOllama(model=local_llm, temperature=0.1)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "web_summary_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "    \n",
    "### **Agent Role:**\n",
    "You are the Competitive Insights Summarizer. Your task is to gather and summarize key information from a competitor's website content. The output should be a concise, plain text summary of the business's key details, focusing on its products/services, target audience, and market positioning.\n",
    "\n",
    "### **Agent Mission:**\n",
    "Analyze the provided content from the competitor’s website and extract essential business information, which could be helpful for building our product. Summarizing it in plain text format.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions:**\n",
    "\n",
    "1. **Key Information to Extract:**\n",
    "   - **Company Name**: Identify the name of the competing business.\n",
    "   - **Product/Service Offerings**: Summarize the primary products or services the company offers.\n",
    "   - **Target Audience**: Determine the audience the company is serving.\n",
    "   - **Industry**: Identify the business's operating industry or market.\n",
    "   - **Competitive Positioning**: Summarize how the business positions itself in the market (e.g., pricing, unique selling points, customer focus).\n",
    "   - **Key Features/Benefits**: Highlight the key features or benefits of the company's products or services.\n",
    "\n",
    "\n",
    "2. **Logic for Responses**:\n",
    "   - If the website content provides sufficient information for all fields, the agent will output the full plain text summary.\n",
    "   - If some details are missing or unclear, the agent should output the summary with the available details, and mark missing parts as “Unclear.”\n",
    "\n",
    "3. **Guiding Questions for Summarization**:\n",
    "   - What products or services does this company offer?\n",
    "   - Who is their target audience or customer base?\n",
    "   - In what industry or market is this business operating?\n",
    "   - How does the company position itself competitively (e.g., pricing strategy, unique features, customer service)?\n",
    "   - What are the key features or benefits that they highlight to their customers?\n",
    "\n",
    "\n",
    "\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    competiton website:{web_text}\\n\\n\n",
    "    oour product: \\n\\n {product} \\n\\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[ \"product\", \"web_text\"],\n",
    ")\n",
    "\n",
    "web_summary_chain = web_summary_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments= reddit_comments(subreddit_searcher_agent)\n",
    "\n",
    "comments[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66d626da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def filter_comments(comments):\n",
    "    unwanted_keywords = ['https']\n",
    "    # Filter out comments containing unwanted keywords and comments with less than 4 words\n",
    "    filtered_comments = []\n",
    "    for comment in comments[:300]:\n",
    "        if len(comment.split()) >= 4 and not any(keyword.lower() in comment.lower() for keyword in unwanted_keywords):\n",
    "            filtered_comments.append(comment)\n",
    "\n",
    "    # Remove comments with links\n",
    "    filtered_comments = [comment for comment in filtered_comments if 'http' not in comment and 'https' not in comment]\n",
    "    \n",
    "    # Remove duplicate comments that are 80% similar or more\n",
    "    def is_duplicate(comment, existing_comments, threshold=80):\n",
    "        for existing_comment in existing_comments:\n",
    "            if fuzz.ratio(comment, existing_comment) >= threshold:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    unique_comments = []\n",
    "    for comment in filtered_comments:\n",
    "        if not is_duplicate(comment, unique_comments):\n",
    "            unique_comments.append(comment)\n",
    "    \n",
    "    return unique_comments\n",
    "\n",
    "# List of unwanted keywords\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Filter the comments\n",
    "#filtered_comments = filter_comments(comments)\n",
    "#filtered_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74f40b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Market Researcher Expert\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama, ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, temperature=0.1)\n",
    "market_researcher_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "\n",
    "market_researcher_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    ## My goal\n",
    "\n",
    "I'm looking for customer insights for my business idea:\n",
    "“{product} ”\n",
    "\n",
    "## Your role\n",
    "\n",
    "You are a market researcher expert in finding customer insights\n",
    "\n",
    "## Your mission\n",
    "\n",
    "I'm either going to provide you with a copy and paste of Reddit posts from related subreddits, or, a list of YouTube comments from a related video (or any type of document).\n",
    "\n",
    "Please extract any gold nuggets that I can use in my marketing.\n",
    "\n",
    "## Instructions and formatting\n",
    "\n",
    "I want to have the exact customer wording, create a simple list, and list all of them.\n",
    "\n",
    "Use a Markdown block dto display your answer, nothing before, nothing after.\n",
    "\n",
    "## EXTREMELY IMPORTANT\n",
    "\n",
    "- Only select the sentences that have a direct link to my business idea\n",
    "- Only mention short impactful sentence with wording that every person in my audience can rely to.\n",
    "- DO NOT WRITE ANY SENTENCE THAT HAS NOT A DIRECT LINK WITH MY BUSINESS IDEA\n",
    "\n",
    "## Format example\n",
    "[\n",
    "## (Give a name to the pain point)\n",
    "“Gold nugget related to the pain point”\n",
    "“Gold nugget related to the pain point”\n",
    "“Gold nugget related to the pain point”\n",
    "\n",
    "## (Give a name to the pain point)\n",
    "“Gold nugget related to the pain point”\n",
    "“Gold nugget related to the pain point”\n",
    "“Gold nugget related to the pain point”\n",
    "\n",
    "... ]\n",
    "\n",
    "\n",
    "\n",
    "## Document to work from\n",
    "\n",
    "{filtered_comments}\n",
    "\n",
    "   \n",
    "    \"\"\",\n",
    "    input_variables=[\"filtered_comments\", \"product\"],\n",
    ")\n",
    "\n",
    "\n",
    "market_researcher_chain = market_researcher_prompt | market_researcher_llm | StrOutputParser()\n",
    "\n",
    "\n",
    "\n",
    "#market_researcher_agent= market_researcher_chain.invoke({\"filtered_comments\":filtered_comments[:1000], \"product\": product})\n",
    "#print(market_researcher_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b008df98-8394-49da-8fb8-aefe2c90d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Marketing Strategist Chain\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama, ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "\n",
    "brand_strategist_prompt = PromptTemplate(\n",
    "    template=\"\"\" \n",
    "    product: {product}\\n\n",
    "\n",
    "    Previous knowledge:\n",
    "    {market_researcher_agent}\\n\n",
    "    \n",
    "    \n",
    "## Your role\n",
    "\n",
    "You are a marketing strategist with a deep understanding of copywriting, psychological behaviors and Meta advertising.\n",
    "You know perfectly the market analysis and advertising principles from 'Breakthrough Advertising' by Eugene M. Schwartz, and from David Ogilvy.\n",
    "\n",
    "## Context\n",
    "\n",
    "I’m in the process of validating a product idea using a Meta advertising campaign as well as a landing page.\n",
    "At this stage, I only have very little knowledge about who is the customer and what do they really need., only the information previously mentioned in our conversation.\n",
    "\n",
    "## Your mission\n",
    "\n",
    "Your mission is to help me to craft the both the landing page and the advertising campaign by providing them with different potential target audiences, marketing angles and hooks, following the definitions and process described\n",
    "\n",
    "\n",
    "## Methodology: Think step by step\n",
    "\n",
    "1. Understand the insight provided earlier in this conversation\n",
    "2. Think of potential markets the product/offer could address, the mass desires behind it, market awareness, and market sophistication\n",
    "3. Think of the potential customers, who are they, what are they struggling with, what do they really want\n",
    "4. Think of the best potential target audiences\n",
    "5. Generate your answer\n",
    "\n",
    "After gathering this information, generate a clear and simple product description that includes the following:\n",
    "\n",
    "### Structure of your answer\n",
    "\n",
    "\n",
    "Here is the structure to follow:\n",
    "\n",
    "(\n",
    "\n",
    "## Name\n",
    "\n",
    "(Give it a nice but self explanatory name)\n",
    "\n",
    "## Colors\n",
    "\n",
    "(The background is going to be white, pick 1 HEX colors that fit the product, that should create a strong constrast to use on the call to action)\n",
    "\n",
    "## Font\n",
    "\n",
    "(Pick 2 Google fonts, one for heading, distinctive enough to create a real identity, and another more classic for paragraphs)\n",
    "\n",
    "## Product\n",
    "\n",
    "(Describe what the product is and what it does.)\n",
    "\n",
    "### Features:\n",
    "\n",
    "(List the 3 main potential features or components of the product.)\n",
    "\n",
    "### Benefits\n",
    "\n",
    "(Highlight the 3 potential key benefits the product provides.)\n",
    "\n",
    "## Potential target audience\n",
    "\n",
    "List 3 potenial niches/target audience for the product. From most important to least important\n",
    "\n",
    ")\n",
    "\n",
    "### Format\n",
    "\n",
    "- [potential group of people] that are struggling with [a potential problem] that what to [achieve a potential goal]\n",
    "- [potential group of people] that are struggling with [a potential problem] that what to [achieve a potential goal]\n",
    "- ...\n",
    "\n",
    "### Important\n",
    "\n",
    "When picking an audience, be niche, be accurate, don't use broad useless audiences like \"busy professional\" or \"health enthusiast\", we want to address a specific part of a big market to solve a specific problem.\n",
    "\n",
    "    respond in plain english, do not use brackets.\n",
    "    \n",
    "    \"\"\",\n",
    "    input_variables=[\"market_researcher_agent\", \"product\"],\n",
    ")\n",
    "\n",
    "\n",
    "brand_strategist_chain =  brand_strategist_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "\n",
    "#marketing_strategist_agent= marketing_strategist_chain.invoke({\"market_researcher_agent\": market_researcher_agent, \"product\": product})\n",
    "#print(marketing_strategist_agent)\n",
    "#target_audience= marketing_strategist_agent['Potential target audience'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b64326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'LeadCraft AI', 'Colors': '#007BFF', 'Font': {'Heading': 'Montserrat', 'Paragraph': 'Roboto'}, 'Product': \"LeadCraft AI is an AI-powered personalized cold email writer designed specifically for businesses looking to engage potential leads effectively. By researching each lead's website and LinkedIn profile, it crafts tailored emails that resonate with the recipient, increasing the chances of conversion.\", 'Features': [\"Automated Research: The AI analyzes leads' online presence to gather relevant information for personalization.\", 'Customizable Templates: Users can choose from a variety of email templates that can be easily customized to fit their brand voice.', 'Performance Tracking: The tool provides analytics on email open rates, responses, and engagement metrics to optimize future outreach.'], 'Benefits': ['Time-Saving: Automates the email writing process, allowing users to focus on other critical business tasks.', 'Higher Engagement: Personalized emails lead to better response rates, improving overall outreach effectiveness.', 'Data-Driven Insights: Users gain valuable insights into their email campaigns, enabling continuous improvement.'], 'Potential target audience': [{'group': 'B2B Sales Teams', 'problem': 'struggling with crafting personalized outreach to potential clients', 'goal': 'achieve higher response rates and conversions'}, {'group': 'Marketing Agencies', 'problem': 'finding it challenging to create tailored email campaigns for multiple clients', 'goal': 'deliver effective and personalized email marketing solutions'}, {'group': 'Startup Founders', 'problem': 'lacking the resources to engage leads effectively through cold emailing', 'goal': 'build relationships with potential investors and customers'}]}\n",
      "{'group': 'Startup Founders', 'problem': 'lacking the resources to engage leads effectively through cold emailing', 'goal': 'build relationships with potential investors and customers'}\n"
     ]
    }
   ],
   "source": [
    "print(marketing_strategist_agent)\n",
    "target_audience= marketing_strategist_agent['Potential target audience'][2]\n",
    "print(target_audience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1d531a81-6d4d-405e-975a-01ef1c9679fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Branding Agent\n",
    "import re\n",
    "from langchain_community.chat_models import ChatOllama, ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# LLM\n",
    "#llm = ChatOllama(model=local_llm, temperature=0.1)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "branding_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    \n",
    "    product: {product}\\n\n",
    "    \n",
    "    competition website: {web_summary_agent}\n",
    "    \n",
    "    About this domain: {google_summary}\n",
    "    \n",
    "    \n",
    "    \n",
    "    Previous knowledge:\n",
    "    {market_researcher_agent}\\n\n",
    "    \n",
    "    \n",
    "\n",
    "## Your new mission\n",
    "\n",
    "Your Role:\n",
    "You are an expert in brand strategy and communications, specializing in helping businesses build compelling brands and messaging.\n",
    "\n",
    "Your Mission:\n",
    "Based on my business, industry, market research and market strategy, your task is to generate the following:\n",
    "\n",
    "1. Company Briefing:\n",
    "Summarize the core mission, vision, and values of my business.\n",
    "Provide a brief overview of what the company offers and its unique position in the market.\n",
    "Highlight the key problem my business solves for its target clients and why it matters.\n",
    "\n",
    "2. Company Branding:\n",
    "Develop the brand identity, including the tone, personality, and values that define my business.\n",
    "Suggest elements like colors, fonts, and imagery that represent the brand.\n",
    "\n",
    "3. Brand Story:\n",
    "Craft a compelling narrative that explains the history, inspiration, and journey of the brand.\n",
    "Include why the brand was created, its mission, and what drives it forward.\n",
    "Ensure the story emotionally connects with the target audience, showing how the brand solves a critical problem for them.\n",
    "\n",
    "4. Company/Brand Messages:\n",
    "Create a series of concise and impactful brand messages that communicate the business's value proposition.\n",
    "Develop key phrases or taglines that resonate with the target audience, addressing their needs and showcasing how the company provides the solution.\n",
    "Ensure the messaging aligns with the brand's identity and tone.\n",
    "\n",
    "Instructions:\n",
    "Keep the tone professional but relatable to the target audience.\n",
    "Ensure the company briefing and story are detailed but easy to understand.\n",
    "Make sure the branding and messages are unique, memorable, and align with the company’s mission.\n",
    "Example Format:\n",
    "\n",
    "## Company Briefing:\n",
    "[Company Briefing Summary]\n",
    "\n",
    "## Company Branding:\n",
    "- Brand Personality: [Description]\n",
    "- Tone: [Description]\n",
    "- Suggested Elements: [Colors, Fonts, Imagery]\n",
    "\n",
    "## Brand Story:\n",
    "[Narrative of the brand's journey, inspiration, and mission]\n",
    "\n",
    "## Company/Brand Messages:\n",
    "- Message 1: [Key message or tagline]\n",
    "- Message 2: [Key message or tagline]\n",
    "- Message 3: [Key message or tagline]\n",
    "\n",
    "    \n",
    "    \"\"\",\n",
    "    input_variables=[\"product\", \"web_summary_agent\",\"google_summary\", \"market_researcher_agent\",\"brand_strategist_agent\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Chain\n",
    "branding_chain = branding_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "\n",
    "#campaign_agent = campaign_chain.invoke({\"product\":product, \"market_researcher_agent\": market_researcher_agent,\"marketing_strategist_agent\":marketing_strategist_agent, \"target_audience\":target_audience})\n",
    "#print(campaign_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e75abf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Landing Page Chain\n",
    "import re\n",
    "from langchain_community.chat_models import ChatOllama, ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# LLM\n",
    "#llm_landing_page = ChatOllama(model=local_llm, temperature=0.1)\n",
    "llm_landing_page = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "landing_page_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    \n",
    "    product: {product}\\n\n",
    "    \n",
    "    Previous knowledge:\n",
    "    \n",
    "    {market_researcher_agent}\\n\n",
    "    \n",
    "    {marketing_strategist_agent}\\n\n",
    "    \n",
    "    Target Audince:\n",
    "    {campaign_agent}\\n\\n\n",
    "\n",
    "## Your new mission\n",
    "\n",
    "From all the informations in the conversation above, your new mission is to help the user to craft the landing page to display the product/offer.\n",
    "The landing page is using the Before-After-Bridge copywriting framework\n",
    "\n",
    "IT IS EXTREMELY IMPORTANT THAT YOU USE THE WORDING OF THE CUSTOMER AS MUCH AS POSSIBLE IN YOUR COPY\n",
    "\n",
    "### Think step by step\n",
    "\n",
    "1. Summarize the conversation for yourself\n",
    "2. Think of the potential target audience, who are the customers, what are their current believes, what are they struggling with, what do they really want, what have they potentially tried to solve the problem\n",
    "3. Generate your answer\n",
    "\n",
    "## Basic rules for crafting landing pages\n",
    "\n",
    "- Be crystal clear in your writing - Don’t assume “they will understand”, write simple things, do not use metaphores.\n",
    "- Write for a 10 years old - Avoid jargon at all cost use only simple words and formulation.\n",
    "- Say everything in the titles, back it up with the paragraphs - Most people only scan the page, everything should be said only with the titles.\n",
    "- No one cares about the product, people care about themselves - Write using “You” or “Your” not “Us”, customer centric.\n",
    "- Write with one single person in mind.\n",
    "- Create mental pictures as much as possible, the more the visitor visualize a situation they can relate to, the more likely they will understand the benefits the product can bring them.\n",
    "- If possible, pick a side, declare an ennemy, it's us versus them, do it subltely.\n",
    "- Never use buzzword, or power verbs like unleash, unveil, discover, unlock and all similar bullshit words\n",
    "\n",
    "## Definitions\n",
    "[\n",
    "### Above the fold\n",
    "\n",
    "The Above the fold part of the landing page is the first part the visitors sees when landing on the page, before scrolling. This section should should contain all the pieces, the visitor should understand they are in the right place in a blink of an oeil.\n",
    "It contains the following pieces\n",
    "\n",
    "#### Headline\n",
    "\n",
    "\n",
    "ALWAYS USE THE WORDS OF THE CUSTOMERS IN THE HEADLINE\n",
    "Here are 3 types of headlines that work well:\n",
    "\n",
    "1. Short straight to the point headlines\n",
    "\n",
    "Good short straight to the point headlines describe what the business does in a super creative way. They don't use buzzwords. They're short and consumable, while generating curiosity. They orient towards the business outcomes that customers would get. \n",
    "\n",
    "2. Question headlines\n",
    "\n",
    "Question headlines are a simple question making the visitor directly connect to a specific situation or relate to a fact they know about, related to the problem the product/offer solves, If possible make the visitor visulaze a scene they are familiar with or trigger an emotion.\n",
    "\n",
    "3. The desired outcome headlines\n",
    "\n",
    "Desired outcome headlines are short and designed to make the visitor feel the emotion they would feel if they finally solve the problem the product/offer is solving. It's not about the direct benefits of the product/offer, it's about how would their life look like once the problem is solved and how would they feel about that\n",
    "\n",
    "\n",
    "#### Subheadline\n",
    "\n",
    "The subheadline is meant to be placed right below the headline and should describe the solution for the target audience in a more objective way so the visitor knows exactly what to expect. It should confirm the user expectation by mentioning clearly for who it is for and what the product/offer does, if possible by adding some uniqueness or time period, and always make it feel easy as a breath.\n",
    "\n",
    "#### Bullet points\n",
    "\n",
    "Generally, depending on the product/offer, the above the fold will contain 3-5 bullet points\n",
    "They are short (about 15 words) and straight to the point stating a benefits the customer will get backed up with a feature from the product\n",
    "\n",
    "Example: \"\n",
    "Learn how to relieve your jaw tension and feel refreshed and ready to face the day in the morning.\n",
    "Experience deep relaxation and improved mobility in the jaw, head and neck area\n",
    "Discover how a new jaw feeling fundamentally improves your quality of life.\n",
    "\"\n",
    "\n",
    "#### Call to action\n",
    "\n",
    "The call to action is the text of a button to go to the next step, it should be very short, and adapted to any kind of next step\n",
    "\n",
    "Example:\n",
    "\"\n",
    "- Tell me more!\n",
    "- Yes, I want...\n",
    "- Find out if [product] is made for you?\n",
    "\"\n",
    "\n",
    "### Message from the founder\n",
    "\n",
    "Since we don't have testimonial yet, this section is going to show a sentence from the founder to humanize and rationalize the product/offer, it should act as if it would be a testimonial but it's not, it is directly from the founder.\n",
    "\n",
    "\n",
    "### The current situation (Before)\n",
    "\n",
    "This section is the \"Before\" in the BAB copywriting framework.\n",
    "It should described vividly the current situation and pain of the visitor, using visual words, creating images and linking them to the effect that these situation have on their life.\n",
    "The goal is to clearly picture the life of the customer with the pain, and the believes they have, and what solution they already tried, so we can deconstruct these believes.\n",
    "\n",
    "It contains:\n",
    "\n",
    "#### A title grabbing attention\n",
    "\n",
    "Like \"Does any of this ring a bell?\", \"Do you know that?\"\n",
    "\n",
    "\n",
    "#### 3 title-paragraph blocks\n",
    "\n",
    "All containing a short and vivid description of scene the customer can rely to, that shows them in the pain related to the product.\n",
    "\"Every night, you lie awake, your mind racing with worries. The insomnia keeps you tossing and turning, frustration building as the hours slip by without sleep.\"\n",
    "\n",
    "### A Believes deconstruction block\n",
    "\n",
    "The goal here is to get the customer where they are with one current belief, aknoledge it and explain why it is wrong.\n",
    "Mention the solution they have tried to solve the problem, and back it up with scientific studies if possible, or with a statement.\n",
    "\n",
    "#### Believes deconstruction - headline\n",
    "\n",
    "It starts by a statement like \"You are not alone\", or \"In fact 80% of the population...\"\n",
    "\n",
    "#### Believes deconstruction - paragraph\n",
    "\n",
    "Then comes a short paragraph to further expand the headline.\n",
    "\n",
    "### Message from the founder\n",
    "\n",
    "Same principle as previous message\n",
    "\n",
    "### Desired outcome (After)\n",
    "\n",
    "This section is the \"after\" from the BAB copywriting framework.\n",
    "It is the exact opposite of the \"Before\", it should describe how the customer's life would look like after they obtained the result provided by the product/offer.\n",
    "\n",
    "Some clarification to avoid confusion:\n",
    "\"\n",
    "Problem: Muscle tension creating pain\n",
    "Solution: A course that teaches you to relax every muscle of your body\n",
    "Benefits: Pain free, you feel better\n",
    "Desired outcome: Finally play with your grankids and enjoy life on your own terms\n",
    "\"\n",
    "\n",
    "It contains:\n",
    "\n",
    "#### A title grabbing attention\n",
    "\n",
    "Like \"And now, imagine...\"\n",
    "\n",
    "#### 3 title-paragraph blocks\n",
    "\n",
    "All containing a short description of the scene and a small text like \"You start every morning positive and full of energy - You enjoy breakfast, are in a good mood and start the day with a positive attitude. This new morning routine will not only boost your self-confidence, but also improve your overall mood and boost your social and professional interactions.\"\n",
    "\n",
    "### A new paradigm block\n",
    "\n",
    "We deconstructed the customers believes earlier in the page, now it's time to reconstruct new believes by introducing something they haven't thought about before,a new way,  a new vehicule to move from the place they are to the place they want to be. We are not introducing the solution or the product yet, only \n",
    "\n",
    "##### New paradigm - Healdline\n",
    "\n",
    "Should be directly related to the \"Believes deconstruction\"\n",
    "\n",
    "Here is an example: \"Introducing [Product] A new way...\n",
    "\n",
    "##### New paradigm - paragraph\n",
    "\n",
    "Backing up the headline, explaining why this solution is different and can make a real change, based on the secret sauce\n",
    "Not only we explain it but we want the solution to feel like it's a new paradigm, a new solution that is going to solve their problem.\n",
    "Following the deconstruction of the believes, the construction of the new ones, and the introduction of the uniqueness of the solution, the paragraph should rationalize the excitment of finding out this new believe by facts, if possible backed up by science\n",
    "\n",
    "\n",
    "#### Solution 3-Steps blocks\n",
    "\n",
    "Each of these blocks are made from a Title and a short paragraph.\n",
    "Depending on the product/offer, it can be a 3-steps blocks showing the different steps to get from current to new situation, or, if it is not possible, the blocks should emphasize the benefits of the solution, backed up by the features of the solution\n",
    "\n",
    "\n",
    "### Message from the founder\n",
    "\n",
    "Same principle as previous message\n",
    "\n",
    "\n",
    "### Connection block\n",
    "\n",
    "This block is made to define the WHY behing the product/offer, while, at the same time, creating a connection between the founder and the customer.\n",
    "It is made with a Picture of the founder, a catchy headline and a paragraph\n",
    "\n",
    "#### Connection block headline\n",
    "\n",
    "Own words of the founders shortly explaining why the idea of creating this new product came up\n",
    "\n",
    "#### Connection block paragraph\n",
    "\n",
    "A semi-long paragraph telling the story and experience of the founder leading them to create the solution, in their own words.\n",
    "\n",
    "### Last call to action\n",
    "\n",
    "At this step, the customer went through all the emotion phases, and understand perfectly what the product/offer does, and how it will change their life.\n",
    "This block is the last push to rationally make them take the next step.\n",
    "\n",
    "#### Last call to action Headline\n",
    "\n",
    "A short sentence pushing on the timing to change, to take the next step\n",
    "\n",
    "#### Last call to action Subheadline\n",
    "\n",
    "A short sentence backing up the headline\n",
    "\n",
    "#### Last call to action CTA\n",
    "\n",
    "A clear action (button text)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "### The format of your answer\n",
    "\n",
    "DO NOT USE EMOJIES\n",
    "USE A MARKDOWN BLOCK TO WRITE YOUR ANSWER NOTHING BEFORE, NOTHING AFTER\n",
    "JUST WRITE THE ANSWER (e.g. do not write \"Hook 1: This is the hook\", instead write: This is the hook)\n",
    "\n",
    "Example format for the campaign structure:\n",
    "\n",
    "[\n",
    "Title: Landing page for [Product/offer name]\n",
    "- Above the fold\n",
    "\t- Headline\n",
    "\t\t- Short straight to the point headlines\n",
    "\t\t\t- [Short straight to the point headline version 1]\n",
    "\t\t\t- [Short straight to the point headline version 2]\n",
    "\t\t- Question headlines\n",
    "\t\t\t- [Question headline version 1]\n",
    "\t\t\t- [Question headline version 2]\n",
    "\t\t- Desired outcome headlines\n",
    "\t\t\t- [Desired outcome headline version 1]\n",
    "\t\t\t- [Desired outcome headline version 2]\n",
    "\t- Subheadline\n",
    "\t\t- [Subheadline version 1]\n",
    "\t\t- [Subheadline version 2]\n",
    "\t- Bullet points\n",
    "\t\t- [Bullet point 1]\n",
    "\t\t- [Bullet point 2]\n",
    "\t\t- [Bullet point 3]\n",
    "\t\t- [Bullet point 4]\n",
    "\t\t- [Bullet point 5]\n",
    "\t\t- [Bullet point 6]\n",
    "\t- Call to action\n",
    "\t\t- [Call to action version 1]\n",
    "\t\t- [Call to action version 2]\n",
    "\t\t- [Call to action version 3]\n",
    "- Message from the founder\n",
    "\t- [Message from the founder]\n",
    "- The current situation\n",
    "\t- Title grabbing attention\n",
    "\t\t- [Title grabbing attention version 1]\n",
    "\t\t- [Title grabbing attention version 2]\n",
    "\t- Title-paragraph blocks\n",
    "\t\t- [Title-paragraph block version 1]\n",
    "\t\t- [Title-paragraph block version 2]\n",
    "\t\t- [Title-paragraph block version 3]\n",
    "\t\t- [Title-paragraph block version 4]\n",
    "- Believes deconstruction block\n",
    "\t- Believes deconstruction - headline\n",
    "\t\t- [Believes deconstruction - headline]\n",
    "\t- Believes deconstruction - paragraph\n",
    "\t\t- [Believes deconstruction - paragraph]\n",
    "- Message from the founder\n",
    "\t- [Message from the founder]\n",
    "- Desired outcome\n",
    "\t- Title grabbing attention\n",
    "\t\t- [Title grabbing attention version 1]\n",
    "\t\t- [Title grabbing attention version 2]\n",
    "\t- Title-paragraph blocks\n",
    "\t\t- [Title-paragraph block version 1]\n",
    "\t\t- [Title-paragraph block version 2]\n",
    "\t\t- [Title-paragraph block version 3]\n",
    "\t\t- [Title-paragraph block version 4]\n",
    "- New paradigm block\n",
    "\t- New paradigm - headline\n",
    "\t\t- [New paradigm - headline]\n",
    "\t- New paradigm - paragraph\n",
    "\t\t- [New paradigm - paragraph (Starting with for example: \"this is not just another...\" This section is about how this new solution will help the customer, don't use \"our product\", about 70 words)]\n",
    "- Solution\n",
    "\t- Solution 3-Steps blocks\n",
    "\t\t\t- [Solution 3-Steps block 1 ]\n",
    "\t\t\t- [Solution 3-Steps block 2]\n",
    "\t\t\t- [Solution 3-Steps block 3]\n",
    "- Message from the founder\n",
    "\t- [Message from the founder]\n",
    "- Connection block\n",
    "\t\t- [Connection block headline]\n",
    "\t\t- [Connection block paragraph]\n",
    "- Last call to action\n",
    "\t\t- [Last call to action Headline]\n",
    "\t\t- [Last call to action Subheadline]\n",
    "\t\t- [Last call to action CTA]\n",
    "]    \n",
    "    \"\"\",\n",
    "    input_variables=[\"product\",\"market_researcher_agent\",\"marketing_strategist_agent\", \"campaign_agent\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Chain\n",
    "landing_page_chain = landing_page_prompt | llm_landing_page | StrOutputParser()\n",
    "\n",
    "\n",
    "\n",
    "#landing_page_agent = landing_page_chain.invoke({\"product\":product, \"market_researcher_agent\":market_researcher_agent,\"marketing_strategist_agent\":marketing_strategist_agent, \"campaign_agent\":campaign_agent})\n",
    "#print(landing_page_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c910c1-738c-4bf7-bf9e-801862b227eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Router\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOllama\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JsonOutputParser\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "### Router\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an expert websearcher.\n",
    "    you have been provided with google search results for a location. summarizer the information to pass it to email writer.  \n",
    "    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \n",
    "    no premable or explanation. Question to route: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "question_router = prompt | llm | JsonOutputParser()\n",
    "question = \"llm agent memory\"\n",
    "\n",
    "doc_txt = docs[1].page_content\n",
    "print(question_router.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd59cdf-a04d-4b2e-b9cc-6a1b1e80a6c6",
   "metadata": {},
   "source": [
    "We'll implement these as a control flow in LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "07fa3d08-6a86-4705-a28b-e2721070bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from typing import List\n",
    "from termcolor import colored\n",
    "from langchain_core.documents import Document\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, START, MessagesState\n",
    "from datetime import date\n",
    "\n",
    "from google_serper import serper_search\n",
    "\n",
    "import json\n",
    "\n",
    "### State\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "   \"\"\"\n",
    "    product: str\n",
    "    \n",
    "    \n",
    "      \n",
    "    sub_reddits_to_search: str\n",
    "    sub_reddits_to_scrape: str\n",
    "    \n",
    "    comments: str\n",
    "    google_search_summary: str\n",
    "    web_summary: str\n",
    "\n",
    "    market_research: str\n",
    "    brand_strategy: dict\n",
    "    branding: str\n",
    "   \n",
    "   \n",
    "    \n",
    "    \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "### Nodes\n",
    "\n",
    "\n",
    "def product_info(state):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    print(colored(f\"---PRODUCT INFO---\", 'green'))\n",
    "    \n",
    "    chat_history= state[\"chat_history\"]\n",
    "    #user = state[\"user_input\"]\n",
    "\n",
    "    info_collector_agent= info_collector_chain.invoke({\"user\": user, \"chat_history\": chat_history})\n",
    "    print(info_collector_agent)\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    return {\"product\": info_collector_agent, \"chat_history\": user}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def router(state):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    print(colored(f\"---ROUTER---\", 'green'))\n",
    "    \n",
    "    #user = state[\"user_input\"]\n",
    "    product = state[\"product\"]\n",
    "\n",
    "    router_agent= router_chain.invoke({\"product\": product})\n",
    "    \n",
    "    if router_agent['status'] == 'yes':\n",
    "        return {\"router\":'yes'}\n",
    "    elif router_agent['status'] == 'no':\n",
    "        return {\"router\":'no'}\n",
    "\n",
    "    else:\n",
    "        return {\"router\":'__end__'}\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def google_search(state):\n",
    "    #agency_type=\"AI Automation Agency\"\n",
    "    \n",
    "    product = state[\"product\"]\n",
    "    \n",
    "    print(colored(f\"\\n---GOOOGLE SEARCHER---\", 'green'))\n",
    "    \n",
    "    results=serper_search(f\"branding stratergies for {product} \")\n",
    "    print(results)\n",
    "    web_text = detect_and_scrape_url(results)\n",
    "    \n",
    "    google_summary_agent= web_summary_chain.invoke({\"web_text\":web_text, \"product\": product})\n",
    "    \n",
    "    return {\"google_search_summary\":google_summary_agent}\n",
    "\n",
    "#google_search(agency_type)\n",
    "\n",
    "\n",
    "def subreddit_to_search(state):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    print(colored(f\"---POSSIBLE SUB REDDITS---\", 'green'))\n",
    "    \n",
    "    product = state[\"product\"]\n",
    "\n",
    "    subreddit_name_agent= subreddit_name_chain.invoke({\"product\": product})\n",
    "    print(subreddit_name_agent)\n",
    "    \n",
    "    \n",
    "    return {\"sub_reddits_to_search\": subreddit_name_agent}\n",
    "\n",
    "\n",
    "def subreddit_selector(state):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print(colored(f\"\\n\\n ---SUB-REDDITS SELECTOR---\", 'green'))\n",
    "    sub_reddits_to_search = state[\"sub_reddits_to_search\"]\n",
    "    product= state[\"product\"]\n",
    "   \n",
    "    \n",
    "    sub_reddits = search_subreddits(sub_reddits_to_search)\n",
    "    \n",
    "\n",
    "    #google_search=web_search_tool.invoke({\"query\": \"latest {location} \"})\n",
    "    subreddit_searcher_agent= subreddit_searcher_chain.invoke({\"product\": product, \"sub_reddits\":sub_reddits})\n",
    "    print(subreddit_searcher_agent)\n",
    "    print(colored(f\"\\nSub Reddits:\\n\\n {subreddit_searcher_agent} \", 'green'))\n",
    "    \n",
    "    return {\"sub_reddits_to_scrape\": subreddit_searcher_agent}\n",
    "\n",
    "\n",
    "def detect_and_scrape_url(message):\n",
    "    # Regular expression to detect URLs\n",
    "    url_pattern = re.compile(r'(https?://[^\\s]+)')\n",
    "    \n",
    "    # Search for URLs in the message\n",
    "    match = url_pattern.search(message)\n",
    "\n",
    "    # Check if a URL was found\n",
    "    if match:\n",
    "        url = match.group(0)\n",
    "        \n",
    "        # Check if the URL has already been scraped\n",
    "        \n",
    "        print(f\"\\nScraping {url}\")\n",
    "        website_text = get_links_and_text(url)\n",
    "        # Store the scraped content\n",
    "        \n",
    "    \n",
    "        result = {\"URL\": url, \"text\": website_text}\n",
    "    else:\n",
    "        result = {}\n",
    "\n",
    "    # Convert to JSON format\n",
    "    result_json = json.dumps(result)\n",
    "    print(result_json)\n",
    "    return result_json\n",
    "\n",
    "\n",
    "\n",
    "def web_summarizer(state):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print(colored(f\"\\n---COMPETITION WEB SUMMARY---\", 'green'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    product = state[\"product\"]\n",
    "    \n",
    "\n",
    "    # summary generation\n",
    "    web_text= detect_and_scrape_url(product)\n",
    "    \n",
    "    \n",
    "    web_summary_agent= web_summary_chain.invoke({\"web_text\":web_text, \"product\": product})\n",
    "    print(web_summary_agent[:300])\n",
    "    return { \"web_summary\": web_summary_agent}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def market_researcher(state):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print(colored(f\"\\n---MARKET RESEARCHER---\", 'green'))\n",
    "    subreddits_to_scrape = state[\"sub_reddits_to_scrape\"]\n",
    "    product = state[\"product\"]\n",
    "    \n",
    "\n",
    "    # summary generation\n",
    "    comments= reddit_comments(subreddits_to_scrape)\n",
    "    \n",
    "    print(colored(f\"\\n---Filtering Comments---\", 'blue'))\n",
    "    \n",
    "    filtered_comments= filter_comments(comments)\n",
    "    market_researcher_agent= market_researcher_chain.invoke({\"filtered_comments\":filtered_comments[:1000], \"product\": product})\n",
    "    return { \"market_research\": market_researcher_agent}\n",
    "\n",
    "\n",
    "\n",
    "def strategist(state):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print(colored(f\"\\n---MARKET STRATEGIST---\", 'green'))\n",
    "    market_research = state[\"market_research\"]\n",
    "    product = state[\"product\"]\n",
    "    \n",
    "\n",
    "    # summary generation\n",
    "    brand_strategist_agent=  brand_strategist_chain.invoke({\"market_researcher_agent\": market_research, \"product\": product})\n",
    "    print( brand_strategist_agent)\n",
    "    #target_audience=  brand_strategist_agent['Potential target audience']\n",
    "    \n",
    "    return { \"brand_strategy\":  brand_strategist_agent}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def branding_creator(state):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print(colored(f\"\\n---BRAND CRAFTER---\\n\\n\", 'green'))\n",
    "    market_research = state[\"market_research\"]\n",
    "    brand_strategy = state[\"brand_strategy\"]\n",
    "    web_summary =state[\"web_summary\"]\n",
    "    google_search_summary = state[\"google_search_summary\"] \n",
    "    product = state[\"product\"]\n",
    "    \n",
    "    \n",
    "\n",
    "    # summary generation\n",
    "    branding_agent = branding_chain.invoke({\"product\":product, \"google_summary\": google_search_summary, \"web_summary_agent\":web_summary, \"market_researcher_agent\": market_research,\"brand_strategist_agent\":brand_strategy})\n",
    "\n",
    "    return { \"product\":product, \"branding\": branding_agent}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def landing_page_generator(state):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print(colored(f\"\\n---LANDING_PAGE_GENERATOR---\", 'green'))\n",
    "    market_research = state[\"market_research\"]\n",
    "    marketing_strategy = state[\"marketing_strategy\"]\n",
    "\n",
    "    product = state[\"product\"]\n",
    "    #campaign_agent = state[\"campaign\"]\n",
    "    \n",
    "\n",
    "    # summary generation\n",
    "    landing_page_agent = landing_page_chain.invoke({\"product\":product, \"market_researcher_agent\":market_research,\"marketing_strategist_agent\":marketing_strategy})\n",
    "\n",
    "    return {\"product\":product, \"landing_page\": landing_page_agent}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f5398399",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "#workflow.add_node(\"product_info\", product_info)\n",
    "\n",
    "#workflow.add_node(\"router\", router)\n",
    "workflow.add_node(\"google_search\", google_search)\n",
    "workflow.add_node(\"subreddit_to_search\", subreddit_to_search)  # \n",
    "workflow.add_node(\"subreddit_selector\",subreddit_selector) \n",
    "workflow.add_node(\"web_summarizer\",web_summarizer) # \n",
    "workflow.add_node(\"market_researcher\", market_researcher)\n",
    "\n",
    "workflow.add_node(\"strategist\", strategist)  # \n",
    "\n",
    "\n",
    "workflow.add_node(\"branding_creator\",branding_creator)  # \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Edges\n",
    "#workflow.set_entry_point(\"router\")\n",
    "\n",
    "#workflow.add_conditional_edges(\n",
    "#                               router, {\"yes\": \"google_search\", \"no\": \"router\", \"__end__\": END},\n",
    "#)\n",
    "\n",
    "\n",
    "workflow.set_entry_point(\"google_search\")\n",
    "workflow.add_edge(\"google_search\", \"subreddit_to_search\")\n",
    "\n",
    "workflow.add_edge(\"subreddit_to_search\",\"subreddit_selector\")\n",
    "\n",
    "\n",
    "workflow.add_edge(\"subreddit_selector\",\"web_summarizer\")\n",
    "workflow.add_edge(\"web_summarizer\",\"market_researcher\")\n",
    "workflow.add_edge(\"market_researcher\",\"strategist\")\n",
    "\n",
    "workflow.add_edge(\"strategist\", \"branding_creator\")\n",
    "\n",
    "\n",
    "workflow.add_edge(\"branding_creator\", END)\n",
    "\n",
    "#checkpointer = MemorySaver()\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()#checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "685e2991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cab23ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = \"We are an AI automation services agency named 'INFINITLY' that empowers business owners with cutting-edge AI solutions. Our services include developing AI-powered applications, robust RAG (Retrieval-Augmented Generation) chatbots, and custom AI Telegram bots, all designed to streamline operations, enhance customer interactions, and drive business growth. With our expertise, businesses can leverage advanced AI technology to stay competitive and innovative. competition website: https://tovie.ai/ai-consulting\"\n",
    "\n",
    "inputs = {\"product\": product}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "details= {\n",
    "      \"product_details\": {\n",
    "        \"name\": \"[Startup Name]\",\n",
    "        \"product_service\": \"[Product or Service]\",\n",
    "        \"industry\": \"[Industry]\",\n",
    "        \"problem_solved\": \"[Problem]\"\n",
    "        \"Competition Website\": \"[url]\"\n",
    "      }\n",
    "     }\n",
    "\n",
    "inputs = {\"product\": product}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f21594-00d4-48a8-ae2e-4e55a010b540",
   "metadata": {},
   "source": [
    "### Graph Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f9f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"landing_page\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fbfcec3e-a09a-40b4-9c15-fead97bf4e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "---GOOOGLE SEARCHER---\u001b[0m\n",
      "Title: Branding in the Age of AI Automation and Innovation\n",
      "Link: https://www.linkedin.com/pulse/branding-age-ai-automation-innovation-endeavour-marketing-llp-9ylaf\n",
      "Snippet: 1. Personalization at Scale: AI enables brands to deliver highly personalized experiences to consumers. · 2. Enhanced Customer Insights: AI- ...\n",
      "---\n",
      "Title: AI for customer success: Significance, applications ...\n",
      "Link: https://www.leewayhertz.com/ai-for-customer-success/\n",
      "Snippet: Our strategic AI/ML consulting empowers businesses to leverage artificial intelligence for improved customer engagement, enhanced support efficiency, and ...\n",
      "---\n",
      "Title: Ai Automation Agency\n",
      "Link: https://love.marketing/ai-automation-agency/\n",
      "Snippet: Predictive Analytics: We use AI to analyze data and predict future trends, customer behavior, and sales patterns to inform marketing strategies.\n",
      "---\n",
      "Title: Top 50+ Chatbot Companies September 2024\n",
      "Link: https://www.upwork.com/agencies/chatbot-companies/?page=15\n",
      "Snippet: Our Expertise: 1. Custom AI Solutions: Our skilled developers and prompt engineers design bespoke automation solutions using cutting-edge AI technologies.\n",
      "---\n",
      "Title: 10 Cutting-Edge AI Applications Revolutionizing Modern ...\n",
      "Link: https://pcsocial.medium.com/10-cutting-edge-ai-applications-revolutionizing-modern-marketing-strategies-e04775a0aaf3\n",
      "Snippet: Marketing automation platforms use AI algorithms to automate repetitive marketing tasks and gather data from various sources. Data visualization ...\n",
      "---\n",
      "Title: Branding and Marketing Strategy in the Age of AI\n",
      "Link: https://www.brandingmarketingagency.com/blogs/ai-driven-branding-and-marketing/\n",
      "Snippet: In this blog, we will explore the impact of AI on branding and marketing, some key challenges, and helpful strategies that businesses can use to create a ...\n",
      "---\n",
      "Title: Angela Ferrante's Post\n",
      "Link: https://www.linkedin.com/posts/angela-ferrante_a-few-of-the-the-ai-tools-automations-ive-activity-7191566802030678016-LEd0\n",
      "Snippet: Innovative AI Solutions Explore the top 10 AI tools to empower your business ... generation with AI-powered chatbots and sales support tools.\n",
      "---\n",
      "Title: 6 Ways Brands Are Leveraging AI in Marketing\n",
      "Link: https://tinuiti.com/blog/marketing/6-ways-brands-are-leveraging-ai-in-marketing/\n",
      "Snippet: Here are six ways brands are harnessing AI for their marketing strategies, along with practical examples and ideas for implementation.\n",
      "---\n",
      "Title: e2b-dev/awesome-ai-agents: A list of AI autonomous agents\n",
      "Link: https://github.com/e2b-dev/awesome-ai-agents\n",
      "Snippet: Description. A low-code framework designed for the swift creation, testing, and iteration of AI-powered autonomous agents and Cognitive Architectures, ...\n",
      "---\n",
      "Title: chatbot Applications - Lablab.ai\n",
      "Link: https://lablab.ai/apps/topic/chatbot\n",
      "Snippet: Our AI Agent is able to create a marketing campaign that adapts to your business needs by creating multimodal content, calendar proposal, campaign strategy and ...\n",
      "---\n",
      "\n",
      "Scraping https://www.linkedin.com/pulse/branding-age-ai-automation-innovation-endeavour-marketing-llp-9ylaf\n",
      "49\n",
      "44\n",
      "{\"URL\": \"https://www.linkedin.com/pulse/branding-age-ai-automation-innovation-endeavour-marketing-llp-9ylaf\", \"text\": [{\"source\": \"https://www.linkedin.com/pulse/branding-age-ai-automation-innovation-endeavour-marketing-llp-9ylaf\", \"content\": \"Branding in the Age of AI Automation and Innovation Agree & Join LinkedIn By clicking Continue to join or sign in, you agree to LinkedIn\\u2019s User Agreement , Privacy Policy , and Cookie Policy . Sign in to view more content Create your free account or sign in to continue your search Sign in Welcome back Email or phone Password Show Forgot password? Sign in or By clicking Continue to join or sign in, you agree to LinkedIn\\u2019s User Agreement , Privacy Policy , and Cookie Policy . New to LinkedIn? Join now or By clicking Continue to join or sign in, you agree to LinkedIn\\u2019s User Agreement , Privacy Policy , and Cookie Policy . New to LinkedIn? Join now Skip to main content LinkedIn Join now Sign in Branding in the Age of AI Automation and Innovation Report this article Close menu Endeavour Marketing Endeavour Marketing Think Creative. Think Endeavour Published Jun 21, 2024 + Follow As we progress into the digital age, artificial intelligence (AI) is transforming the landscape of branding. Automation and innovation are at the forefront, reshaping how brands interact with consumers and build their identities. In this article, we explore how AI is revolutionizing branding and the strategies businesses can adopt to leverage these advancements effectively. The Role of AI in Modern Branding 1. Personalization at Scale: AI enables brands to deliver highly personalized experiences to consumers. By analyzing vast amounts of data, AI algorithms can tailor marketing messages, product recommendations, and content to individual preferences, enhancing customer engagement and loyalty. 2. Enhanced Customer Insights: AI-driven analytics provide deep insights into consumer behavior, preferences, and trends. These insights help brands understand their audience better, refine their targeting strategies, and develop products that meet evolving consumer needs. 3. Automated Customer Service: AI-powered chatbots and virtual assistants offer 24/7 customer support, resolving queries and issues efficiently. This automation not only improves customer satisfaction but also frees up human resources for more complex tasks. 4. Content Creation and Curation: AI tools can generate and curate content, such as social media posts, blog articles, and email newsletters. This automation ensures consistent and timely content delivery, maintaining brand presence and engagement across platforms. 5. Dynamic Pricing and Inventory Management: AI algorithms optimize pricing strategies and inventory management by analyzing market conditions, demand fluctuations, and competitor actions. This dynamic approach helps brands stay competitive and maximize profits. Strategies for Leveraging AI in Branding 1. Data-Driven Decision Making: Embrace a data-centric approach to branding. Use AI to collect and analyze customer data, gaining actionable insights that inform marketing strategies, product development, and customer engagement initiatives. 2. Invest in AI Technology: Adopt AI technologies that align with your brand\\u2019s objectives. From customer relationship management (CRM) systems to predictive analytics and AI-driven design tools, investing in the right technology can drive significant branding improvements. 3. Focus on Personalization: Leverage AI to create personalized customer experiences. Use machine learning algorithms to tailor product recommendations, customize marketing messages, and deliver relevant content that resonates with your audience. 4. Enhance Customer Interactions: Implement AI-powered chatbots and virtual assistants to provide instant support and information to customers. Ensure these tools are integrated seamlessly into your customer service strategy to enhance overall user experience. 5. Content Optimization: Utilize AI to generate, curate, and optimize content. AI can help identify trending topics, create engaging content, and ensure consistent messaging across all channels, strengthening your brand\\u2019s voice and presence. 6. Monitor and Adapt: Continuously monitor the performance of AI-driven branding initiatives. Use AI analytics to track key metrics, such as engagement rates, conversion rates, and customer satisfaction. Adapt your strategies based on these insights to ensure ongoing success. Case Study: AI in Action \\u2013 Netflix Netflix is a prime example of a brand that has effectively harnessed AI for branding and customer engagement. By leveraging AI algorithms, Netflix delivers personalized content recommendations to its users, enhancing viewer satisfaction and loyalty. The brand\\u2019s AI-driven approach to content curation and user experience has been pivotal in its global success. Challenges and Considerations 1. Data Privacy and Security: With the increased use of AI, ensuring data privacy and security is paramount. Brands must implement robust data protection measures and comply with regulations to maintain customer trust. 2. Human Touch: While AI offers automation and efficiency, the human touch remains essential in branding. Striking the right balance between AI-driven interactions and human engagement is crucial for maintaining authenticity and emotional connections with customers. 3. Ethical AI Usage: Ethical considerations in AI deployment are vital. Brands must ensure their AI systems are unbiased, transparent, and aligned with ethical standards to avoid potential reputational risks. Conclusion The age of AI is redefining branding through automation and innovation. By leveraging AI technologies, brands can deliver personalized experiences, gain valuable customer insights, and optimize their marketing strategies. However, it\\u2019s essential to balance AI capabilities with human touch and ethical considerations. Embrace AI as a tool to enhance your brand\\u2019s identity and engagement, driving success in the competitive digital landscape. Brand Pulse Insight Brand Pulse Insight 520 followers + Subscribe 1 Like Comment Copy LinkedIn Facebook Twitter Close menu Share To view or add a comment, sign in More articles by this author No more previous content Disneys Cross Platform Marketing Aug 29, 2024 Branding in the Gaming Industry: Creating Immersive Experiences Aug 29, 2024 Peloton\\u2019s Community Building Tactics Aug 28, 2024 The Impact of Branding on Consumer Perceptions of Environmental Sustainability Aug 28, 2024 ASOS\\u2019s Social Commerce Strategy Aug 27, 2024 The Success of Salesforce\\u2019s Community Marketing Aug 27, 2024 Branding in the Healthcare Industry Building Trust and Credibility Aug 27, 2024 Taco Bell\\u2019s Social Media Savvy Aug 26, 2024 The Role of Branding in Non-Profit Organizations: Communicating Impact Aug 26, 2024 The Influence of Malcolm Gladwell's \\\"Outliers\\\" on Entrepreneurial Success Stories Aug 25, 2024 No more next content Explore topics Sales Marketing IT Services Business Administration HR Management Engineering Soft Skills See All LinkedIn \\u00a9 2024 About Accessibility User Agreement Privacy Policy Cookie Policy Copyright Policy Brand Policy Guest Controls Community Guidelines \\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629 (Arabic) \\u09ac\\u09be\\u0982\\u09b2\\u09be (Bangla) \\u010ce\\u0161tina (Czech) Dansk (Danish) Deutsch (German) \\u0395\\u03bb\\u03bb\\u03b7\\u03bd\\u03b9\\u03ba\\u03ac (Greek) English (English) Espa\\u00f1ol (Spanish) Suomi (Finnish) Fran\\u00e7ais (French) \\u0939\\u093f\\u0902\\u0926\\u0940 (Hindi) Magyar (Hungarian) Bahasa Indonesia (Indonesian) Italiano (Italian) \\u65e5\\u672c\\u8a9e (Japanese) \\ud55c\\uad6d\\uc5b4 (Korean) \\u092e\\u0930\\u093e\\u0920\\u0940 (Marathi) Bahasa Malaysia (Malay) Nederlands (Dutch) Norsk (Norwegian) \\u0a2a\\u0a70\\u0a1c\\u0a3e\\u0a2c\\u0a40 (Punjabi) Polski (Polish) Portugu\\u00eas (Portuguese) Rom\\u00e2n\\u0103 (Romanian) \\u0420\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439 (Russian) Svenska (Swedish) \\u0c24\\u0c46\\u0c32\\u0c41\\u0c17\\u0c41 (Telugu) \\u0e20\\u0e32\\u0e29\\u0e32\\u0e44\\u0e17\\u0e22 (Thai) Tagalog (Tagalog) T\\u00fcrk\\u00e7e (Turkish) \\u0423\\u043a\\u0440\\u0430\\u0457\\u043d\\u0441\\u044c\\u043a\\u0430 (Ukrainian) Ti\\u1ebfng Vi\\u1ec7t (Vietnamese) \\u7b80\\u4f53\\u4e2d\\u6587 (Chinese (Simplified)) \\u6b63\\u9ad4\\u4e2d\\u6587 (Chinese (Traditional)) Close menu Language\"}, {\"source\": \"https://www.linkedin.com/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement\", \"content\": \"User Agreement | LinkedIn Skip to main content User Agreement Summary of User Agreement Privacy Policy Professional Community Policies Cookie Policy Copyright Policy Regional Info California Privacy Disclosure U.S. State Privacy Laws User Agreement Summary of User Agreement Privacy Policy Professional Community Policies Cookie Policy Copyright Policy Regional Info California Privacy Disclosure U.S. State Privacy Laws User Agreement Effective on February 1, 2022 Our mission is to connect the world\\u2019s professionals to allow them to be more productive and successful. Our services are designed to promote economic opportunity for our members by enabling you and millions of other professionals to meet, exchange ideas, learn, and find opportunities or employees, work, and make decisions in a network of trusted relationships. Table of Contents: Introduction Obligations Rights and Limits Disclaimer and Limit of Liability Termination Governing Law and Dispute Resolution General Terms LinkedIn \\u201cDos and Don\\u2019ts\\u201d Complaints Regarding Content How To Contact Us Introduction 1.1 Contract When you use our Services you agree to all of these terms. Your use of our Services is also subject to our Cookie Policy and our Privacy Policy, which covers how we collect, use, share, and store your personal information. You agree that by clicking \\u201cJoin Now\\u201d, \\u201cJoin LinkedIn\\u201d, \\u201cSign Up\\u201d or similar, registering, accessing or using our services (described below),\\u00a0you are agreeing to enter into a legally binding contract\\u00a0with LinkedIn (even if you are using our Services on behalf of a company). If you do not agree to this contract (\\u201cContract\\u201d or \\u201cUser Agreement\\u201d), do\\u00a0not\\u00a0click \\u201cJoin Now\\u201d (or similar) and do not access or otherwise use any of our Services. If you wish to terminate this contract, at any time you can do so by closing your account and no longer accessing or using our Services. Services This Contract applies to LinkedIn.com, LinkedIn-branded apps, LinkedIn Learning and other LinkedIn-related sites, apps, communications and other services that state that they are offered under this Contract (\\u201cServices\\u201d), including the offsite collection of data for those Services, such as our ads and the \\u201cApply with LinkedIn\\u201d and \\u201cShare with LinkedIn\\u201d plugins. Registered users of our Services are \\u201cMembers\\u201d and unregistered users are \\u201cVisitors\\u201d. LinkedIn You are entering into this Contract with LinkedIn (also referred to as \\u201cwe\\u201d and \\u201cus\\u201d). We use the term \\u201cDesignated Countries\\u201d to refer to countries in the European Union (EU), European Economic Area (EEA), and Switzerland. If you reside in the \\u201cDesignated Countries\\u201d, you are entering into this Contract with LinkedIn Ireland Unlimited Company (\\u201cLinkedIn Ireland\\u201d) and LinkedIn Ireland will be the controller of your personal data provided to, or collected by or for, or processed in connection with our Services. If you reside outside of the \\u201cDesignated Countries\\u201d, you are entering into this Contract with LinkedIn Corporation (\\u201cLinkedIn Corp.\\u201d) and LinkedIn Corp. will be the controller of your personal data provided to, or collected by or for, or processed in connection with our Services. This Contract applies to Members and Visitors. As a Visitor or Member of our Services, the collection, use and sharing of your personal data is subject to this Privacy Policy (which includes our Cookie Policy and other documents referenced in this Privacy Policy) and updates. 1.2 Members and Visitors When you register and join the LinkedIn Services, you become a Member. If you have chosen not to register for our Services, you may access certain features as a \\u201cVisitor.\\u201d 1.3 Change We may make changes to the Contract. We may modify this Contract, our Privacy Policy and our Cookies Policy from time to time. If we make material changes to it, we will provide you notice through our Services, or by other means, to provide you the opportunity to review the changes before they become effective. We agree that changes cannot be retroactive. If you object to any changes, you may close your account . Your continued use of our Services after we publish or send a notice about our changes to these terms means that you are consenting to the updated terms as of their effective date. 2. Obligations 2.1 Service Eligibility Here are some promises that you make to us in this Contract: You\\u2019re eligible to enter into this Contract and you are at least our \\u201cMinimum Age.\\u201d The Services are not for use by anyone under the age of 16. To use the Services, you agree that: (1) you must be the \\\"Minimum Age\\\" (described below) or older; (2) you will only have one LinkedIn account, which must be in your real name; and (3) you are not already restricted by LinkedIn from using the Services. Creating an account with false information is a violation of our terms, including accounts registered on behalf of others or persons under the age of 16. \\u201cMinimum Age\\u201d means 16 years old. However, if law requires that you must be older in order for LinkedIn to lawfully provide the Services to you without parental consent (including using of your personal data) then the Minimum Age is such older age. 2.2 Your Account You will keep your password a secret You will not share an account with anyone else and will follow our rules and the law. Members are account holders. You agree to: (1) use a strong password and keep it confidential; (2) not transfer any part of your account (e.g., connections) and (3) follow the law and our list of Dos and Don\\u2019ts and Professional Community Policies . You are responsible for anything that happens through your account unless you close it or report misuse. As between you and others (including your employer), your account belongs to you. However, if the Services were purchased by another party for you to use (e.g. Recruiter seat bought by your employer), the party paying for such Service has the right to control access to and get reports on your use of such paid Service; however, they do not have rights to your personal account 2.3 Payment You\\u2019ll honor your payment obligations and you are okay with us storing your payment information. You understand that there may be fees and taxes that are added to our prices. Refunds are subject to our policy. If you buy any of our paid Services (\\u201cPremium Services\\u201d), you agree to pay us the applicable fees and taxes and to additional terms specific to the paid Services. Failure to pay these fees will result in the termination of your paid Services. Also, you agree that: Your purchase may be subject to foreign exchange fees or differences in prices based on location (e.g. exchange rates). We may store and continue billing your payment method (e.g. credit card) even after it has expired, to avoid interruptions in your Services and to use to pay other Services you may buy. If you purchase a subscription, your payment method automatically will be charged at the start of each subscription period for the fees and taxes applicable to that period. To avoid future charges, cancel before the renewal date. Learn how to cancel or suspend your Premium Services. All of your purchases of Services are subject to LinkedIn\\u2019s refund policy . We may calculate taxes payable by you based on the billing information that you provide us at the time of purchase. You can get a copy of your invoice through your LinkedIn account settings under \\u201c Purchase History \\u201d. 2.4 Notices and Messages You\\u2019re okay with us providing notices and messages to you through our websites, apps, and contact information. If your contact information is out of date, you may miss out on important notices. You agree that we will provide notices and messages to you in the following ways: (1) within the Service, or (2) sent to the contact information you provided us (e.g., email, mobile number, physical address). You agree to keep your contact information up to date. Please review your settings to control and limit messages you receive from us. 2.5 Sharing When you share information on our Services, others can see, copy and use that information. Our Services allow messaging and sharing of information in many ways, such as your profile, articles, group posts, links to news articles, job postings, messages and InMails. Information and content that you share or post may be seen by other Members, Visitors or others (including off of the Services). Where we have made settings available, we will honor the choices you make about who can see content or information (e.g., message content to your addressees, sharing content only to LinkedIn connections, restricting your profile visibility from search engines, or opting not to notify others of your LinkedIn profile update). For job searching activities, we default to not notifying your connections network or the public. So, if you apply for a job through our Service or opt to signal that you are interested in a job, our default is to share it only with the job poster. We are not obligated to publish any information or content on our Service and can remove it with or without notice. Key terms Minimum Age Members who were below this new Minimum Age when they started using the Services under a previous User Agreement which had allowed certain persons under 16 to use the Services, may continue to use the Services. As of June 2017 persons under the age of 16 are not eligible to use our Services. 3. Rights and Limits 3.1. Your License to LinkedIn You own all of the content, feedback and personal information you provide to us, but you also grant us a non-exclusive license to it. We\\u2019ll honor the choices you make about who gets to see your information and content, including how it can be used for ads. As between you and LinkedIn, you own the content and information that you submit or post to the Services, and you are only granting LinkedIn and our affiliates the following non-exclusive license: A worldwide, transferable and sublicensable right to use, copy, modify, distribute, publish and process, information and content that you provide through our Services and the services of others, without any further consent, notice and/or compensation to you or others. These rights are limited in the following ways: You can end this license for specific content by deleting such content from the Services, or generally by closing your account, except (a) to the extent you shared it with others as part of the Service and they copied, re-shared it or stored it and (b) for the reasonable time it takes to remove from backup and other systems. We will not include your content in advertisements for the products and services of third parties to others without your separate consent (including sponsored content). However, we have the right, without payment to you or others, to serve ads near your content and information, and your social actions may be visible and included with ads, as noted in the Privacy Policy. If you use a Service feature, we may mention that with your name or photo to promote that feature within our Services, subject to your settings. We will get your consent if we want to give others the right to publish your content beyond the Services. However, if you choose to share your post as \\\"public, everyone or similar\\\", we will enable a feature that allows other Members to embed that public post onto third-party services, and we enable search engines to make that public content findable though their services. Learn More While we may edit and make format changes to your content (such as translating or transcribing it, modifying the size, layout or file type or removing metadata), we will not modify the meaning of your expression. Because you own your content and information and we only have non-exclusive rights to it, you may choose to make it available to others, including under the terms of a Creative Commons license . You and LinkedIn agree that if content includes personal data, it is subject to our Privacy Policy. You and LinkedIn agree that we may access, store, process and use any information and personal data that you provide in accordance with, the terms of the Privacy Policy and your choices (including settings). By submitting suggestions or other feedback regarding our Services to LinkedIn, you agree that LinkedIn can use and share (but does not have to) such feedback for any purpose without compensation to you. You promise to only provide information and content that you have the right to share, and that your LinkedIn profile will be truthful. You agree to only provide content or information that does not violate the law nor anyone\\u2019s rights (including intellectual property rights). You also agree that your profile information will be truthful. LinkedIn may be required by law to remove certain information or content in certain countries. 3.2 Service Availability We may change or end any Service or modify our prices prospectively. We may change, suspend or discontinue any of our Services. We may also modify our prices effective prospectively upon reasonable notice to the extent allowed under the law. We don\\u2019t promise to store or keep showing any information and content that you\\u2019ve posted. LinkedIn is not a storage service. You agree that we have no obligation to store, maintain or provide you a copy of any content or information that you or others provide, except to the extent required by applicable law and as noted in our Privacy Policy. 3.3 Other Content, Sites and Apps Your use of others\\u2019 content and information posted on our Services, is at your own risk. Others may offer their own products and services through our Services, and we aren\\u2019t responsible for those third-party activities. By using the Services, you may encounter content or information that might be inaccurate, incomplete, delayed, misleading, illegal, offensive or otherwise harmful. LinkedIn generally does not review content provided by our Members or others. You agree that we are not responsible for others\\u2019 (including other Members\\u2019) content or information. We cannot always prevent this misuse of our Services, and you agree that we are not responsible for any such misuse. You also acknowledge the risk that you or your organization may be mistakenly associated with content about others when we let connections and followers know you or your organization were mentioned in the news. Members have choices about this feature . LinkedIn may help connect Members offering their services (career coaching, accounting, etc.) with Members seeking services. LinkedIn does not perform nor employs individuals to perform these services. You must be at least 18 years of age to offer, perform or procure these services. You acknowledge that LinkedIn does not supervise, direct, control or monitor Members in the performance of these services and agree that (1) LinkedIn is not responsible for the offering, performance or procurement of these services, (2) LinkedIn does not endorse any particular Member\\u2019s offered services, and (3) nothing shall create an employment, agency, or joint venture relationship between LinkedIn and any Member offering services. If you are a Member offering services, you represent and warrant that you have all the required licenses and will provide services consistent with our Professional Community Policies . Similarly, LinkedIn may help you register for and/or attend events organized by Members and connect with other Members who are attendees at such events. You agree that (1) LinkedIn is not responsible for the conduct of any of the Members or other attendees at such events, (2) LinkedIn does not endorse any particular event listed on our Services, (3) LinkedIn does not review and/or vet any of these events, and (4) that you will adhere to these terms and conditions that apply to such events. 3.4 Limits We have the right to limit how you connect and interact on our Services. LinkedIn reserves the right to limit your use of the Services, including the number of your connections and your ability to contact other Members. LinkedIn reserves the right to restrict, suspend, or terminate your account if you breach this Contract or the law or are misusing the Services (e.g., violating any of the Dos and Don\\u2019ts or Professional Community Policies ). 3.5 Intellectual Property Rights We\\u2019re providing you notice about our intellectual property rights. LinkedIn reserves all of its intellectual property rights in the Services. Trademarks and logos used in connection with the Services are the trademarks of their respective owners. LinkedIn, and \\u201cin\\u201d logos and other LinkedIn trademarks, service marks, graphics and logos used for our Services are trademarks or registered trademarks of LinkedIn. 3.6 Automated Processing We use data and information about you to make relevant suggestions to you and others. We use the information and data that you provide and that we have about Members to make recommendations for connections, content and features that may be useful to you. For example, we use data and information about you to recommend jobs to you and you to recruiters. Keeping your profile accurate and up to date helps us to make these recommendations more accurate and relevant. Learn More Key Terms Affiliates Affiliates are companies controlling, controlled by or under common control with us, including, for example, LinkedIn Ireland, LinkedIn Corporation, LinkedIn Singapore and Microsoft Corporation. Social Action e.g.\\u00a0likes, comments, follows,\\u00a0share 4. Disclaimer and Limit of Liability 4.1 No Warranty This is our disclaimer of legal liability for the quality, safety, or reliability of our Services. LINKEDIN AND ITS AFFILIATES MAKE NO REPRESENTATION OR WARRANTY ABOUT THE SERVICES, INCLUDING ANY REPRESENTATION THAT THE SERVICES WILL BE UNINTERRUPTED OR ERROR-FREE, AND PROVIDE THE SERVICES (INCLUDING CONTENT AND INFORMATION) ON AN \\u201cAS IS\\u201d AND \\u201cAS AVAILABLE\\u201d BASIS. TO THE FULLEST EXTENT PERMITTED UNDER APPLICABLE LAW, LINKEDIN AND ITS AFFILIATES DISCLAIM ANY IMPLIED OR STATUTORY WARRANTY, INCLUDING ANY IMPLIED WARRANTY OF TITLE, ACCURACY OF DATA, NON-INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. 4.2 Exclusion of Liability These are the limits of legal liability we may have to you. TO THE FULLEST EXTENT PERMITTED BY LAW (AND UNLESS LINKEDIN HAS ENTERED INTO A SEPARATE WRITTEN AGREEMENT THAT OVERRIDES THIS CONTRACT), LINKEDIN, INCLUDING ITS AFFILIATES, WILL NOT BE LIABLE IN CONNECTION WITH THIS CONTRACT FOR LOST PROFITS OR LOST BUSINESS OPPORTUNITIES, REPUTATION (E.G., OFFENSIVE OR DEFAMATORY STATEMENTS), LOSS OF DATA (E.G., DOWN TIME OR LOSS, USE OF, OR CHANGES TO, YOUR INFORMATION OR CONTENT) OR ANY INDIRECT, INCIDENTAL, CONSEQUENTIAL, SPECIAL OR PUNITIVE DAMAGES. LINKEDIN AND ITS AFFILIATES WILL NOT BE LIABLE TO YOU IN CONNECTION WITH THIS CONTRACT FOR ANY AMOUNT THAT EXCEEDS (A) THE TOTAL FEES PAID OR PAYABLE BY YOU TO LINKEDIN FOR THE SERVICES DURING THE TERM OF THIS CONTRACT, IF ANY, OR (B) US $1000. 4.3 Basis of the Bargain; Exclusions The limitations of liability in this Section 4 are part of the basis of the bargain between you and LinkedIn and shall apply to all claims of liability (e.g., warranty, tort, negligence, contract and law) even if LinkedIn or its affiliates has been told of the possibility of any such damage, and even if these remedies fail their essential purpose. These limitations of liability do not apply to liability for death or personal injury or for fraud, gross negligence or intentional misconduct, or in cases of negligence where a material obligation has been breached, a material obligation being such which forms a prerequisite to our delivery of services and on which you may reasonably rely, but only to the extent that the damages were directly caused by the breach and were foreseeable upon conclusion of this Contract and to the extent that they are typical in the context of this Contract. 5. Termination We can each end this Contract, but some rights and obligations survive. Both you and LinkedIn may terminate this Contract at any time with notice to the other. On termination, you lose the right to access or use the Services. The following shall survive termination: Our rights to use and disclose your feedback; Members and/or Visitors\\u2019 rights to further re-share content and information you shared through the Services; Sections 4, 6, 7, and 8.2 of this Contract; Any amounts owed by either party prior to termination remain owed after termination. You can visit our Help Center to close your account. 6. Governing Law and Dispute Resolution In the unlikely event we end up in a legal dispute, depending on where you live, you and LinkedIn agree to resolve it in California courts using California law, Dublin, Ireland courts using Irish law, or in your local courts using local law. If you live in the Designated Countries, the laws of Ireland govern all claims related to LinkedIn's provision of the Services, but this shall not deprive you of the mandatory consumer protections under the law of the country to which we direct your Services where you have habitual residence. With respect to jurisdiction, you and LinkedIn agree to choose the courts of the country to which we direct your Services where you have habitual residence for all disputes arising out of or relating to this User Agreement, or in the alternative, you may choose the responsible court in Ireland. If you are a business user within the scope of Article 6(12) of the EU Digital Markets Act (\\u201cDMA\\u201d) and have a dispute arising out of or in connection with Article 6(12) of the DMA, you may also utilize the alternative dispute resolution mechanism available in the Help Center . For others outside of Designated Countries, including those who live outside of the United States: You and LinkedIn agree that the laws of the State of California, U.S.A., excluding its conflict of laws rules, shall exclusively govern any dispute relating to this Contract and/or the Services. You and LinkedIn both agree that all claims and disputes can be litigated only in the federal or state courts in Santa Clara County, California, USA, and you and LinkedIn each agree to personal jurisdiction in those courts 7. General Terms Here are some important details about the Contract. If a court with authority over this Contract finds any part of it unenforceable, you and we agree that the court should modify the terms to make that part enforceable while still achieving its intent. If the court cannot do that, you and we agree to ask the court to remove that unenforceable part and still enforce the rest of this Contract. This Contract (including additional terms that may be provided by us when you engage with a feature of the Services) is the only agreement between us regarding the Services and supersedes all prior agreements for the Services. If we don't act to enforce a breach of this Contract, that does not mean that LinkedIn has waived its right to enforce this Contract. You may not assign or transfer this Contract (or your membership or use of Services) to anyone without our consent. However, you agree that LinkedIn may assign this Contract to its affiliates or a party that buys it without your consent. There are no third-party beneficiaries to this Contract. You agree that the only way to provide us legal notice is at the addresses provided in Section 10. 8. LinkedIn \\u201cDos and Don\\u2019ts\\u201d LinkedIn is a community of professionals. This list of \\u201cDos and Don\\u2019ts\\u201d along with our Professional Community Policies limit what you can and cannot do on our Services. 8.1. Dos You agree that you will: Comply with all applicable laws, including, without limitation, privacy laws, intellectual property laws, anti-spam laws, export control laws, tax laws, and regulatory requirements; Provide accurate information to us and keep it updated; Use your real name on your profile; and Use the Services in a professional manner. 8.2. Don\\u2019ts You agree that you will not : Create a false identity on LinkedIn, misrepresent your identity, create a Member profile for anyone other than yourself (a real person), or use or attempt to use another\\u2019s account; Develop, support or use software, devices, scripts, robots or any other means or processes (including crawlers, browser plugins and add-ons or any other technology) to scrape the Services or otherwise copy profiles and other data from the Services; Override any security feature or bypass or circumvent any access controls or use limits of the Service (such as caps on keyword searches or profile views); Copy, use, disclose or distribute any information obtained from the Services, whether directly or through third parties (such as search engines), without the consent of LinkedIn; Disclose information that you do not have the consent to disclose (such as confidential information of others (including your employer)); Violate the intellectual property rights of others, including copyrights, patents, trademarks, trade secrets or other proprietary rights. For example, do not copy or distribute (except through the available sharing functionality) the posts or other content of others without their permission, which they may give by posting under a Creative Commons license; Violate the intellectual property or other rights of LinkedIn, including, without limitation, (i) copying or distributing our learning videos or other materials or (ii) copying or distributing our technology, unless it is released under open source licenses; (iii) using the word \\u201cLinkedIn\\u201d or our logos in any business name, email, or URL except as provided in the Brand Guidelines ; Post anything that contains software viruses, worms, or any other harmful code; Reverse engineer, decompile, disassemble, decipher or otherwise attempt to derive the source code for the Services or any related technology that is not open source; Imply or state that you are affiliated with or endorsed by LinkedIn without our express consent (e.g., representing yourself as an accredited LinkedIn trainer); Rent, lease, loan, trade, sell/re-sell or otherwise monetize the Services or related data or access to the same, without LinkedIn\\u2019s consent; Deep-link to our Services for any purpose other than to promote your profile or a Group on our Services, without LinkedIn\\u2019s consent; Use bots or other automated methods to access the Services, add or download contacts, send or redirect messages; Monitor the Services\\u2019 availability, performance or functionality for any competitive purpose; Engage in \\u201cframing,\\u201d \\u201cmirroring,\\u201d or otherwise simulating the appearance or function of the Services; Overlay or otherwise modify the Services or their appearance (such as by inserting elements into the Services or removing, covering, or obscuring an advertisement included on the Services); Interfere with the operation of, or place an unreasonable load on, the Services (e.g., spam, denial of service attack, viruses, gaming algorithms); and/or Violate the Professional Community Policies or any additional terms concerning a specific Service that are provided when you sign up for or start using such Service, and the Bing Maps terms where applicable. 9. Complaints Regarding Content Contact information for complaint about content provided by our Members. We respect the intellectual property rights of others. We require that information posted by Members be accurate and not in violation of the intellectual property rights or other rights of third parties. We provide a policy and process for complaints concerning content posted by our Members. 10. How To Contact Us Our Contact information. Our Help Center also provides information about our Services. For general inquiries, you may contact us online . For legal notices or service of process, you may write us at these addresses . LinkedIn \\u00a9 2024 About Accessibility User Agreement Privacy Policy Cookie Policy Copyright Policy Brand Policy Guest Controls Community Guidelines \\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629 (Arabic) \\u09ac\\u09be\\u0982\\u09b2\\u09be (Bangla) \\u010ce\\u0161tina (Czech) Dansk (Danish) Deutsch (German) \\u0395\\u03bb\\u03bb\\u03b7\\u03bd\\u03b9\\u03ba\\u03ac (Greek) English (English) Espa\\u00f1ol (Spanish) Suomi (Finnish) Fran\\u00e7ais (French) \\u0939\\u093f\\u0902\\u0926\\u0940 (Hindi) Magyar (Hungarian) Bahasa Indonesia (Indonesian) Italiano (Italian) \\u65e5\\u672c\\u8a9e (Japanese) \\ud55c\\uad6d\\uc5b4 (Korean) \\u092e\\u0930\\u093e\\u0920\\u0940 (Marathi) Bahasa Malaysia (Malay) Nederlands (Dutch) Norsk (Norwegian) \\u0a2a\\u0a70\\u0a1c\\u0a3e\\u0a2c\\u0a40 (Punjabi) Polski (Polish) Portugu\\u00eas (Portuguese) Rom\\u00e2n\\u0103 (Romanian) \\u0420\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439 (Russian) Svenska (Swedish) \\u0c24\\u0c46\\u0c32\\u0c41\\u0c17\\u0c41 (Telugu) \\u0e20\\u0e32\\u0e29\\u0e32\\u0e44\\u0e17\\u0e22 (Thai) Tagalog (Tagalog) T\\u00fcrk\\u00e7e (Turkish) \\u0423\\u043a\\u0440\\u0430\\u0457\\u043d\\u0441\\u044c\\u043a\\u0430 (Ukrainian) Ti\\u1ebfng Vi\\u1ec7t (Vietnamese) \\u7b80\\u4f53\\u4e2d\\u6587 (Chinese (Simplified)) \\u6b63\\u9ad4\\u4e2d\\u6587 (Chinese (Traditional)) Language\"}]}\n",
      "\u001b[32m---POSSIBLE SUB REDDITS---\u001b[0m\n",
      "AI automation, RAG chatbots, custom AI applications, business growth solutions, Telegram bots\n",
      "\u001b[32m\n",
      "\n",
      " ---SUB-REDDITS SELECTOR---\u001b[0m\n",
      "LangChain, aiautomationagencies, automation\n",
      "\u001b[32m\n",
      "Sub Reddits:\n",
      "\n",
      " LangChain, aiautomationagencies, automation \u001b[0m\n",
      "\u001b[32m\n",
      "---COMPETITION WEB SUMMARY---\u001b[0m\n",
      "\n",
      "Scraping https://tovie.ai/ai-consulting\n",
      "121\n",
      "105\n",
      "{\"URL\": \"https://tovie.ai/ai-consulting\", \"text\": [{\"source\": \"https://tovie.ai/ai-consulting\", \"content\": \"AI Consulting for Enterprise | Tovie AI Solutions GenAI Agents Generative AI On-Prem for enterprise reinvention Data Agent for data discovery Data Mask for data masking Generative AI Consulting for fast AI adoption ML Place for LLM hosting and training AI Bots Voice Bots for Contact centres \\u0421hatbots for customer support Success Stories BNP Paribas Cardif insurance bot for call center Philip Morris retail bot for call centre Jardim Exotico retail bot for website Bradwell B nuclear power bot for website Dodo Pizza food tech bot for call centre Royal Institute of Navigation web navigator bot Kodland bot for contact centre Blog Company About Partner Program Press Room Tovie AI Code of Ethics Contacts Contact us GenAI Agents Generative AI On-Prem For enterprise reinvention Data Agent For data discovery Data Mask For data masking Generative AI Consulting For fast AI adoption ML Place For LLM hosting and training AI Bots Voice Bots For contact centres \\u0421hatbots For customer support Success Stories BNP Paribas Cardif Philip Morris Jardim Exotico Bradwell B Dodo Pizza Royal Institute of Navigation Kodland Blog Company About Partner Program Press Room Tovie AI Code of Ethics Contacts Contact us Generative AI Consulting for\\u00a0Enterprise Boost business efficiency and fast-track innovation with\\u00a0our\\u00a0AI\\u00a0consulting\\u00a0services Talk to an expert Talk to an expert Generative AI Discovery with Tovie Harness the power of Generative AI to outperform competitors and fast-track your company's digital transformation. An AI consulting project with Tovie AI will showcase the practical applications and true potential of this technology for your teams What can Tovie\\u2019s artificial intelligence consulting services do for your business? We take AI out of its black box and demonstrate how Large Language Models (LLMs) will benefit your business, focusing on automation, efficiency, and cost reduction. We'll guide you in leveraging GenAI and getting maximum value. AI consultancy is pivotal in bridging the gap between the potential of artificial intelligence and its fast practical application within a business context. Companies across industries, from finance to healthcare and telecom already leverage a range of use cases to capture the AI value creation potential. At Tovie AI, our team of experts can help you design a tailored AI strategy that aligns with your goals and aspirations. Whether you want to begin with a small project or aim for something bigger, we can help you. Let us know what you need, and we'll create a\\u00a0customised path for your organisation Contact us This is what your AI business consulting with Tovie AI will\\u00a0look like 01 AI application discovery During the discovery phase, we initiate a series of workshops involving stakeholders and teams. Our aim is to share our knowledge about Generative AI applications and help your company in mapping potential AI use cases. The brainstorming sessions are conducted for different departments to ensure that LLMs bring the most value across teams. 02 Pilot project definition We evaluate the proposed use cases by comparing their complexity, delivery speed, and costs. We then shortlist AI applications that can make the most significant impact across various teams in your organisation. Only carefully selected and customised use cases proceed to the application phase. 03 Pilot run and business case production We initialise by deploying the pilot using cloud infrastructure and running it for\\u00a0three months. Following the pilot phase, we present a comprehensive business case to support future production deployment. We help you learn how to orchestrate the technology effectively and derive maximum benefit from it. 04 Generative AI implementation Our team will help you deploy Generative AI applications in your infrastructure with minimal disruptions and maximum benefits. This ensures a hassle-free utilisation of AI capabilities. Tovie AI empowers organisations to leverage LLMs securely and responsibly with our comprehensive suite of AI tools tailored to your specific needs. As a result, you get powerful tools for your business performance improvement within your teams. Tovie Generative AI offering Generative AI on-premise Data Agent for data discovery Data Mask for privacy and security Reports&Research Reports&Research Learn more about our approach in Generative AI consulting services and discover the most popular use cases in enterprise. Download our free guide! Get your copy Partner with Tovie AI to\\u00a0accelerate your AI transformation Extensive experience in Generative and Conversational AI Scalable solutions to address enterprise business challenges Robust in-house technology ecosystem Flexible and secure AI model-agnostic approach Compliant & Validated for Security with IBM We are one of the first Conversational AI vendors to be validated by IBM Cloud for Financial Services. All our conversational solutions are now automatically compliant for FS organisations. Learn more Some of our clients that succeeded with\\u00a0Generative AI consulting Do you want to implement Generative AI in\\u00a0your team but don't know how to start and ensure its secure usage? Contact us for artificial intelligence business consulting Contact us Business leaders recognise the significance of this moment. They can see how LLMs and Generative AI will fundamentally transform everything from business, to science, to society itself\\u2014unlocking new performance frontiers. Accenture \\u201cEnterprises are migrating from early experimentation to deploying Generative AI use cases in production\\u201d A16z research on the developments of Generative AI in enterprise The rapid development of Generative AI and the accessibility of new technologies for users have made AI popular and widely discussed. Generative AI is already reshaping entire industries. However, to secure leading positions in\\u00a0markets five years from now, companies must adopt a focused AI strategy centred on exploring, testing, and analysing new applications of LLMs in business. As we've seen, until recently, AI applications in enterprise settings were limited to a few obvious use cases. However, the situation is changing significantly as attitudes and resource allocation shift towards GenAI. The range of use cases deployed is expanding, and more workloads are transitioning from early experimentation to production. AI strategy consulting helps companies be the first to implement new AI tools and ensure their competitiveness in the market. Enhanced productivity Automated routine Higher employee satisfaction Reduced costs Improved decision-making Discover the latest insights and trends in Generative AI for enterprises Skyrocketing budgets Budgets for AI implementation have tripled in 2024 compared to the previous year. On average, companies are now spending two to five times more on LLMs, with an expected annual average spend of $18 million. This increase in spending is reflected in the allocation of resources to permanent software budget lines, indicating that companies are prioritising their investment in AI technology. Multi-model approach Enterprises are now using multiple AI models instead of relying solely on popular LLMs from OpenAI, Google or other providers. By utilising multiple models, including both proprietary and open-source options, companies can customise solutions to suit specific needs. At Tovie AI, we advocate for a multi-model approach that enables leveraging the latest AI advancements and reduces dependence on single providers. AI for internal use cases Businesses prioritise implementing internal use cases before customer-facing ones. One of the most popular internal use cases is internal data search. Tovie AI addresses this need with Data Agent, a Generative AI chatbot designed to access company databases seamlessly. The bot is capable of efficiently handling various file types and sources for easy internal data retrieval. Learn more Security and privacy concerns Companies\\u2019 top AI-related concerns include privacy, data security, and reliability. To mitigate the risks and ensure enterprise-grade privacy and protection for your proprietary data, Tovie AI offers a Generative AI on-premise deployment and sensitive data masking tool. Higher employee productivity and work quality According to the 2024 AI Index Report , AI can boost productivity speed by 25% and improve work quality by 40% in certain roles. Moreover, access to AI seems to help bridge the performance disparity between low- and high-skilled workers, making tasks more efficient and consistent across skill levels. More industries impacted Generative AI will impact various industries, including consumer services, finance, public services and healthcare. As this technology matures and organisations continue to integrate it for business advantage, we can anticipate the emergence of increasingly impressive and compelling use cases across different sectors. Contact us What are the most popular use cases in enterprises? 62 % Text summarisation 60 % Enterprise knowledge management 59 % Customer service 53 % Marketing copy 53 % Software development 45 % Contract review The most high-impact use cases across major industries Consumer Services Financial Services and Banking Energy and Industrial Sector Public Services Healthcare Tech, Media & Telecoms Consumer services encompass various industries, such as retail, automotive, travel, transportation, and others. For businesses operating in these sectors, Generative AI offers significant potential for enhancing customer interactions. The potential applications include assisting consumers in understanding and locating products, providing more responsive and real-time support, and fostering brand loyalty. As Generative AI becomes increasingly accessible, companies will further explore its potential applications and deployments to drive benefits. In financial services and banking, integrating Generative AI holds great potential. It can improve tasks like sentiment analysis, customer analytics, and personalised product offerings. This integration also helps streamline operations and enhance data analysis. Incorporating Generative AI into a company's technology stack and AI initiatives is now becoming a priority in the financial services industry. Companies in this industry encounter energy security, affordability, profitability, and sustainability challenges. Utilising Generative AI can help address these issues by enhancing cost-effectiveness, operational efficiency, resilience, and reducing emissions. Despite initial hesitance, early adoption of AI tools can offer a competitive edge. Partnering with an AI consulting company enables industrial businesses to leverage new benefits and manage risks effectively. Generative AI in public services can transform government-citizen interactions and streamline workforce tasks. It enables more personalised communication, tailored solutions, and data-driven decisions, enhancing citizen services and optimising public funds. Using a Generative AI-powered chat function can also improve procurement processes, providing real-time information on contractor qualifications and contracts. This advancement propels the public sector's adoption of cutting-edge AI technologies. Generative AI holds the potential to enhance efficiency, speed, connectivity, and innovation for improved patient care and health outcomes. It can boost operational performance by increasing employee productivity and offering hyper-personalised experiences to patients, customers, and employees. Integrating Generative AI into a healthcare organisation's technology ecosystem can provide valuable insights by Streamlining clinical documentation and healthcare operations and even enhancing medical training. The Tech, Media & Telecoms industry, abundant in data, is poised for digitisation but needs help managing and analysing vast information. Generative AI is the key technology for these companies, irrespective of their AI maturity level, enabling accelerated digital transformation and unlocking new possibilities. Consumer Services Consumer services encompass various industries, such as retail, automotive, travel, transportation, and others. For businesses operating in these sectors, Generative AI offers significant potential for enhancing customer interactions. The potential applications include assisting consumers in understanding and locating products, providing more responsive and real-time support, and fostering brand loyalty. As Generative AI becomes increasingly accessible, companies will further explore its potential applications and deployments to drive benefits. Financial Services and Banking In financial services and banking, integrating Generative AI holds great potential. It can improve tasks like sentiment analysis, customer analytics, and personalised product offerings. This integration also helps streamline operations and enhance data analysis. Incorporating Generative AI into a company's technology stack and AI initiatives is now becoming a priority in the financial services industry. Energy and Industrial Sector Companies in this industry encounter energy security, affordability, profitability, and sustainability challenges. Utilising Generative AI can help address these issues by enhancing cost-effectiveness, operational efficiency, resilience, and reducing emissions. Despite initial hesitance, early adoption of AI tools can offer a competitive edge. Partnering with an AI consulting company enables industrial businesses to leverage new benefits and manage risks effectively. Public Services Generative AI in public services can transform government-citizen interactions and streamline workforce tasks. It enables more personalised communication, tailored solutions, and data-driven decisions, enhancing citizen services and optimising public funds. Using a Generative AI-powered chat function can also improve procurement processes, providing real-time information on contractor qualifications and contracts. This advancement propels the public sector's adoption of cutting-edge AI technologies. Healthcare Generative AI holds the potential to enhance efficiency, speed, connectivity, and innovation for improved patient care and health outcomes. It can boost operational performance by increasing employee productivity and offering hyper-personalised experiences to patients, customers, and employees. Integrating Generative AI into a healthcare organisation's technology ecosystem can provide valuable insights by Streamlining clinical documentation and healthcare operations and even enhancing medical training. Tech, Media & Telecoms The Tech, Media & Telecoms industry, abundant in data, is poised for digitisation but needs help managing and analysing vast information. Generative AI is the key technology for these companies, irrespective of their AI maturity level, enabling accelerated digital transformation and unlocking new possibilities. Generative AI offers a wide range of applications across different modalities GenAI tools are versatile and can create various forms of content, including text, images, videos, audio, and code. Businesses are actively developing applications to address use cases across these domains. Below is a non-exhaustive list Generative AI applications for content creation Modality Application 1. Text Content writing Chatbots or assistants Search Analysis and synthesis 2. Code Code generation Application prototype and design Data set generation 3. Image Stock image generator Image editor 4. Audio Text to voice generation Sound creation Audio editing 5. 3-D or other 3-D object generation Product design and discovery 6. Video Video creation Video editing Voice translation and adjustments Face swaps and adjustments Modality Application Do you want to explore Generative AI more deeply and learn about its training and use cases in various industries? Download our free whitepaper Excited about AI but overwhelmed by the technical jargon? AI has become mainstream thanks to ChatGPT and other tools based on Large Language Models. At Tovie AI, we are eager to share our knowledge about this technology with you. Our whitepaper demystifies LLMs and shows how Generative AI can change the game in business and everyday life. We will explain what Generative AI is, how it is trained, where it is used, how the main generative models are structured, and what industry use cases are. Let\\u2019s explore it together! Reports&Research AI Revolution 2.0 LLMs + GPT: History, types, and impact on the world around us Get your copy Are you interested in AI integration and consulting? Schedule a call with our team to learn more Contact us FAQs What is AI consulting? AI consulting is a service we provide to showcase the practical applications and potential of Generative AI in business. Our goal is to help companies integrate this innovative technology into their operations. We offer expert guidance, insights, and support to enhance products, services, and processes using AI. We highlight the benefits of Large Language Models (LLMs) for your business, focusing on automation, efficiency, and cost reduction. We aim to demonstrate how to leverage Generative AI effectively and maximise its value. How to implement Generative AI in our company? By leveraging the capabilities of large language models, enterprises can streamline their operations and improve their overall efficiency. Among the top applications of LLMs in the Enterprise are document search chatbot, personalised employee training, routine automation, and data analysis. How to implement LLM for business? Generative AI is an innovative technology that business leaders are keen to adopt to improve customer and employee experiences. These tools have shown potential in boosting productivity and reducing costs for organisations. While the capabilities of Generative AI tools are impressive, many companies are uncertain about how to incorporate them into their operations. Our advice to company executives is to focus on understanding how AI will transform their workflow and making strategic decisions to navigate this change effectively. A practical approach is to start with a small pilot project in a single team to assess the benefits of Generative AI and estimate the associated costs. It is essential to short-list specific use cases that address real business challenges. Collaborating with an artificial intelligence consulting company like Tovie AI can accelerate the process of implementing AI innovation within your enterprise. How to use LLMs in an enterprise? Integrating Large Language Models (LLMs) in your business can boost innovation and efficiency. To succeed in this transition, involve stakeholders from various areas and align them with your strategic objectives. Companies can customise LLMs with their data to create a personalised AI chatbot for diverse tasks. There are two methods for adapting LLMs: fine-tuning and in-context learning, each having its benefits. Next, integrate and deploy the customised model into your business workflows. If you partner Tovie AI, our experts in AI management consulting will identify integration requirements and create APIs for seamless interaction with existing systems. Be prepared for potential changes in processes and workflows when implementing LLMs. Develop a plan to manage these changes and train employees on using the new tools effectively. Explore our blog for a detailed guide on integrating LLMs in business settings. What do AI consultants do? AI consultants assist clients in maximising their business potential through the adoption of artificial intelligence solutions. They assess client business processes to pinpoint AI integration opportunities, analyse costs, and develop AI strategies for enterprise innovation. The role of an AI consulting firm also includes monitoring AI system performance, evaluating risks, and devising mitigation strategies. Overall, AI consultancy services help businesses harness the power of AI for strategic growth and efficiency. What industries can benefit from AI consulting services? Industries like finance, retail, healthcare and pharmaceuticals, manufacturing, and logistics, to name a few, are poised to be significantly influenced by AI. Any business aiming to enhance efficiency, streamline operations, or stay competitive can benefit from AI consulting services. According to some estimates, Large Language Models (LLMs) could impact up to 40% of working hours. AI models are a powerful tool for processing and understanding human language, enabling tasks like language translation, text summarisation, and question answering. The adoption of AI tools is expanding across sectors, with new solutions regularly emerging. Companies must invest in digital transformation and AI innovation to remain competitive and leverage cutting-edge solutions. How can AI consulting services help my business? If you consider integrating Generative AI into your company and need assistance selecting the appropriate tools, embarking on an AI business consultancy project can be a valuable initial step. Tovie AI can help you evaluate your readiness for implementing AI, find areas where you can improve efficiency through AI, and identify valuable opportunities together with your teams. We also provide expertise in data management, machine learning, and automation to enhance your business operations and outcomes. What is the process of deploying AI services? The deployment of AI services involves a structured two-phase approach: 1. Discovery Phase: - During this phase, we engage with your stakeholders to explore potential AI applications suitable for your company's workflows. - We evaluate various use cases and select the most promising one that offers significant outcomes across different teams and delivers economic value. - We present our recommendations and conclude the discovery phase by gathering stakeholder feedback on the selected use case, obtaining approval, and developing a project plan for implementation. 2. Implementation Phase: - In the second phase, we implement the chosen use case using the Tovie conversational AI platform. - The pilot project runs for three months with the relevant team to test the solution in a real-world setting. - After the pilot, we present a detailed business case to support the future deployment of the AI service for production use. What is the cost of AI consulting? The cost of consulting services is determined by various factors, such as the project's scope, the complexity of the AI solution required, and the level of support needed. We recommend you contact us directly for a personalised quote. How long does it typically take to complete a consulting project? The timeline of a Generative AI consultancy project is influenced by its scope, complexity, and the business's preparedness for AI integration. Usually structured in two phases. During the discovery phase, we conduct workshops with stakeholders and teams to introduce Generative AI applications and identify potential use cases. In the second phase, we implement the chosen use case. The pilot project runs for three months with the relevant team to test the solution in a real business setting. The post-pilot phase involves presenting a detailed business case to support the future deployment of the AI service for production use. What kind of AI solutions do you provide? Tovie AI offers a range of AI solutions, including voice and text bots and agents powered by Generative AI. These solutions are designed for enterprises to enhance customer service and increase employee engagement. At Tovie AI, we leverage Generative and Conversational AI technologies to drive business growth and efficiency. Our emphasis is on automation and enhancing customer experiences, recognising language-based AI as critical in unlocking enterprise potential. Through our advanced tools for Natural Language Processing, speech synthesis, and dialogue management, businesses can customise their branding and establish deeper connections with customers. What experience do you have in implementing AI solutions? We have extensive experience in implementing AI solutions at Tovie AI. We focus on developing scalable enterprise solutions to enhance customer service and employee engagement. With over 100 enterprise customers utilising our cloud platforms and more than 100 developers utilising our low-code visual studio, we are a UK-based company with established technologies, global clients and expert partners. Our expertise lies in offering Conversational AI solutions validated by IBM Cloud for Financial Services , a proprietary Conversational AI Cloud , and a full-stack Platform for process orchestration. Our track record showcases successful AI implementations that drive business growth and innovation. Does Tovie AI have any Generative AI products? Tovie AI enables organisations to harness Large Language Models securely and responsibly through a tailored suite of AI tools that cater to specific needs. The GenAI product line from Tovie AI includes: 1. ML Place: - A platform for aggregating, hosting, operating, and retraining ML services and neural models. It offers a range of ready-to-use generative models accessible via API and SDK. 2. Data Agent: - A powerful GenAI tool that integrates multiple data sources and modalities. It provides accurate and contextually relevant responses across companies' data and knowledge bases. 3. Tovie CoPilot: - Locally deployed interfaces and access APIs to LLMs and other models, replacing cloud-based LLM interfaces like ChatGPT. CoPilot offers a user-friendly interface for employees to engage with AI applications customised for the company. 4. Data Mask: - A secure gateway within the company's perimeter, filtering and masking sensitive data before transmitting to LLMs. The tool maintains semantic coherence and session context while ensuring data security and privacy. What kind of AI technologies does Tovie AI specialise in? Tovie AI specialises in various AI technologies to support your needs, from implementing small-scale pilots to full-scale enterprise AI solutions. Our robust tools for Natural Language Processing (NLP), speech synthesis, and dialogue management help businesses personalise their brand and connect more deeply with customers. Our end-to-end solutions, including a precise NLP engine and tailored analytical reports, ensure effective market navigation and investment maximisation. As a central part of our offering, we provide comprehensive Generative AI consulting services. We create and integrate custom ML models into client workflows, promoting quick innovation, efficient problem-solving, and collaboration. Key areas of specialisation include: - Enterprise Conversational AI and Machine Learning/NLP SaaS platforms - Advanced Large Language Model (LLM) frameworks such as Tovie Co-Pilot and Tovie Data Agent - Expertise in conversational design and user experience. With a focus on cutting-edge technologies and deep expertise in LLMs , Tovie AI is the ideal partner for driving AI discovery and implementation. What measures does your AI consulting agency take to ensure data security? At Tovie AI, we take extensive measures to ensure data security and compliance with privacy regulations in our consulting services. As an accredited IBM Silver Partner specialising in Conversational AI solutions for clients in the Financial Services sector, we prioritise the protection of our clients' data. Through our partnership with IBM, we empower organisations to securely deploy and manage certified software across various environments, including public and private, cloud, and on-premises setups. This approach allows our clients to drive meaningful change while complying with government regulations. In our Generative AI solutions, we provide the Data Mask tool, acting as a privacy firewall for Large Language Models (LLMs). This tool anonymises sensitive data when interacting with cloud-based AI models like GPT, ensuring the protection of sensitive information. The Data Mask tool integrates customisable filters and alert systems, enabling the secure use of AI without disrupting business operations by obscuring sensitive details in data queries. We believe in minimising the risk of data breaches when utilising neural networks and external LLMs by implementing a data analysis gateway that substitutes sensitive information with fictional but contextually consistent data. For further details on our data security practices, please contact our team or visit our website . How to use AI in consulting? AI in consulting can help connect the technical aspects with the strategic requirements of a business. AI based consulting assists in identifying opportunities for AI integration and in creating and implementing solutions that foster innovation, efficiency, and competitive edge. The primary objective is to analyse the company's processes, pinpoint areas for AI enhancement, and develop customised AI solutions for the client's strategic goals. Does Tovie AI offer a support service after implementing an AI solution? Our team delivers support post-implementation, including performance monitoring, regular maintenance, updates, and training for your team. Additionally, we provide adoption assistance and technical support to guarantee the enduring success of your organisation's AI implementation. I don't believe in consulting. How can I ensure I get the results I need? To make the best decisions about using Generative AI and avoid unnecessary expenses, seek experts who can evaluate your business processes and AI readiness. Generative AI consulting, especially from experienced technology vendors, can be valuable. Tovie AI specialises in AI solutions consulting tailored to your company's needs. Our experts collaborate with your teams to identify the most beneficial applications of Generative AI. We will help unleash the full potential of LLMs and determine where this cutting-edge technology can add the most value. We will help you integrate AI tools across your organisation effectively, guiding you on how to maximise the benefits of this technology within your business processes. This way, you can rest assured that you will receive powerful tools to enhance your business performance within your teams. Please fill in the form to get your free copy Name Company E-mail I'd like to receive Tovie AI's newsletter for industry insights and product news By ticking this box, I agree that Tovie AI may use my information in accordance with its Privacy Policy Download Thanks! Download PDF Sign up to our newsletter Sign me up By ticking this box, I agree that Tovie AI may use my information in accordance with its Privacy Policy . We create solutions and tools to make any conversational experience smooth Solutions Voice Bots \\u0421hatbots Generative AI On-Prem Mobile PA Shop Assistant Debt Collections Bot Hospitality Assistant Insurance Claims Bot Call-Back Assistant Bank Assistant E-Government Solutions Data Agent Data Mask Generative AI Consulting ML Place Industries Financial Services Healthcare Contact Centres Retail Tools Tovie Platform Tovie Cloud Success stories BNP Paribas Cardif Philip Morris Dodo Pizza Bradwell B Jardim Exotico RIN Kodland Company About us Partner Program Press Room Tovie AI Code of Ethics Contacts Blog Glossary of terms Legal GDPR Privacy policy Cookies policy License Agreement Tovie AI Limited. All rights reserved. \\u00a9 2024 | 128 City Road London EC1V 2NX | +44 20 4577 1007 Get a demo Please tell us about yourself and we\\u2019ll get back as soon as we can. Name Business email Company name Work phone Message I'd like to receive Tovie AI's newsletter for industry insights and product news By ticking this box I understand and agree that Tovie AI may use my information in accordance with its Privacy Policy Send Contact Us Please, fill in the form and we will contact you shortly. Name Business email Company name Message I'd like to receive Tovie AI's newsletter for industry insights and product news By ticking this box I understand and agree that Tovie AI may use my information in accordance with its Privacy Policy Send Thank you for joining our newsletter. Thank you for reaching out! We appreciate you contacting Tovie AI and will get back to you as soon as we can. Obrigado por estender a\\u00a0m\\u00e3o! Agradecemos o seu contato e entraremos em contato o mais r\\u00e1pido poss\\u00edvel. Thank you for reaching out! We appreciate you contacting Tovie AI and will get back to you as soon as we can. We use cookies to provide necessary website functionality, improve your experience and analyze our traffic. By using this website, you agree to our Cookies Policy and Privacy Policy Accept\"}, {\"source\": \"https://tovie.ai\", \"content\": \"Tovie AI: Generative AI and on-prem LLMs for Enterprise Solutions GenAI Agents Generative AI On-Prem for enterprise reinvention Data Agent for data discovery Data Mask for data masking Generative AI Consulting for fast AI adoption ML Place for LLM hosting and training AI Bots Voice Bots for Contact centres \\u0421hatbots for customer support Success Stories BNP Paribas Cardif insurance bot for call center Philip Morris retail bot for call centre Jardim Exotico retail bot for website Bradwell B nuclear power bot for website Dodo Pizza food tech bot for call centre Royal Institute of Navigation web navigator bot Kodland bot for contact centre Blog Company About Partner Program Press Room Tovie AI Code of Ethics Contacts Contact us GenAI Agents Generative AI On-Prem For enterprise reinvention Data Agent For data discovery Data Mask For data masking Generative AI Consulting For fast AI adoption ML Place For LLM hosting and training AI Bots Voice Bots For contact centres \\u0421hatbots For customer support Success Stories BNP Paribas Cardif Philip Morris Jardim Exotico Bradwell B Dodo Pizza Royal Institute of Navigation Kodland Blog Company About Partner Program Press Room Tovie AI Code of Ethics Contacts Contact us Tovie AI - your digital transformation partner for Conversational and Generative AI automation Contact us Enhancing productivity and scaling operations with\\u00a0Generative AI Generative AI Applications Deploy GenAI solutions safely on-premise or in your company's private cloud Learn more LLM-Based Search Simplify data access with RAG-based search for fast, accurate, and conversational results Learn more Generative AI Consulting Identify the best AI application for your business goals with our industry-specific knowledge Learn more Ensuring compliance and security with IBM Tovie AI\\u2019s conversational AI solutions for Financial Services are validated and available on the IBM Cloud for Financial Services\\u00ae. Learn more Guiding companies to success Streamlining AI adoption into business workflows Anticipating enterprise needs for AI Tailored for enterprises\\u2019 AI-centric strategic initiatives, we predict and mitigate pain points, developing scalable solutions to\\u00a0overcome business challenges Simplifying in-house development Our tooling is designed to facilitate the easy transition of GenAI development in-house, ensuring quicker and smoother adoption processes Optimising enterprise data usage By reimagining the core workflows of enterprises, we assist them in leveraging their proprietary data more effectively, leading to optimised operations and value\\u00a0creation Driving business innovation and growth with Generative AI Our team excels in Generative AI, supporting clients in effectively implementing this breakthrough technology Learn more Reports&Research Discover how our consulting experts can help maximise your business's potential with Generative AI. Download our free guide today. Get your copy Enhancing e-government with cutting-edge AI technology Transform your digital public services with AI-driven solutions that enhance efficiency and provide seamless multi-channel experiences for citizens Discover how our AI solutions can modernise your e-government elevate your e-government services with our innovative AI solutions. Contact us today to reduce costs, streamline operations, and enhance citizen satisfaction Learn more Revolutionising businesses with Generative\\u00a0AI See what the media is saying about us 2024 State of AI in the Speech Technology Industry: AI\\u2019s Impact on Natural Language Processing Transform Your Data Landscape: How Businesses Are Winning with Generative AI Tovie AI partners with Richmond & Wandsworth Councils to improve adult and social care outreach for residents Partnering with industry leaders Digital services and consulting, Worldwide Visit website Conversational AI solutions, Europe Visit website IBM Cloud for Financial Services validation for Tovie\\u00a0Ai Visit website Partner with us to expand your business opportunities Learn more Large Language Models are revolutionising the data-centric world, enhancing real-time engagements and workflows, making them vital for innovative enterprises. Harnessing our extensive expertise in AI, we're ready to contribute our best practices and valuable experiences to the global community. Tovie AI Team Converting complexity into clarity Generative AI enhances decision-making by analysing extensive data for summaries, insights, and predictive models and creating novel data points and content, transforming data management across sectors Explore Tovie AI's Data Agent to innovate your business's data handling Discover Data Agent Fostering trust in customer relationships Tovie tools make a difference for retailers in e-commerce. It is efficient, easy to handle, and provide a part of the service, ensuring that the customer does not leave a home page with doubts. Camila Balegre Founder of Jardim Ex\\u00f3tico The chatbot has been an engaging and eye-catching way to encourage website visitors to explore the project information. The monthly summary reports allow the project team to understand what our visitors are interested in, allowing us to tailor future communications to them. Olivia White PCM, Bradwell B The first benefit we are seeing from Tovie AI\\u2019s implementation is more insights into what our website visitors are looking for. The implementation was hassle-free and Tovie AI has integrated easily into our existing front-end and back-end systems. John Pottle RIN Director The innovative AI assistant implemented by Tovie AI is a game-changer that provides 24/7 support and positively impacts our educational platform's user experience. We plan to add an animated avatar and leverage Generative AI, setting the stage for an even more interactive and effective user experience. Orlando Powell WizdomCRM Please fill in the form to get your free copy Name Company E-mail I'd like to receive Tovie AI's newsletter for industry insights and product news By ticking this box, I agree that Tovie AI may use my information in accordance with its Privacy Policy Download Thanks! Download PDF Sign up to our newsletter Sign me up By ticking this box, I agree that Tovie AI may use my information in accordance with its Privacy Policy . We create solutions and tools to make any conversational experience smooth Solutions Voice Bots \\u0421hatbots Generative AI On-Prem Mobile PA Shop Assistant Debt Collections Bot Hospitality Assistant Insurance Claims Bot Call-Back Assistant Bank Assistant E-Government Solutions Data Agent Data Mask Generative AI Consulting ML Place Industries Financial Services Healthcare Contact Centres Retail Tools Tovie Platform Tovie Cloud Success stories BNP Paribas Cardif Philip Morris Dodo Pizza Bradwell B Jardim Exotico RIN Kodland Company About us Partner Program Press Room Tovie AI Code of Ethics Contacts Blog Glossary of terms Legal GDPR Privacy policy Cookies policy License Agreement Tovie AI Limited. All rights reserved. \\u00a9 2024 | 128 City Road London EC1V 2NX | +44 20 4577 1007 Get a demo Please tell us about yourself and we\\u2019ll get back as soon as we can. Name Business email Company name Work phone Message I'd like to receive Tovie AI's newsletter for industry insights and product news By ticking this box I understand and agree that Tovie AI may use my information in accordance with its Privacy Policy Send Contact Us Please, fill in the form and we will contact you shortly. Name Business email Company name Message I'd like to receive Tovie AI's newsletter for industry insights and product news By ticking this box I understand and agree that Tovie AI may use my information in accordance with its Privacy Policy Send Thank you for joining our newsletter. Thank you for reaching out! We appreciate you contacting Tovie AI and will get back to you as soon as we can. Obrigado por estender a\\u00a0m\\u00e3o! Agradecemos o seu contato e entraremos em contato o mais r\\u00e1pido poss\\u00edvel. Thank you for reaching out! We appreciate you contacting Tovie AI and will get back to you as soon as we can. We use cookies to provide necessary website functionality, improve your experience and analyze our traffic. By using this website, you agree to our Cookies Policy and Privacy Policy Accept\"}]}\n",
      "**Company Name**: Tovie AI\n",
      "\n",
      "**Product/Service Offerings**: Tovie AI provides a range of AI consulting services and solutions, including:\n",
      "- Generative AI consulting for enterprise transformation\n",
      "- On-premise Generative AI solutions\n",
      "- Data Agent for data discovery\n",
      "- Data Mask for data privacy and secu\n",
      "\u001b[32m\n",
      "---MARKET RESEARCHER---\u001b[0m\n",
      "Scraping subreddit: LangChain\n",
      "Scraping subreddit: aiautomationagencies\n",
      "Scraping subreddit: automation\n",
      "[\"Hello LangChain.  We're all set to start at the top of the hour - welcome to the AMA.  Thanks to Harrison for participating, I know we've got a lot of LangChain ideas to share!\", 'Are you planning on release an LTS or stable version? Atm, using Langchain is quite hit or miss based on the version', 'Why are the docs so hard to read? This is a genuine question and not a complaint disguised as a question', \"I've primarily learned about Langchain through YouTube, in addition to the official documentation. Do you have any channel recommendations that offer deep insights into its usage and applications?\", 'Are there ways to invest capital in Langchain pre-ipo?', '[I submitted a PR](https://github.com/langchain-ai/langchain/pull/7916) for a new text splitter because the recursive text splitter doesn\\'t chunk evenly.\\n\\n> Unless the total token count of a document is evenly divisible by the chunk_size param, you will always get a final chunk that is smaller than chunk_size. And in many cases it\\'s too small to be useful, so it\\'s essentially chopping the end off of most documents.\\n\\nPR wasn\\'t accepted because adding an additional splitter with similar functionality to the current one was not correct. Which is fair. Since then [I rewrote my original PR using a DFS method](https://github.com/ShelbyJenkins/shelby_as_a_service/blob/82fad422f5127d09377d4b4a8a5cc6fc2b8bad24/shelby_as_a_service/services/text_processing/chunk.py#L1) which produces equally sized chunks without any performance issues.\\n\\n\\nMy question is: I\\'m still interested in adding my updates to Langchain, but I\\'m also unsure if completely rewriting a core functionality (the recursive text splitter) of the package is the right path. Is there another way forward?\\n\\nAlso, were you at the Pinecone convention in SF a few months ago? If so, I may have asked if you were \"the guy.\"', 'What is the business model for Langchain?', 'Are there any plans to support other languages besides python and JavaScript?', 'A lot of people look at LangChain and think they can make Jarvis from Iron Man. Is this directionally the type of thing you envision LangChain should be used to build or are there other tools/products you have in mind as part of the future use of LangChain?', 'There have been many questions on this sub similar to \"Why use LangChain and not OpenAI functions directly?\" lately. How would you have answered it ? :D', 'Has LangChain explored using Mojo at all or even creating a Mojo specific library?', 'Why there\\'s no response from the team or even the \"experts\" in the discord server?\\nMajority of the questions are never answered (check all the question forums)\\n\\nWe\\'re expected to ask kapa ai questions and it answers the questions from docs that people have already gone through. \\n\\nI\\'d suggest, you should definitely invest in getting a content creators dedicated for making YouTube videos for both Python and especially for JS. The collaboration with Scrimba is good but the examples in the docs are very basic.\\n\\nAnd please don\\'t leave the JS behind. In the docs, sometimes there are snippets for Python but not for JS so it\\'s gets very confusing.', \"Where do you see langchain in 1 year or rather what is the next big feature you can't wait to see implemented?\", 'What do you have to say about this article saying how convoluted it is: [https://minimaxir.com/2023/07/langchain-problem/](https://minimaxir.com/2023/07/langchain-problem/)\\n\\nNamely: \" LangChain’s vaunted prompt engineering is just [f-strings](https://realpython.com/python-f-strings/), a feature present in every modern Python installation, but with extra steps. Why do we need to use these \\n\\n    PromptTemplates\\n\\nto do the same thing?\"\\n\\nAlso I saw your docs lately and they suck. Barely any info on some pages. I am going to use what the author of that article made: [https://github.com/minimaxir/simpleaichat](https://github.com/minimaxir/simpleaichat)', 'Seems like langchain is really committed to compatibility with openai, but it is challenging to work with local LLMs. What are the plans to support additional prompt templates for different model styles? Unless I totally  missed that in the docs ... Seems like agent templates are not optimized for Llama or other templates. Sometimes the library feels overly abstracted, so it seems natural for other prompt formats to be integrated directly into source.', \"Love LangSmith and I'm sure LangSmith is going to come up with subscription soon? \\n\\nAnd would there be an affordable version of self-hostable LangSmith so non-enterprise apps don't need to share data over to LangSmith for privacy/security reasons?\", 'As far as I know, the library seems to provide support to single agents and some experimental support to other types of agent runtimes (eg. BabyAGI, AutoGPT). Do you have any plans to include multi-agent support like autogen?', 'Let me start by saying LangChain is a wonderful product. I’m working on extraction chain, which extract data from documents, using a schema. I’m trying to understand through the documents. If there’s a way we can check if the extracted data is accurate, some sort of a confidence score or accuracy of some kind. Does LangChain provide something like that or plans to provide in future?', 'What about libraries that support quantitative questions to structured data (database tables, CSVs etc). Any plans on enhancing NLP capabilities with quantitative agents?', \"Hi, i have a use case where i need to build a custom model between a set of input docs (around 100) and one output doc with around 30-40 samples of input and output, my director of ds suggests that with few shot learning and Langchains and openai api we can build a model with this so that the model can learn from the pair of input and outputs and predict the output for the next set of documents, i have tried a lot but can't find any relevant few shot learning example for such large inputs , so my question is does this lie in Langchain and openai capabilities , as everyone is very interested in genAI so they want genAI in everything!! Thanks in advance\", 'Thanks for the amazing work. Have you plans to make same integrations that have the python version in js for example llm integration with hugging faces text generation inference and vllm using ts/js also any plans on rust?', 'What AI workflow tools do you and/or the team use to help with your day to day tasks? Interested in code assistance in particular, but curious to hear about all of it (even maybe something that makes parsing and seeding responses to AMA questions more manageable)', 'Where do you see langchain in 5 years?', \"What's the biggest challenge you're facing a) on the business side and b) on the technical side?\", 'How many people work for langchain? What is your funding model? \\n\\nThanks for all the contributions!', 'There are many Agents out there, many experimental. Which agent you feel has the most potential?', 'What do you think is going to be the 3 largest use cases for langchain and llm as a whole. \\nDo you plan to go beyond llms?(into other generative ai)?', 'What are your thoughts on small models with added layers to make them more performant e.g. [https://arxiv.org/abs/2307.09702](https://arxiv.org/abs/2307.09702)?\\n\\nThis one has little overhead to the token sequence generation process and significantly outperforms existing solutions. Summary [here](https://will-bennett.beehiiv.com/p/small-language-models-and-defensibility)', 'LangChain is an awesome project, I really enjoy using it. How can I as a python developer contribute to your open source project?', \"Hello Harrison, \\n\\nI love langchain and I am a big fan of your work, love your YouTube sessions about what's cooking in the field of Gen AI and LLM. \\n\\nMy question: langchain has amazing support for OpenAI models but for Textgen LLMs, the basic functionalities work but the updates are not frequent. Couple of updates that I have been looking for \\n- temperature, and max_new_tokens do not with textgen llms \\n- for ReACT and agent tools, I think prompts are designed for openai gpt-3.5+ llms. Are the prompts going to be customized for open 7b llms? \\n\\nAre these updates something that the team is currently working on?\", \"First of all, happy first birthday to LangChain, and thank you, for providing such an invaluable framework to the community! It's truly transformed LLM app development.\\n\\n\\nMy question revolves around the emergence of multimodal models that can handle not just text, but vision, audio, and even code. Are there plans or considerations for extending LangChain to support these types of multimodal functionalities? For instance, enabling LangChain to process and query within images, audio, or video content. \\n\\n\\nI understand this would be a very big task, but I'm curious if you have any thoughts on it.\", 'Talking with langchain documentation is great, but sometimes it feels a little limited with its knowledge of development and coding. Is there any plans on building this feature to be more robust in the future?', \"Hello, I've been trying to get a better understanding of how LangChain can be used. Is it possible to use LangChain components and functionalities with a custom implementation of the OpenAI API?\\n\\nIs it for example possible to perform a RAG query using Langchain, but then passing the retrieved and generated context to my own Implementation of the ChatCompletion.create() method from OpenAI?\", 'Hi there is still some bug when we try to use langchain locally without internet . the lib still try to access to openai or hugging face specially for tokenizer', 'What hardware is needed to run llm locally on a cpu to answer within seconds', 'An updated documentation Will be beneficial in line with the new changes in the library', \"I love developing AI stuff, but the frustrating part is dealing with external issues like json repair from 0613 reply (found this btw https://github.com/josdejong/jsonrepair), or synching audio and stream (for text2speech), chat mem management etc. What are your thoughts on this on what's percentage of your work is purely about AI rather than incumbent?\", 'Hi great work with LangChain! I want to know what are the plans with the open source version of Langchain? Will it be supported in the near future or will there be paywalls?', 'Happy Birthday !!\\n\\nWhat are the main differences between Langchain and Llamaindex?', 'What’s a memorable project you’ve seen utilize langchain in a unique and unexpected way?', 'Langchain seems to be focused towards people with a lot of programming experience. Langflow and flowiseAI are front-ends with limited functionality. Do you see langchain making a product that average, non-programming people can use to easily make models that use all the components?', 'What are some of the best implementations of predictive agents you’ve seen with langChain?', 'Can you guys build something that helps me pick which chain to go with depending on my usecase? Could be a software or an infographic or something else.', '![gif](giphy|888R35MJTmDxQfRzfS)', \"Would love to come work for you. If I could choose to do anything, it would probably be to work on this repo. One of the most impressive things I've seen in a long time. How would you suggest I reach out?\", 'I just want to say \"thank you\" for your work', 'There are claims that Langchain does not scale well in production, how do you respond to this?', 'How can we use LangChain for building data visualization agents?', 'Can you hire me?', \"The scheduled time for today's AMA has ended.\\n\\nThank you to u/hwchase17 for taking the time to respond to questions today in a thoughtful manner, Harrison-feel free to drop by again!\\nEveryone else, thank you for participating. For more updates from LangChain, check out the link below.\\n\\n- https://www.langchain.com/\", 'Is it true that it is 9 inches long and 7 inches thick?', 'how do you start langchain u/hwchase17', 'Hi Harrison, first of all, happy first anniversary to LangChain! As a developer who has been closely following the progress of LangChain, your platform has indeed revolutionized the way we perceive LLM app development. \\n\\nMy question is regarding the future of LangChain. Given the rapid advancements and competition in the tech industry, how does LangChain plan to sustain its growth and stay ahead in the game? Also, could you shed some light on any upcoming features or improvements in the toolkit that we might look forward to? Thanks!', 'this is test comment', 'Hi Harrison! I was an early user of LangChain, then beta on Smith, tried Serve but moved back to fastAPI and now using Graph. Is it possible to get on the Cloud beta? I’ve had over 7000 runs (~3000 questions) through my beta site: www.deepskyai.com helping pilots find information all in a real production environment. At first langchain was pretty bad, but it’s way better now, especially Graph. \\nCloud beta access plssss?!?', 'Are you hiring cloud app devs?', \"Hello Harrison. \\n\\nMy name is Saeed Shamshiri, I am the founder and CEO of RoboCoach, a San Diego based startup in robotics. We are using LangChain in both of our open source products: \\n\\nGPT-Synthesizer: a tool for software design & code generation: [https://github.com/RoboCoachTechnologies/GPT-Synthesizer](https://github.com/RoboCoachTechnologies/GPT-Synthesizer)\\n\\nROScribe: a tool for robot software generation (this is our main product):   [https://github.com/RoboCoachTechnologies/ROScribe](https://github.com/RoboCoachTechnologies/ROScribe) \\n\\nI want to ask you if we can showcase our main product (ROScribe) on your website? ROScribe is a state-of-the-art solution for robotics softwares and starting next release it will be using RAG (Retrieval Augmented Generation) mostly based on LangChain APIs and LangChain agents. We are publishing a paper on it in the next ROS conference. I think ROScribe is mature enough for this purpose, otherwise I wouldn't ask. Please let me know.\", 'Is the main problem with langchain that trying to deal with an AI as an API is freaking impossible? No standard response', 'What’s the best way to implement Langchain in a micro services architecture for different tools in the chain so we’re not running a giant monolith for many use cases?', 'Will LangSmith have an ETL pipeline to upload and curate new docs for our RAG applications?', \"Harrison, you mentioned in one of your webinar that LC's OutputParse is obviated by function calling (for those using OpenAI). can you elaborate on what you mean by this? Also, agents like ConversationAgent were created before the release of function calling. Are these agents (which generates chain-of-thought tokens) still usable or we should utilize function calling? What do you think is the best approach for 'tool selection' or 'routing' to the appropriate API/expert based on a given query? Thanks.\", 'Hey Harrison! Amazing work (I built multiple products using LangChain. Hope to see them picking up soon..)\\n\\nI’m very interested in API based groundings for LLMs (think Zapier for LLMs). \\n\\nWhile I have used different agents before (https://python.langchain.com/docs/modules/agents/agent_types/) I’ve found them to be a bit different than my usecase. \\n\\nWhat I want exactly is for a way to integrate APIs directly into LLMs in a Zapier like way. Right now I have to do it using code. A feature that natively supports these integrations in langchain would be of immense use to the developer community.\\n\\nIs there any work going on in that area w.r.t. LangChain? (It seems to be a hot research topic right now and if executed properly could make it 10x more useful).', '!RemindMe 1 week', 'Please add more informations and use-cases on cookbook. It will be helpful', '[deleted]', 'Hello @hwchase,\\n\\nFirst of all i would like to thank you for building langchain, makes our devs life so much easier.\\n\\nI am at a place technically where i am exploring integrating llms with knowledge graphs.\\n\\nI believe they are a big step in curing hallucinations to some extent and help with multi hop questions answering providing a way to query unstructured way using RAG.\\n\\nMy question is :-\\nWhat do you think is the future of this integration of llm with Graphdb, can it start recommendation .If yes is it better than Vector db at handling some type of data?', \"Where does LangSmith store the data it works with? For those of us in  Europe who need to comply with data protection laws that require us to  keep our clients' data within Europe, is there any possibility of  hosting the application on our own server?\", \"There is a lot of imperfect execution when using chat_history option for follow-ups. Example use case would be Q1. Write an essay on Taj Mahal. Q2 Add more details about the materials used Q3. Remove details about Mumtaj's history - just as an example and not word for word exact question but you get the idea\\n\\nThese follow-up questions are hit or miss. In certain cases they work upto level 1 of follow-up and for most cases they don't exactly work. It all seems to be related to the context being used - as a reference you can do n number of follow-ups using chatGPT without any issue. But through langchain its a issue.\", \"Tried csv agents with Open AI, worked very well. Why Does Agents run indefinitely and don't give desired outputs with llama2, Mistral other Open source LLMs?\", 'What is your favorite RAG pipeline? What is your favorite embedding model?', 'Can you please make it more configurable', 'When are you going to refactor and do better documentation? Tons of potential, but so much time wasted trying to figure out basic things.', 'What if we want a small gibberish model', 'Can you take a look at this question please ?   \\n[https://www.reddit.com/r/LangChain/comments/17g7cer/how\\\\_to\\\\_handle\\\\_concurrent\\\\_streams\\\\_coming\\\\_from/?utm\\\\_source=share&utm\\\\_medium=web2x&context=3](https://www.reddit.com/r/LangChain/comments/17g7cer/how_to_handle_concurrent_streams_coming_from/?utm_source=share&utm_medium=web2x&context=3)', 'Why is it so hard to stream data  using langchain', \"There's alot of frustration with the docs. I'll say that- although the docs aren't straight forward like Twilio, they're good Docs for experienced devs.\\n\\nWhat really helped me learn quickly was creating a RAG AI of LangChain's Github, then asking my AI questions about docs. \\n\\nNow I never have to manually search Docs, and the LLM gives me real examples of code.\", 'Why does JS output JSON for the final answer, but Python outputs as a string?', 'Is LangChain offering any jobs or compensation for people who can help create tutorital videos on YouTube?', 'This tool has been really helpful in this AI times', 'Please tell me more about your company', 'How are you m8 :)', \"Dude you are a god, I LOVE LANGCHAIN, I've been using it for a ton of stuff, memory, embeddings, vector stores, chat bots, agents, custom tools, custom retrievers, it's so much fun!!!\\n\\nOne suggestion though I would like two things, one: ts and python docs should be as similar as posible, meaning the underlying repos should look as closely as posible, having used langchain on both node and python backends I can understand a lot of the confusion that comes from the docs.two: The docs IMHO should have a section on each module, with typing for methods, fields, args, etc, for example here\\n\\n&#x200B;\\n\\nhttps://preview.redd.it/ertyr0tm8swb1.png?width=277&format=png&auto=webp&s=0907e69823ecdc6926496a52c6724860269eed8d\\n\\nAfter toolkit add definitions, and have a detail of every major class in that module.\\n\\nAnyway, AMAZING job with this library, I'm having a blast using it!\", 'What would you say justifies owning your own abstractions over using Langchain in a production setting? Is Langchain truly ready for a high load, software application?', 'I used langchain before. But I finally give up. It have some basic bugs like pdf chunk size not really works. Take me hours to found the bug. Now I am doing myself from scratch. Save a lot of time. And langchain is too powerful make it become hard to follow the code. Too many abstracts for little value', 'Why is there a lack of support for local LLM connections? Why are the docs only providing examples for OpenAI API to connect to SQLDatabaseChain, CSV, or PowerBI files? The only available piece of documentation for local LLM inferencing on textgen-webui is how to setup a chat session. Please consider adding better support for local LLM connections.', 'Are you planning to release some integration with memgpt and autogen. I mean working on docs to include some examples. Other than that langchain is great. Thanks for developing this library.', 'Will LangChain agents for conversational analytics (SQL, CSV) ever be production ready for enterprise-grade applications?', 'How to create sperate memory for each session means i have saved user chat history and i want to add this history into memory but in chains there is no option for separate memory for each session', \"I’m looking into Knowledge Graphs, Large Language Models, Machine Learning and Natural Language Processing.  \\nI am aiming to combine this with projects such as Langchain to allow personal vector databases and knowledge graphs to use in Retrieval-augmented generation, so that documents, media, texts can be first classified and then using Langchain’s Agents and Tools methods then processed in a context rich way.  \\n  \\nAre there any talks with WC3 or large dataset libraries or museums for such an AI Open Source model?  \\nIs the best method to put in context of Knowledge Graph to use an agent when loading as context or tuning an LLM to that specific task and then use it on Loaded to Tokenise and categorise in a pipeline?  \\nDo you know of someone already doing this? Top level semantic domain classification seems like a great step for all programs that would be built or documents tagged.  \\nAm I making sense or rambling? I'm self-taught and looking for this since I'm pretty sure I'd be too slow trying this as a first big dev project.\", 'Yes we are very actively considering this. We should have some updates here in the next few weeks or so. I think we want to see what OpenAI releases at dev day before committing too heavily\\n\\nOOC - when you say \"hit or miss\" what do you mean exactly? We\\'ve tried to make changes backwards compatible as much as possible', \"Would honestly love to know which part of the docs! We have a lot of different parts (which probably contributes to the problem). Python/JS? Use cases/cookbooks/core modules/api reference docs?\\n\\nThe underlying issue is probably that there's a lot changing rapidly and theres a lot in LangChain. We recently made some structural changes to help organize things better - separate API reference docs, splitting out use cases from core modules. There's probably a lot to be improved within those splits, but I'm hopeful that that organization will help set the groundwork.\\n\\nAgain, would love to hear more specifics of what docs and in what way they are hard to read - would really help us prioritize!\", '[deleted]', 'Yeah this, trying to find a good example with all the parameters explained was really difficult when I tried.', 'The docs are easy to read imo', \"Greg Kamradt's channel is awesome for learning: [https://www.youtube.com/playlist?list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5](https://www.youtube.com/playlist?list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5)\\n\\nFor deeper dives on particular topics, we post recordings of our webinars: [https://www.youtube.com/channel/UCC-lyoTfSrcJzA1ab3APAgw](https://www.youtube.com/channel/UCC-lyoTfSrcJzA1ab3APAgw)\\n\\nI'd also highly reccomend anything James Briggs does: [https://www.youtube.com/@jamesbriggs](https://www.youtube.com/@jamesbriggs)\", 'This', 'Thanks for even thinking of contributing! And yes I was there haha\\n\\nLooking at your PR, I think the new one is pretty different from the existing implementation (which is good - I think the initial one was pretty similar modulo a line or two). Although its rewriting core functionality, I think adding this as a separate class and clearly documenting the differences would definitely be helpful!', 'Awesome! Would it be straightforward to update this to use custom separators? Could the splitter from your original PR be used this way?', 'Currently, we are offering an enterprise version of LangSmith. However, we still believe it is really early in this space and very fast moving and so we are constantly evaluating.', 'For core functionality, no. There are awesome community led projects for Go, Java, Elixir, Ruby, etc though! Just not maintained by LangChain the company.\\n\\nWe may add lightweight LangSmith SDKs for other languages, or super lightweight LangServe SDKs (for interacting with hosted LangServe objects)', 'Langchain is unfortunately very poorly designed and is filled with overlapping abstractions which leads to a lot of confusion. The documentation suffers from poor organisation too', \"I don't disagree, but I'm mostly here for the interoperability + agents.\\n\\nThis is one of those 'Yes I know how to code, no I don't want to spend hours working on boilerplate.'\", \"Say you wrote a program without langchain that uses GPT3.5 as a language model, chroma for your vector store, and you wrote some code for splitting your text docs.\\n\\nNow let's say a week later you want the same program to use a local Llama language model, faiss for vectors, and a want to split PDF docs instead of text docs.\\n\\nYou'd pretty much have to rewrite the whole thing.\\n\\nBut because langchain's codebase is written with substitutionality at its core, you could swap out the model, vector store and splitter in under a minute.\\n\\nThat's not the only reason to use langchain of course. But these kind of libraries are written in a way that saves you time in the long run.\\n\\nIf you just want to write a one off script, then of course you could do this without langchain.\", \"Idk, man. I can't code. Like, seriously, I need to look up how to `try` statements. But with LangChain, I've got my own custom chatbot who even gives me lip from time to time. I hope to have him browsing on his own by this weekend. And when I decide it's time to change my prompts, or my tools, or even my LLM, the modular switching out is super easy.\\n\\nI would say LangChain has its points.\", \"I think of it like an ORM. A lot of the comments around here seem to be similar to ones in ORM vs non-ORM debates. I think there's a place and time for both.\", \"The documentation is awful. There are many times that I have to traverse the source code myself to figure out what something does. Even then, it's miserably awful because you find the source code is literally all just func(\\\\*\\\\*kwargs): next\\\\_func(\\\\*\\\\*kwargs)...\\n\\nOh, and tons and tons and tons of Pydantic line noise...\", \"I'm sure the entire thing was whipped up in the first month of this new AI revolution. I never quite thought any of these toolkits were amazing considering how quickly they came out. The hype train is a hell of a drug tho. \\n\\nI'm working on an LLM toolkit of my own that includes context management, embedding tools, an embedding based command chooser, chaining, and optimized TTS that works with chunks as they're coming in. \\n\\nMore than anything it's a way to learn all I possibly can about LLMs and how to work with them. Its not quite there yet but considering it's only been 3 months since chat came out, that's understandable.\", 'My favorite is the PrompTemplate class AKA an f string !!!!', \"I believe the abstractions in Langchain are inherently flawed. The core problem resides in the composability of chains. While it offers a handy way to create prototypes, it becomes restricting when you desire to modify a specific element within the chain. The hierarchical design of chains in Langchain conceals the component you wish to alter and obscures the parts developers might want to adjust, making the process of experimenting and refining the pipeline difficult.\\n\\nThe optimal abstraction for LLM apps, in my view, should resemble a DAG or a state machine. This alternative exposes the distinct stages in the pipeline rather than masking them in a hierarchy. Yes, adopting this new abstraction might lead to more code but it offers superior control. It's hardly surprising that many users start prototyping with Langchain, but then, when ready, they clone the prompts and construct their own systems.\\n\\nFixing this fundamental issue would be very difficult. It would necessitate reworking the library from the ground up.\", \"LangChain promises so much but as soon as you get started it just sucks you into inconsistencies for every single simple thing until you forget what you actually wanted to achieve. Type system is completely broken, interfaces don't match and every chain type has completely different way of doing things and key names for the same thing.  $10m won't fix this.\", 'Yeah, a higher up wanted me to base a project off of this, but constant bugs and improper documentation led me to just building my own tooling :/', 'My main problem with it is how so many modules explain how to do one or two things then if you dig into the code you realize theres like 10 things built in there that arent documented AT ALL. i guess thats what happens when you grow that fast.', 'Ironically, a modern AI would have produced much better code.', 'I am just dropping a link to the hacker news discussion about this post for future reference https://news.ycombinator.com/item?id=36645575', \"100% agree with this! Langchain seems to be a text-book instance of an ill-conceived poorly designed academic project that is growing in size and adoption for the sake resume buzzwords. It abstracts and complicates for no reason or value. There might be a couple of useful pieces of functionality in here but they're poorly named, badly documented, and largely swamped by useless fluff like 'chaining'. Software *is* chaining of commands. We don't need a framework to abstract this and make coding and debugging 1000x harder.\", 'So what is the lesson here? Should I just look for particular libs to recreate what langchain is doing?', 'As a hobbyist (and beginner) I thought langchain was the go to tool for coders given it’s popularity amongst the YouTube tutorials on this subject.\\n\\nI feel misled reading opinions of people who actually code for a living.\\n\\nIs there an actual library I can study and use for my own use cases? Huggingface’s transformers maybe?', \"I feel you, but ultimately anything library that is built around a LLM will aways just be fancy string parsers. I wouldn't expect much from them either way.\", \"> This seems like a beginner's project\\n\\nIt absolutely is a beginner project that blew up. There has been so much movement in this space, and it's sufficiently new to a lot of people that people naturally gravitated towards a library with high number of stars on github.\", \"My path with langchain was :  \\n\\\\- Ok, this seems widely used, must learn about it  \\n\\\\- Mmhhh, do I really need to use this ? Is this actually helping me or is it a weight ? I will only use chains and templates for my project, then we'll see.  \\n\\\\- \\\\* Sees a reddit post about it\\\\*\\n\\nI would say the LLM client wrapper is useful because it creates an abstraction with many LLMs\", 'Came for the abstraction; stayed for the agents…', \"just prototyped something simple for js/ts: [https://github.com/gsidsid/gptio](https://github.com/gsidsid/gptio). imo just making custom tools the default practice for ppl adding long term memory or document stuff is the way, esp when it's all evolving so quick. obv there are limits to this approach\", \"I'm trying to build a production-level LLM-powered app, and LangChain makes me a lot of pain; the documents are inconsistent, it passes parameters so randomly but still checks types with `pydantic`, so some use cases fail and some do not, and the time I spent debugging custom tools and chains is even enough for me to implement one from scratch.\\n\\nIf I just wanted a data science lab or an LLM toy, LangChain would be great, but for production-level systems, I don't think so.\", 'What about lamaindex? (Or that suffer from same issues...) \\n\\nhttps://www.llamaindex.ai/', 'I was beginning to feel this way after watching some videos of the founder. It’s like a big marketing push with the hopes of filling the gaps along the way. But I couldn’t find any value, seems like basic python is all you need here.', 'I think that Generative AI applications is a config management problem. Think Prompts X Chains X LLMs. Your prompts wont work across everything and everything will break on model change. Coding this into ur classes is what everyone does.\\n\\nI think the better answer is to *declaratively* pull out the prompts X chains as jsonnet code. Call it trauma & learnings from the K8s/Borg world. We have formats that have evolved as a result of millions of lines of code wrangling clusters/terraform/etc - so we decided to build a SDK over it.\\n\\nthat is what we did here - https://github.com/arakoodev/EdgeChains/releases/tag/0.2.0\\n\\nEdgeChains is basically Generative AI prompt engineering modeled as config management.', 'Thank you! How did they raise SO MUCH money!!', \"I agree with this 100%. It's trying to solve a lot of things and that package has become ginormous and leading towards dependency hell. I was recently trying to build a RAG on some research papers and thought of using it but ended up writing something from scratch and had a good experience. I have documented my apprehensions and why I thought its at least not for me. [https://thevatsalsaglani.medium.com/why-you-dont-need-langchain-for-building-a-rag-bot-a1dfbc74b64f](https://thevatsalsaglani.medium.com/why-you-dont-need-langchain-for-building-a-rag-bot-a1dfbc74b64f)\", \"came here to say this, after so many months the sentiment remain the same. I wanted them to be good but quite frankly this is a pile of hot mess. It is only good for very specific and controlled scenario if anything is out of ordinary then you're screwed.  \\n\\n\\nJust write your own prompts and implement your own logic guys.  \\n\\n\\nFunction calling is just multi-shot prompting with COA\", 'The argument that it saves you from writing boilerplate code is BS since you spend more time in reading the half done abstraction with not so up to date upstream connectors  resulting in loosing a lot of features.', 'Why isn’t this getting more play. You hit it on the head. Well done.', \"Seems kinda dogsht code - multitude of circular dependencies.  Company has received not that much investment - so guess they've already been sniffed out.\", 'So where are your push requests, big guy?', 'Why does one need langchain when you can just call the openai chat completion API directly with a dictionary of \"chained\" prompts?? The LLM doesn\\'t hold any of the previous context in-memory so you have to provide all of the context in every request, and that is easily handled by adding and popping messages from a dictionary, so why do we need langchain again?', 'LightRAG, The PyTorch Library for LLM Applications, is now publicly available in alpha release. Would love to hear your thoughts on us!\\n\\nhttps://github.com/SylphAI-Inc/LightRAG\\n\\n*LightRAG* helps developers with building and optimizing *Retriever-Agent-Generator (RAG)* pipelines. It is *light*, *modular*, and *robust*.\\n\\nLightRAG follows three fundamental principles from day one: simplicity over complexity, quality over quantity, and optimizing over building. This design philosophy results in a library with minimal abstraction, providing developers with maximum customizability. View the class hierarchy [here](https://lightrag.sylph.ai/developer_notes/class_hierarchy.html).', 'To l33t programmers like OP, he could just be writing his own library… yet he’s not writing it in c++ like all major AI houses do for prod.', '[deleted]', '... and what do you guys think about the JavaScript version? Is that better designed?', 'What is the alternative to langchain?', \"It's just abstraction to do stuff quickly, definitely better to use alternative approaches for basic action\", \"I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:\\n\\n- [/r/hypeurls] [Langchain Is Pointless](https://www.reddit.com/r/hypeurls/comments/14u9l5i/langchain_is_pointless/)\\n\\n&nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\\\\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*\", 'Haystack is much better , well oragnized langchain alternative.', 'try deepset Haystack, it is a thought through and well designed library that comes with production level code', \"HAHAHA, I agree with you. What's the point of langchain really confused me for a long time.\", \"I think the exciting thing about LangChain is it's potential.\", 'I agree. This is awful. I came here as I was working through the examples.  \\nWith ([https://python.langchain.com/docs/modules/model\\\\_io/prompts/prompt\\\\_templates/custom\\\\_prompt\\\\_template](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/custom_prompt_template)), I get the error:  \\n\\\\`TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases\\\\`  \\nToo many classes and subclasses!', 'I thought, I was the only one...  \\n\\n\\nGreat for a simple hello world project but painful for anything real world...  \\n\\n\\n4 lines of simple code to get started, and then for any troubleshooting takes 4 days;  there is no way unless you understand the whole library...especially the agent abstractions...  \\n\\n\\nI hate all the \\\\*\\\\*kwargs and \\\\*\\\\*agent\\\\_kwargs and multiple ways to do the same thing...  \\n\\n\\nNow they are pushing LCEL... another layer of obscurity....  \\n\\n\\nI am seriously considering going with vanilla openai python SDK...  \\n\\n\\nany feedback?', \"So I will be very honest. We found langchain documentation to be very poor. For using internally, we made something like a ChatGPT on top of Langchain's code and docs. hosted it on [https://langchainx.web.app/](https://langchainx.web.app/).   \\n\\n\\nWe are eventually not using any langchain functions or helpers but still keeping the portal available for the langchain community. Let me know if you use it and find it helpful\", 'Can you think of any alternative of langchain for now?', \"Eh, except when the boilerplate is an obstacle. Try building a retrieval QA chain \\\\_with\\\\_ memory using langchain. You can't unless you override one of the chain's prompt templates. Which means you have to dig into the code with a debugger to figure out exactly where it happens and what to do.\\n\\nCobbled together the same exact thing with plain openai and chromadb in like an hour. If you know what you're doing sometimes langchain works against you. And I'm a huge fan of libraries and frameworks and whatever makes your life easier but I found langchain to, well, not do that.\\n\\nEven agents are simply loops with a carefully crafted prompt that gives you whatever you need in the right format so you can use it to call external functions (which is now kinda pointless with openai's function calls). The value added of langchain, so far, doesn't justify its bloatedness.\", \"That's definitely a risk, but the solution isn't to abstract everything you possibly can. Are you really going to want to split your text with a different underlying text splitter? No. The solution is to be smart about what you plan for. We know models change constantly so you should abstract that--make an interface with `_call` like Langchain does, that makes sense, then your consumer code can be agnostic as to whether it's hitting OpenAI, ooba, kobold, etc.\", 'Not true. I got stuck in this specific use case and ended up spending pointless days trying to figure out the data types langchain is passing underneath its poorly documented classes.\\n\\nIt’s a nice springboard in theory, but in practice it turned out to be far easier to just write my own functions (with the exception of using llangchain to load the model; it’s a wrapper on top of the python llama.cpp library, and doesn’t do much, but it’s readable).', \"> But because langchain's codebase is written with substitutionality at its core, you could swap out the model, vector store and splitter in under a minute.\\n\\nPragmatically, that has not been my experience. I've been digging into Langchain over the last few months for just this promise. In reality, swapping between models leads to a rabbit hole of installing new dependencies (sometimes requiring custom configuration or compiling from scratch - like `bitsandbytes`), swapping custom document logic out for a `JSONLoader` errors because of shell escaping issues in the underlying `jq`bindings, and you burn time trying to figure out exactly what the difference between `load_qa_chain(..)` and `RetrievalQA.from_chain_type(..)` are.\\n\\nI think the motivation behind Langchain is good. The ecosystem is hungry for abstractions over common use-cases and components, but the landscape as a whole is still so unstable, and it's not clear that Langchain has identified the right abstractions yet to me. Too many details leak through from underlying implementations, too much overlap between components, and the rate of change fast outpacing the documentation to support those changes. Hopefully contributors keep driving the project to something closer in quality to the Scikit-Learn model interfaces, and are able to deliver on the promise of seamless swapability.\", 'It’s called dependency injection and is a core part of software engineering', '[deleted]', 'In practice, no foundation model beats the OAI suite and you\\'d probably have to redo much of your prompts (and maybe some of your internal logic anyway) if you wanted to switch away.\\n\\nOn the vector db front, I am not as certain, but I\\'m still pretty certain that Chroma will be a top tier competitor for the foreseeable future.\\n\\nThat said, even if you did decide you wanted to move away from the OAI suite, langchain poorly abstracts over it, hence why langchain\\'s Anthropic is \"model\\\\_name\" and langchain\\'s OAI is \"model\" (or the other way around, I forget).', 'It does look like a good way for beginners to get started, and the tutorials tend to be short, as long as you don\\'t stray away from what they want to do. But as you want to do more advanced things I think you can naturally learn more (and ask ChatGPT how to learn what you need, too). So maybe \"pointless\" is too harsh. But the README and the hype does make it seem like it\\'s more advanced and deeper than it is.', 'You are a genius ! [https://python.langchain.com/docs/get\\\\_started/introduction](https://python.langchain.com/docs/get_started/introduction) Please view the diagram.', 'how us this going :)', 'Yes, I was personally quite surprised when I realized it was nothing other than an f-string lol', 'hear hear! finally some sense.  \\nThe core abstractions are good old (non-llm) DAGs, with functions, and data artifacts as input outputs to those functions - yes provide me with a lot of ready-made function and artifact types..', 'Langchain shall use their own chain to rewrite their code.', \"I suspect it's more nefarious than that at this point. It seems to be lock-in for the sake of it, fueled by hype. They have nothing of value to offer so they purposefully make things difficult while pretending they're offering a solution, to make your codebase dependent on them.\", 'Seen this one? https://www.reddit.com/r/Python/comments/13djuec/github_griptapeaigriptape_python_framework_for_ai/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1', 'If you\\'re a beginner I\\'d recommend starting with Langchain, nothing wrong with that. But as you go use \"go to declaration\" in your IDE from time to time and see what it\\'s doing under the hood. In most cases you can just use the underlying library, like the examples I gave above.', 'It’s all basic api requests, langchain is just a clunky library with some prebuilt stuff.  Learn what’s going on there, and if it works for your pet project, all good! But it’s not likely going to be production ready, and anything you see in the langchain repo is probably better custom built for your own use.', \"Langchain is great to learn what is going on. Look at their code and study it. It's a decent collection of utilities but not the end all be all that people seem to think it is.\", 'Lmao. It’s a pull request, new guy.', \"You don't request a push, you request a pull. \\n\\nAnd this is the same argument everyone gives when you criticize something they like. 'Well then make your own Twitter!'\\n\\nOr just accept not everything is perfect and be happy people are critical\\n\\nETA: the TLC got suspended for brigading me into my universities sub and threatening violence. \\n\\nBecause he didn't understand git.\", 'Push request!!! 😂🤣😂🤣😂🤣😂🤣', \">why do we need langchain again?\\n\\nYou don't. It's marketing slop.\", 'Rough day, huh?', 'It depends on the specific functionality, but if you go one layer down in their code you can see the actual libraries doing the work. I pointed out SentenceTransformers, ChromaDB, and requests for what I was looking at.', 'SymbolicAI\\nhttps://github.com/Xpitfire/symbolicai\\nhttps://symbolicai.readthedocs.io/en/latest/README.html', 'Just write the small amount of glue code needed (and hey, you can even get help from openai directly to do that). Most of what langchain does I just implemented directly for my own use case because it’s easier to manage and update that way and in the end it was such a small amount of work that was better to understand the underlying APIs anyway.', 'Was just thinking about making one of these!! The more I read the more I feel like I should just use Langchain as a reference rather than any meaningful implementation.', \"That's what I was looking for, something to query the langchain docs. Funny enough, it told me to use tfid vectorizer and a similarity search, rather than langchain for my query of how to create a chatbot that can read a json file.\", 'Griptape', 'I AM LOOKING FOR LITERALLY ANY ALTERNATIVE TO LANGCHAIN that is not in python,\\n\\nanything that is .net or .cpp \\n\\nPLEASE!!!', 'The right tool is obviously Airflow + Vector DB like Weaviate or Pinecone.', 'Just write your own abstractions ¯\\\\_(ツ)_/¯', 'I have found LLMWare to be the best alternative to Langchain that is focused on RAG. It has native parsing for PDFs and Office documents, is end-to-end, with open source components like Mongo and Milvus. They also have a 1.3B model on HF that runs on CPU (not GPU) for fast and easy POCs. Check it out!\\n\\n[https://github.com/llmware-ai/llmware](https://github.com/llmware-ai/llmware)', 'We launched in mid of January and are working on improving architecture design, usability and debugging of neuro-symbolic systems with strong focus on LLM research.\\n\\nhttps://github.com/Xpitfire/symbolicai\\nhttps://symbolicai.readthedocs.io/en/latest/README.html', 'f-strings / template strings\\n\\nSeriously, 90% of what people use langchain for could be replaced with simple string substitutions.', \"Yep, I had the exact same experience. Spent several hours fighting with LangChain, debugging its internals, etc. just to combine two of its features. In the end, I realized that LangChain hadn't done anything but get in the way, while I had implemented everything useful myself.\\n\\nGave up on LangChain and had a cleaner, more extensible implementation in two hours.\", 'Yes I agree.\\n\\nLucky that as you mentioned, you can throw that example together in an hour.', '[deleted]', 'LangChain has a place in the world and the ability to swap out functionality could have a lot of value to the discerning user. That said, most of Langchain use is for TikTok hype', '>Are you really going to want to split your text with a different underlying text splitter? No. \\n\\nabsolutely yes!', \"I agree with your thoughts 100%.\\n\\nLangChain leads you to believe you can easily abstract away which LLM you're using, but my experience has shown this is *not* the case in practice.\\n\\nFor these applications, 80% of the work is going to be the prompt engineering. You aren't going to get the same reliable quality results from different LLMs using the same prompts. I've noticed that often times you need to dramatically change some prompts, depending on the model you're using.\\n\\nBecause of this, a lot of the abstractions LangChain exposes are kind of wasted effort and just unnecessarily adding to overall complexity.\\n\\nSure, you can hotswap which LLM you're using with LangChain's composable approach: but what's the use of that simple one line change when you wind up having to rewrite all of the prompts anyway? You may as well had used an official API - especially because the official APIs (e.g. OpenAI, HuggingFace Transformers, etc) support newer features much sooner, and in my experience tend to be way more stable and fast.\\n\\nI really, really want to like LangChain. It does have some good stuff and I think there are noble intentions behind some of its design principles. But I had way too many issues with some things being broken (streaming tokens from OpenAI), very frequent API changes that completely break my code in sometimes silent ways, and just having to wrestle with some of the abstractions way too much.\\n\\nIn the end I wound up writing my own code in far less time, and just borrowed a few conceptual principles from LangChain, and I couldn't be happier with this approach\", \"> Main problem is how do you write a program that uses gpt 3.5 as a language model if langchain don't let you change a prompt. It is a huge task to rewrite a prompt for something more specific. \\n\\nIs this a joke or are you actually this bad at programming? \\n\\nIf you answer me without getting offended, I'll tell you exactly how to do it.\", '🤦you can change the prompts of the chain', '> Want to code in Spanish? Portuguese? French?\\n\\nNo, I never have.', 'I see Chroma and Qdrant as top tier. Which is better? Yes I want TS binding', 'What are the more advanced things that I can ask GPT to teach me? Actually very curious, I’ve started to play with LangChain but already seems like I am late to the party. Incredible how fast things are moving', \"Interesting you should ask! It's not really. But I did learn a lot.\", '[Ex-fucking-scure you?](https://imgur.com/cELeFt2)\\n\\nNew to what? Automated, by the way. Every single day I was pushing commits to existing repos that had updates and creating a repo a day for my new work. Everyday for a whole summer. New to what?', \">You don't request a push, you request a pull.\\n\\nOh, okay. So when you're done editing your branch and want to commit changes, what command are you going to give git in bash? Is it `git pull`, sensei? And when you're ready to merge that branch into the master (that isn't your repo), you're just going to go ahead and do it, right? No approval required, right? \\n\\nRampant autism in the programming community notwithstanding, you knew what I meant, buddy. \\n\\n>And this is the same argument everyone gives when you criticize something they like. 'Well then make your own Twitter!'\\n\\nIf you are a programmer and you are saying that something is wrong, and it is a public repo, the mature thing to do would be to fix the problem (the one you so obviously know how to fix since you identified it as a problem, implying a *correct* reference structure in your mind to compare it to), not whatever this is. \\n\\n>Or just accept not everything is perfect and be happy people are critical\\n\\nWhile critique is generally useful for creators, telling them how they can improve, the fact that folks like you don't view things like LangChain as a communal effort, don't really seem to want to put work in to help improve it, **and** generally seem to think that having this negative posture in the one of the most interesting epochs of technology development to happen in your lifetime is pretty disconcerting. No one is telling you to stop b!tching, but maybe flex those fingers to whip up some code **while** you're b!tching.\", 'Correct. We have redirected the above link to [chat.dowhile.ai](https://chat.dowhile.ai) :D', '> Griptape\\n\\nOnly Python? No thanks', \"langchain isn't a library, it's a collection of demos held together by duct tape, fstrings and prayers. It doesn't provide building blocks, it provides someone's fantasy of one line of code is all you need. And it mainly breaks apart if you're using anything but openai. \\n\\nI'd only use it to quickly validate some ideas, PoC style to test the waters, but for sanity and production you need to pick alternatives or write your own stack.\\n\\nAlternatives include - haystack, griptape, openai-api and autogen, and for better local model control guidance, LMQL, etc.\", 'And their horrendous documentation that is outright wrong in many aspects. I got so pissed that I’ve started ripping out all langchain components from my apps and rebuilding them with simple Python code and the openAI Python library.', 'It would help if their docs weren’t so awful. For a tool so commonly used for RAG apps, I can never find what I’m looking for.', 'Sorry to hear your experience, and thanks for sharing. I would love to better understand where you\\'re running into these issues! I\\'d be particularly interested to learn more about why you mean by \"Inconsistent abstractions\", \"inconsistent behaviour\", \"confusing chain life-cycle\" .... thanks in advance!', \"It's an organic library evolving as the fast paced world of LLMs have. I put together [my own style of library](https://github.com/Mattie/chatsnack) I like better, but mad props to langchain for keeping up so well with the craziest dev moment in our entire lives.\\n\\nIt's so silly for 'senior' devs to come and complain about the quality of stuff built when they didn't even know there was a revolution underway that langchain was helping to shape.\\n\\nThe authors deserve mad respect for what they've put together in this blinding pace! Of course there will be cleaner alternatives and reworks, but good luck keeping up.\", \"I understand your pain.\\n\\nI went through this myself. Took me a while to get the hang of it.\\nYou have to read the code which is evolving fast as the field itself. \\nNot the fan of lcel black magic syntactic sugar.\\n\\nI really want them to be successful. I see the opportunity of abstracting new model capabilities across different vendors.\\nI also agree with Harrison Chase idea that the architecture should be owned by the users unlike custom gpts or openai assistant api.\\n\\nHarrison chase will help you if you have a specific issue. I have seen him jump on calls within seconds on x.\\n\\nI don't think you need help, you probably just want to share your frustration and see you are not alone 🙂 BTW you are not.\", 'I feel for you. 6 months ago I tried to build something slightly different from a LangChain one-liner and found that so hard that I decided there had to be a better way, and started building Langroid https://GitHub.com/Langroid/Langroid\\n\\nWe have companies using it in Prod. \\n\\nPrevious more detailed post:\\n\\nhttps://www.reddit.com/r/LangChain/s/5o5JLeutTJ', \"I'm starting to feel this way as well. And yeah, this whole LCEL thing, WTF?!?!?  i was one of the biggest Langchain supporters and now I'm becoming disillusioned. So much of the documentation is missing, it's become a guessing game for me.\\n\\nWhat about LlamaIndex?\", 'I agree in some parts, but disagree with others, I know sometimes langchain can be confusing and it is not so flexible like writing things from scratch. But for me langchain have good abstractions, and actually is the only one framework (that I know), that provides support for very specific user cases (like using quantized models with llama cpp).', \"Haystack might potentially be an alternative. I haven't worked with it extensively, but my first impression was that the design decisions taken there were more consistent and intuitive.\", 'As someone here on reddit summarized.. Its \"dumpster which has set itself on fire\".\\n\\nI used langchain and llama-index. Llama-index felt a bit neat however they are on the similar path to self destruction too once you dig a bit deeper and have to find functionality by digging into the library code.. \\n\\nOne thing I say they are good for is quick demos and experimentations\\n\\nWe have several production LLM apps deployed and its easier to implement your own module instead using these framework.. That way you know what its doing and ita much leaner. We never use langchain or llama-index in production.', 'Have you looked at griptape? [https://github.com/griptape-ai/griptape](https://github.com/griptape-ai/griptape)', 'Yeah I am coming to the conclusion that langchain is more of a pain to deal with and needs a refactor.', 'I feel your pain.  I was wondering if things had improved in the 4 or 5 months since I put together my RAG bot (demo!) for a client.  Now I know.  \\n\\nReading the code to see how to use it can be excusable, inconsistent paradigms across abstractions can be forgivable, and incompatible methods can be overlooked…individually.  \\n\\nIIRC, around 80% of my dev time was spent tricking one part to work with another.  For a funded codebase, it’s pretty disappointing. I think they underestimated the complexity and underinvested in the development.  I get that the world of LLMs is a swirling minefield, but I was so relieved when the effort stopped at the PoC stage.  I wouldn’t feel right handing this over to be maintained or trying to do it myself if it went to prod.', 'The performance of the LangChain framework is another major issue. It is incredibly slow and resource-intensive. Simple tasks that should take milliseconds end up taking seconds or even minutes, which is unacceptable for any production-level application. This severe performance bottleneck hampers the development process and makes the framework impractical for real-world use. I expected much better efficiency and optimization from a modern framework.\\n\\nMoreover, the framework is plagued with bugs that cause it to crash unexpectedly. These are not just minor inconveniences; they are critical issues that make the framework unreliable and unstable. I wasted countless hours trying to debug and find workarounds for problems that should not exist in the first place. The lack of robustness and stability is a major drawback that cannot be overlooked.\\n\\nDespite its claims, LangChain lacks many essential features that are standard in other frameworks. The absence of these features forces developers to implement their own solutions or look for alternative frameworks that actually meet their needs. This lack of functionality is a significant hindrance to productivity and limits the scope of what can be achieved using LangChain.\\n\\nFinally, the framework’s design is overly rigid, making it difficult to customize or extend. This inflexibility is frustrating for developers who need to adapt the framework to their specific use cases. A good framework should offer flexibility and adaptability, but LangChain falls short in this regard.', \"i'm working in lanchain and it's 100% true\", \"Langhain is really shit.Tried to use tavily as tool withit had the worst search results for a query until I used tool directly from tavily. I don't why is that.but it's really fucked up.\", 'how much would you pay for alternative to lag chain which is simpler to use?', \"100% agree and that's why I abandoned it.   But I keep going back for a second, third, fourth..... look to see if it's gotten any better.    It hasn't.\", 'Unfortunately I have to agree. Among the biggest issues I’ve found so far is that the retry strategy for models is hardcoded deep inside the library. Before OpenAI relaxed their GPT 4 rate limits, it was far too aggressive (and still is for some models/providers). I swear at this point I’ve monkeypatched or outright rewritten half of the langchain stuff I’m using anyway. Also, in addition to the docs being wrong or outdated, the AI that they provide to search their docs is extremely prone to hallucinations and multiple times directed me to a nonexistent API. I’m going to be moving to semantic kernel next time I do significant work on my agent.', 'TBH, I had this feeling only when I started with langchain after using OpenAI API for a while, since the whole prompt idea just feels so different to the standard a list of objects as input OpenAI style.\\n\\nBut nothing stops from right click to source, and use it more. Now I don’t have such feeling at all. Things can be approved of course, but nothing major.', 'What do you prefer? Haystack? (Serious question)', 'Look at semantic kernel, it might be a lot better.', 'We started with langchain, moved to HayStack and never looked back.', 'Yea I hate it but figuring out how to implement streaming amd function calling was just not working for me and this handles it well. I abore th callback system', 'Bravo! Well said sir! This is exactly how I feel. The interesting thing is why this is a thing, how did it even got popular?', 'have y’all tried Semantic Kernel? I’m thinking of switching', 'Another one gets bitten. I read this article from a data scientist who tried using it for a month and shared his experience: [https://minimaxir.com/2023/07/langchain-problem/](https://minimaxir.com/2023/07/langchain-problem/). Search \"the problem with langchiin\" and you will find reddit posts and hacker news comments of people sharing a similar horrible experience. Always research a tool and alternatives before using them. You can save so much time and pain by learning from other\\'s experience.', 'Every time I tried to use langchain, I noticed how much they are limiting me from doing anything flexibly so I can do something practical with the underlying library in a way I can more deeply understand the behavior of the llm. Now I only use it as an interface to some simple fuction', \"I am tasked at my company to create a LLM based RAG chatbot for querying internal documents, it has to be implementable in Teams so any internal staff can use it. I was going to use Langchain as it looked exactly to be what I needed, however after browsing this subreddit for a while I am not sure about it anymore haha... What in your opinion is an alternative that I should be using? We want to be based off OpenAI's API and in either Python or C#.\", \"We had the same observation u/Glass-Web6499, so I built a much simpler AI application development framework called AIConfig: [https://github.com/lastmile-ai/aiconfig](https://github.com/lastmile-ai/aiconfig) \\\\-- would love your feedback on it.\\n\\nIt manages generative AI prompts, models and model parameters as JSON-serializable configs that can be version controlled, evaluated, monitored and opened in a notebook playground for rapid prototyping.\\n\\nIt allows you to store and iterate on generative AI behavior *separately from your application code,* and doesn't add any unnecessary abstractions.\\n\\nHere's a getting started tutorial: [https://github.com/lastmile-ai/aiconfig/tree/main/cookbooks/Getting-Started](https://github.com/lastmile-ai/aiconfig/tree/main/cookbooks/Getting-Started) and video [https://www.youtube.com/watch?v=X\\\\_Z-M2ZcpjA](https://www.youtube.com/watch?v=X_Z-M2ZcpjA)\\n\\n&#x200B;\\n\\n&#x200B;\\n\\nhttps://preview.redd.it/ncnh8zc1wp5c1.png?width=1760&format=png&auto=webp&s=006acc412bc9c35fcaa65c9f9395cac22109cb7f\", 'I started using langchain to do vector database searching. But somehow I couldn’t find a way to return search scores and adjust the numbers of search results without exceeding Llm context limit. Instead I just spent 1 hour writing my own vector search that gives me all the flexibility I need.', 'Our langchain implementation had a latency of 60 seconds vs direct open ai call custom implementation latency of <10 seconds. Langchain= 💩', 'Check out RAGStack.', 'Langchain has the most spaghetti open source code base I’ve ever seen', 'Great, I just got started with Langchain.\\n\\n&#x200B;\\n\\nWhat are other alternatives?  What would you do to build what you needed for your work if you did from scratch?  Thanks', 'tutorials dont work, on the other hand they segregated version 2, its pathetic now. \\n\\nI agree with you. I ended up implementing openai apis directly.', \"I just watched langchain videos for 3 hours straight and I can certainly say that I wouldn't have funded if I were in the shoes of Benchmark. Definitely not worth the hype\", 'welcome to opensource!', 'took me a day to switch to LCEL and for what????', 'I’m starting to feel that way as well. I was recommended by AWS architects to use Langchain and took some courses where Harrison was the speaker. Everything looked understandable until you try to use Langchain with other models like Claude. Most of my time is now spent debugging what broke when using other LLMs. \\n\\nThe documentation is lacking and instead of making it better, they’ve been adding LCEL alternatives to the same poor docs. I also work on it in TS/JS and the feature-set and documentation is noticeably worse than Py\\n\\nI don’t necessarily think Langchain is bad, but it was definitely oversold on what it can do.', 'You did a really good job of elucidating the thoughts I had when looking at it and thinking \"oh wow, this looks like what would happen if I tried to write this\".', 'Or just stick with vanilla Python given how simple the OpenAI sdk is anyway', 'My vote goes to Haystack. It was a LLM framework [3 years](https://en.wikipedia.org/wiki/Deepset) before the LLM hype train and is a well designed framework.', 'and prayers 🤣', 'similar crap as next-auth', 'Same haha \\nOpenAI + string formatting and you can already do 90% of what langchain does, without the black box aspect', \"You're not alone...\", \"Please for the love of got if you have a solution for streaming and function calling post it so I can do the same. It's the only thing keeping me on langchain\", 'This is what I have been doing for a while.', 'you never use their built in assistant?', \"Thanks for reaching out and I hope you don't take my post as hate.\\n\\nOne major thing is why prompts are hidden and so hard to work with, when they are the CORE piece of an LLM. Why do you sometimes pass a static prompt with the chat history in context (like you would to GPT-instruct) but to a chat model that expects system/user/assistant objects.\\n\\nI'm quite overwhelmed to list more examples, but a starting point would be adressing the inconsistencies when calling chains.\\n\\n.call(), .invoke(), .run(), and why they seem to accept inputs in an interesting way.\\n\\nAnother thing is to clarify why .invoke() doesn't seem trigger the same callbacks as .call()\\n\\nAnother thing is why there are two starting callbacks handleGenerationStart & handleChatModelStart, but only one ending callback handleGenerationEnd for both of them.\\n\\nIt's a lot of trivial things that as a dev, you spend so much time just guessting your way around.\\n\\n[https://python.langchain.com/docs/modules/chains/how\\\\_to/call\\\\_methods](https://python.langchain.com/docs/modules/chains/how_to/call_methods) is simply not enough for such core functionality.\", 'How about writing langchain v2 with Langchain ? 😅', 'The search feature where you have used some AI search is not at all effective.\\n\\nIt always fails to give correct results. I have completely stopped using it to find anything.', 'Lmao you see it all the time. \"I tried using GPT-4 and it was absolutely worthless. All the libraries are garbage. I knew all this AI stuff was hype, I\\'ll check back in 5 years once it\\'s had time to mature\"\\n\\nFor being in a field that hinges on constantly staying on top of emerging tech, a lot of these senior devs are burying their heads in the sand.', \"I'd agree with this sentiment. I've advocated for custom encapsulations of any langchain class that might be too insufficient or incompatible for whatever purposes the dev requires. \\n\\nThe context of langchain and its growth is important. This is not React or Pandas, both of which grew quietly and addressed no problems until the problems were identified as such. \\n\\nIf people face issues with langchain and they're too lazy to do a little tooling or reading of a code base, then go elsewhere or help solve the problem. The fact that the creator is open and helpful puts this library above the majority of libraries that only pay lip service to openness.\", \"I didn't know there was a revolution? What makes you assume that? \\n\\nYou my friend are part of the problem. You think Langchain is leading some sort of revolution, because you don't understand how it works internally. \\n\\nThere is nothing revolutionariy about LangChain unfortuntaely, it's mostly hype.\\n\\nI'm not in amazement because I'm an **actual contributer** to the GenAI/LLM ecosystem.\", 'yeah, and why not contribute and make it better with all of the ideas and suggestions... at least it might be useful someday, right...', 'Solid project', 'They also want to build as many demo examples and youtube videos they forget to update the documentations. (There is no documentation for OpenAILike llm class) Also, I was using the library and it was breaking because they changed some default parameter od one of the dependent class. I looked at github and the commit was 8 hours ago. Why commit things halfway refactored?', 'Can I ask what alternatives do you use in prod?', \"So what's the alternative you have found, is there any alternative or better to write ur own implementation?\", '>nd 80% of my dev time was spent tricking one part to work with another.  For a funded codebase, it’s pretty disappointing. I think they underestimated the complexity and underinvested in the development.  I get that the world of LLMs is a swirling minefield, but I was so relieved when the effort stopped at the PoC stage.  I wouldn’t feel right handing this over to be maintained or trying to do it myself if it went to prod.\\n\\nDid you make any progress on this? What did you end up using?', 'If your task is simple, sure. But anything more you are reinventing the wheel which is a waste fo time.', 'Honestly this is the best way to go.', \"That was always my thought. Why do I need all this crap with Langchain? Can't I do the same thing with just python? And then I wouldn't be so limited on models. I'm an intermediate python coder, so I may be missing something here.\", 'Where can I find documentation or a guide for all this black magic?!?', 'Streaming: https://platform.openai.com/docs/api-reference/streaming\\n\\nFunction calling: https://platform.openai.com/docs/guides/function-calling/function-calling\\n\\nThe OpenAI Python library docs are extremely well written and you can search for whatever you want.', \"You are not supposed to call anything on streamed chunks except showing it to user or something. Most of langchain does nothing on streamed chunks, instead langchain waits till whole message is completed, before processing it. Streaming is purely for ui experience and it's kind of hack where u inject ur code to be run on intermediate chunks. So wait for whole streaming to complete before doing things it's also how chatgpt works if a response fails mid way u never see it saved or anything because they don't care till message has completely finished streaming\", \"what's your use case for function calling? I might have something for you\", 'https://gist.github.com/hardcorebadger/ab1d6703b13f2829fddbba2eeb1d4c8a\\n\\nOpenAI Chat Function recursive calling (basically chatGPT plugins / lang chain agent replacement) 2x as fast and 2x less model calls + works with gpt4-turbo - less than 100 lines of code with no lang chain dependency', 'In my experience that just takes longer to still not find what I need', 'The assistant is prone to hallucinations, and even if it wasn’t, any assistant is only going to be as good as the underlying docs, which are often outdated or just straight up wrong.', 'Thanks for the details, and really appreciate it. the inconsistencies when calling chains is really great piece of feedback that we can address. Our thought with LCEL is that it would help address some of the points around the prompts being hidden (since now they are explicitly part of the chain) - do you not feel that helps?', 'We’re actually in the process of splitting up the codebase. Factoring out LangChain core (the base abstractions) and langchain-community (all the jntegrstions). So something like what you suggested is actually possible. Which is why I’m really curious and eager for more details! Are this complaints with core? Community? The agents part of LangChain? The normal chains? As OP langchain covers a lot so specificity is actually incredibly helpful', \"You probably think I'm a boomer who can't handle change, why instead of taking my critiscm at face value you create some weird caricature of me?\\n\\nI remember when LangChain was created, probably knew about it before you. It was during the ReAct paper era. The whole foundation is built with that in mind, and the spaghetti is an effect of modelling everything to fit that paradigm.\\n\\nFor what it's worth, I'm actually very on top of the emerging tech. Everything from reading papers to actually implementing in practice.\", \"You must be trolling now? I don't think they're leading a revolution, they're a part of it. I respect the project because they put in an insane amount of work to produce something that we can all leverage *for free if we want.*\\n\\nIs it enterprise ready? Is it perfect? Is it anywhere near ideal? No way.  Have they done an amazing job keeping up with the LLM insanity *every single day* the past 2 years? Hell yes.\\n\\nAs someone who has written 2 different frameworks to do a fraction of what they're doing, and followed the rise of LLMs every day for years, they have massive respect from me. Anyone working in this space for more than 6 months would not be hopping over to ol' r/langchain to proclaim how bad it is like it's a revelation.\\n\\nWe all look forward to you posting your contributions-- I hope your project gets rave reviews and thousands of people use it. I still hope that even the best dev cowboys on Reddit would be respectful of the hard work of other developers.\", \"I am not sure if it's me you are asking as you quoted another comment, but in case it is me... we haven't done any work yet but decided that we would do it in the Azure OpenAI platform instead, based on security, simplicity and the fact that we are microsoft everything already. It is also likely that we will eventually adapt Copilot 365. It is my Q1 project so ask me again in 3 months if you are still curious by then lol.\", 'Dude just read the docs', 'Yea im quite familiar with the oai docs. Am I missing the instructions for having both running together at the same time?', 'What about for other LLMs where you want to write agents that perform actions and call functions?', \"I use it to allow the model preform RAG only when the users request calls for it. Basically giving the model the ability to lookup or read entire documents at its discretion. The reason streaming is so important is that users HATE waiting for the full output before getting the answer. Most of the answers generated by my agents are quite detailed. It's all build it python and uses gradio as the front end. I absolutely hate the custom callback I have to use with langchain to get streaming with gradio to work.\", 'This is similar to the oai cookbooks. No streaming solution presented.', 'Agreed docs are lacking big time!', 'LCEL does appear to create a much more consistent abstraction, and I really like how it puts control of the prompts back into the hands of the developer. More documentation would be helpful though. There are some good examples, but they\\'re all a bit surface level. I want to know how far I can push it without getting into \"this is outside the intent of our design\" territory.', 'Honestly, improving the documentation would be a huge benefit. I’d move the LangChain expression language examples to their own section. It makes it really confusing where there’s 3 subpar examples, and the 3rd ones in LCEL.', \"Reduce layers.  Make usage consistent.   Splitting the code will be helpful but it doesn't truly solve the core issues.\", \"The hidden prompts were by far the most confusing thing about LangChain for me. When I first learnt how to use it, I had no idea these prompts existed and what they were doing. Tbh, I think most of the issues I had could have been resolved with better documentation with examples and explanations of what is going on under the hood. Working with LLMs is a very new tech, and I think it needs to be made crystal clear what is happening. A retrieval QA chain for example has A LOT going on behind the scenes and that isn't at all clear from the docs. I even did a couple of courses where it was pretty clear the instructors didn't even understand it!  \\n\\n\\nA lot of times I had to look at the sourcecode, or use a lot of debugging breakpoints to figure out what was going on. For example, the other day, I used the new OpenAI assistant feature and it was not clear from the docs how to get the response and the thread ID from the object returned by invoke. And the documentation didn't really explain why I would want to build an agent using an assistant. \\n\\nI am not very experienced with Python, but I can normally figure out things from documentation, with LangChain there are not enough examples and explanations.   \\n\\n\\nI still think its is a great library. Of course, there are going to be a million issues working with a tech that is so new and constantly evolving. But I don't want to have to rewrite my code if I use a different LLM so I'm definitely going to keep on using it.\", 'The langchain agent currently fetches results from tools and runs another round of LLM on the tool’s results which changes the format (json for instance) and sometimes worsen the results before sending it as “final answer”. Langchain definitely needs an option that allows the agent to return the results from tools as is, especially tools that return structured data that should not be modified into sentences', \"You shouldn't take my comment personally, it was a generalization not aimed at you in particular. Criticism of LangChain is fine and good on you for providing Harrison with clear feedback of where to improve.\", 'Hey, 85d past, any good news from your side? Could you please share with us? My company is also MS everything.', \"Yes thanks, don't know how the quote ended up with wrong text, I may just follow up haha, get it delivered in Q1!... I expect every company in the world will be throwing someone at similar projects in the near future or trying to use some service that makes it easy, good experience to have. I'm sure there's lots of startups working on this but I'd love to get all internal slack/confluence/apidocs/code queryable, but baby steps.\", 'Plus openai python library docs has a fully working search functionality! Unlike the horrible search in the langchain docs', 'You can iterate through the streamed chunks to find a tool call and args, they’re just spread out through multiple chunks usually', \"I heard from my GCP TAM that Google is working on their function calling equivalent and it'll be available soon. Since everybody else seems to be following openai, by the time you build your app using Langchain'e clunky implementations, there'll be native solutions for those that deliver superior performance and you'd have to rewrite. I went through the same epiphany myself and it's not fun\", 'Yeah, my b.   \\nYou have to set streaming=true in the requests to openAI then rem the response as a stream ie.  \\n\\n\\nrequest =   \\n response = openai.ChatCompletion.create({  \\n...  \\n \"stream\": True,  \\n}\\n\\n)  \\n collected\\\\_chunks = \\\\[\\\\]  \\n collected\\\\_messages = \\\\[\\\\]  \\n for chunk in response:  \\n   collected\\\\_chunks.append(chunk)  \\n   delta = chunk\\\\[\\'choices\\'\\\\]\\\\[0\\\\]\\\\[\\'delta\\'\\\\]  \\n   collected\\\\_messages.append(delta)', 'Any particular parts of the docs? Use cases? Getting started? The agent docs?', 'Any particular parts of the docs? Use cases? Getting started? The agent docs?', 'Layers where? I’m guessing on inheritance- which classes? And usage of what parts? The small core things or the higher level chains? Agree that splitting doesn’t solve, but hopefully helps solidify foundations', \"I was thinking of using other LLMs like llama, etc. where I will self-host. if I want to be able to switch between models for different tasks (agents) how would you recommend I proceed? I'm currently testing with langchain and it seems to work pretty decently. I'm concerned down the line though as things are moving quickly.\", 'Hi, I’m trying to build a web based voice assistant but struggle connecting web to service like vapi or vocode using the sdk as I’m not a developer. The low code tool like bland are good too but same problem integrating with web - that part is not for beginner coders', 'hello where are you based', 'I’m based in Cairo. Shoot me a DM if you need anything!', 'Are you looking for a co-founder? I may not be tech savvy with code but I am pretty handy when it comes to Lead Gen and Market research', '[H](https://www.upyogai.com/post/10-step-guide-are-you-considering-starting-an-ai-automation-agency)i - see this: [https://www.upyogai.com/post/10-step-guide-are-you-considering-starting-an-ai-automation-agency](https://www.upyogai.com/post/10-step-guide-are-you-considering-starting-an-ai-automation-agency)', 'Hey, yesterday I published a blog about it. You can check my newsletter here: [https://ai-automation-life-daily.beehiiv.com/p/rise-ai-automation-agencies-enormous-opportunity?\\\\_gl=1\\\\*19fuyll\\\\*\\\\_ga\\\\*NjQ4MjkyMjIuMTY4ODI4MzI4MQ](https://ai-automation-life-daily.beehiiv.com/p/rise-ai-automation-agencies-enormous-opportunity?_gl=1*19fuyll*_ga*NjQ4MjkyMjIuMTY4ODI4MzI4MQ)', 'Here’s a a free course I highly recommend you can take https://youtube.com/playlist?list=PLpbuxgEHPokP44J-OD4ZnKydAedAFvfKZ', \"Hey buddy, it's was bad time for me , actually I was Disconnected from My laptop which I used to work with and now I'm busy with all these useless sem Exams . which I have to study to Satisfy My parents. I can Be In Touch With you after a Month. What Do you say?.\", 'Sounds good, shoot me a DM', 'A bunch of dudes can do it better', 'Ok now make it use mortar too', 'Where is the cement?', 'Why not 3D print?  This seems like a step backwards.', 'Thank you for your post to /r/automation!\\n     \\nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\\n\\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\\n\\nLastly, enjoy your stay!\\n\\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Hadrian did nothing wrong.', 'You say that like it would be impossible for the robot. lol', 'Read it, it says they use an adhesive and show it being applied.', 'It uses adhesive.', 'Not really - 3D print is great for prototyping but for anything else it quite sucks because out of the Principe material quality is lower than for stuff that is formed at one peace and it is much slower. That is why the amount of successful 3D printed stuff on the mass market you can buy is around 0.\\n\\nTo be clear this is also a toy prototype, but at least one with potential.', 'Not impossible, but theres some major engineering challenges to overcome. Iike how would quality control work on the mortar laying? The mk.I eyeball is a fine tool for that, but I imagine it could be a challenge with CV', 'Open chrome, load pornhub.com', \"thanks for showing interest everyone! This is still work in progress, merely an MVP right now.\\n\\nIf you have any use cases that would fit in your workflow please let me know and I'll try to test it on my extension and have you be my first beta user!\", \"Oh wow I've dreamed of stuff like this! Is it available to the public anywhere? I could very much use this type of thing, I've been using auto hot key and others, but this looks way more smart and powerful!\", \"Ya it'd be great to see something more substantial than a video.\", 'Thank you for your post to /r/automation!\\n     \\nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\\n\\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\\n\\nLastly, enjoy your stay!\\n\\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'We are in the process of setting up some automated tasks and think you would benefit from some of our real  use case scenarios. If interested PM me and I will give you some more info.', \"not yet! I just started working on it last month, I will keep grinding and let you know when it's in a share-able state!\", 'just PMd you!', \"Awesome! I'd even be interested in beta testing if that would be helpful. I look forward to seeing what you make!\", 'Thanks for volunteering! Just sent you a message', \"5G energy harvesting? I'm gonna guess this is powered by batteries.\", \"Yea, AI and automation isn't going to cost anybody a job... Keep voting for people who don't give a shit about the working class at your own peril folks. \\n\\nHere's the future we are on track for: No jobs unless you can repair a robot or program one, all as the planet tries to remove us from it by cooking us or drowning us.\\n\\nDon't be confused about any of this. They aren't going to train you or any other such thing. If you build a thing, sell a thing, make a thing, move a thing, etc, you are screwed! You will be excluded from the economy and the power and social mobility that entails.\", 'Thank you for your post to /r/automation!\\n     \\nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\\n\\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\\n\\nLastly, enjoy your stay!\\n\\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'God damn son I love the present', 'The early Iron Man comics said he was powered by transistors....', 'The early Iron Man comics said he was powered by transistors....', \"i'm happy to make love to the robots\", 'Stop being so dramatic', \"He's got a point, though.\"]\n",
      "Total comments scraped: 339\n",
      "\u001b[34m\n",
      "---Filtering Comments---\u001b[0m\n",
      "\u001b[32m\n",
      "---MARKET STRATEGIST---\u001b[0m\n",
      "## Name\n",
      "\n",
      "AI Empowerment Solutions\n",
      "\n",
      "## Colors\n",
      "\n",
      "#007BFF (a vibrant blue that creates a strong contrast for call-to-action buttons)\n",
      "\n",
      "## Font\n",
      "\n",
      "Heading: Montserrat (for a modern and distinctive identity)\n",
      "Paragraph: Roboto (for a clean and classic look)\n",
      "\n",
      "## Product\n",
      "\n",
      "AI Empowerment Solutions is an innovative service offered by INFINITLY that provides businesses with tailored AI automation solutions. Our offerings include the development of AI-powered applications, advanced RAG (Retrieval-Augmented Generation) chatbots, and custom AI Telegram bots. These solutions are designed to streamline operations, enhance customer interactions, and drive business growth, enabling companies to leverage cutting-edge AI technology for a competitive edge.\n",
      "\n",
      "### Features:\n",
      "\n",
      "1. Custom AI-Powered Applications: Tailored solutions that meet specific business needs and enhance operational efficiency.\n",
      "2. Robust RAG Chatbots: Intelligent chatbots that can query internal documents and provide accurate responses, integrated seamlessly into platforms like Teams.\n",
      "3. Custom AI Telegram Bots: Personalized bots that facilitate communication and engagement with customers on popular messaging platforms.\n",
      "\n",
      "### Benefits\n",
      "\n",
      "1. Streamlined Operations: Automate repetitive tasks and improve workflow efficiency, allowing teams to focus on strategic initiatives.\n",
      "2. Enhanced Customer Interactions: Provide instant, accurate responses to customer inquiries, improving satisfaction and loyalty.\n",
      "3. Competitive Advantage: Leverage advanced AI technology to stay ahead of competitors and foster innovation within the business.\n",
      "\n",
      "## Potential target audience\n",
      "\n",
      "- Small to medium-sized business owners that are struggling with inefficient customer service processes and want to enhance customer engagement through automation.\n",
      "- Internal IT teams at larger corporations that are struggling with implementing effective AI solutions for internal document querying and want to improve knowledge management.\n",
      "- Marketing professionals in tech companies that are struggling with generating personalized customer interactions and want to leverage AI for targeted communication strategies.\n",
      "\u001b[32m\n",
      "---BRAND CRAFTER---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32mBranding:\u001b[0m\n",
      "\u001b[36m\n",
      "Message: ## Company Briefing:\n",
      "**Mission**: INFINITLY is dedicated to empowering business owners by providing cutting-edge AI automation solutions that streamline operations, enhance customer interactions, and drive sustainable growth.\n",
      "\n",
      "**Vision**: To be the leading AI automation services agency, recognized for transforming businesses through innovative AI technologies that foster efficiency and competitiveness.\n",
      "\n",
      "**Values**: Innovation, Integrity, Customer-Centricity, Collaboration, and Excellence.\n",
      "\n",
      "**Overview**: INFINITLY offers a suite of AI solutions, including AI-powered applications, robust RAG chatbots, and custom AI Telegram bots. Our unique position in the market lies in our ability to tailor AI solutions specifically to the needs of businesses, ensuring they can leverage advanced technology without the complexity often associated with AI implementation.\n",
      "\n",
      "**Key Problem Solved**: Many businesses struggle to integrate AI into their operations due to a lack of expertise, resources, and tailored solutions. INFINITLY addresses this challenge by providing accessible, customized AI automation services that simplify the adoption of AI technologies, enabling businesses to remain competitive and innovative in a rapidly evolving market.\n",
      "\n",
      "## Company Branding:\n",
      "- **Brand Personality**: INFINITLY embodies a forward-thinking, approachable, and innovative personality. We are seen as a trusted partner in AI automation, combining technical expertise with a deep understanding of our clients' needs.\n",
      "  \n",
      "- **Tone**: The tone is professional yet relatable, emphasizing clarity and support. We communicate with confidence and enthusiasm, making complex AI concepts accessible to all business owners.\n",
      "\n",
      "- **Suggested Elements**:\n",
      "  - **Colors**: A palette of deep blue (representing trust and intelligence), vibrant green (symbolizing growth and innovation), and soft gray (for professionalism and balance).\n",
      "  - **Fonts**: A modern sans-serif font for headings (e.g., Montserrat) to convey clarity and innovation, paired with a clean serif font for body text (e.g., Merriweather) to enhance readability.\n",
      "  - **Imagery**: Use visuals that depict collaboration, technology in action, and diverse teams working together. Incorporate graphics that illustrate AI concepts in a simplified manner.\n",
      "\n",
      "## Brand Story:\n",
      "INFINITLY was born out of a passion for harnessing the power of artificial intelligence to transform the way businesses operate. Our founders recognized that while AI holds immense potential, many business owners felt overwhelmed by its complexity and the rapid pace of technological change. \n",
      "\n",
      "Driven by a mission to demystify AI, we set out to create a company that not only provides cutting-edge AI solutions but also empowers businesses to embrace innovation confidently. Our journey began with a small team of AI enthusiasts who believed that every business, regardless of size, should have access to the tools that can drive efficiency and growth.\n",
      "\n",
      "As we grew, we focused on understanding the unique challenges faced by our clients, allowing us to develop tailored solutions that truly meet their needs. Today, INFINITLY stands as a beacon of support for businesses looking to navigate the complexities of AI, helping them unlock their full potential through automation and intelligent solutions.\n",
      "\n",
      "## Company/Brand Messages:\n",
      "- **Message 1**: \"Empower Your Business with AI: Simplifying Innovation for Growth.\"\n",
      "- **Message 2**: \"Tailored AI Solutions: Because Your Business Deserves More Than One-Size-Fits-All.\"\n",
      "- **Message 3**: \"Transform Complexity into Clarity: Streamline Operations with INFINITLY's Expertise.\" \n",
      "\n",
      "These messages resonate with our target audience by addressing their needs for customized solutions and emphasizing our commitment to making AI accessible and beneficial for their businesses.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "\n",
    "\n",
    "output = app.invoke(inputs)#, config={\"configurable\": {\"thread_id\": 42}})\n",
    "\n",
    "#output[\"messages\"][-1].content\n",
    "\n",
    "genrated_branding= output['branding']\n",
    "\n",
    "print(colored(f\"Branding:\", 'green'))\n",
    "print(colored(f\"\\nMessage: {genrated_branding}\", 'cyan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e49c0d13",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'branding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbranding\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'branding' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d21f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mLanding Page:\u001b[0m\n",
      "\u001b[36m\n",
      "Message: ```\n",
      "Title: Landing page for DocuAI Chatbot\n",
      "- Above the fold\n",
      "\t- Headline\n",
      "\t\t- \"Struggling to understand your legal and financial documents?\"\n",
      "\t\t- \"Do you wish document management was easier?\"\n",
      "\t\t- \"Imagine making informed decisions without document stress.\"\n",
      "\t- Subheadline\n",
      "\t\t- \"DocuAI Chatbot helps small business owners like you quickly find answers in your documents.\"\n",
      "\t\t- \"Get clear, accurate responses about your documents effortlessly.\"\n",
      "\t- Bullet points\n",
      "\t\t- \"Quickly locate essential information without sifting through pages.\"\n",
      "\t\t- \"Understand complex documents with easy-to-follow explanations.\"\n",
      "\t\t- \"Save time and focus on what really matters for your business.\"\n",
      "\t\t- \"Seamlessly integrates with your existing document formats.\"\n",
      "\t\t- \"User-friendly interface designed for effortless interaction.\"\n",
      "\t\t- \"Gain confidence in your document management process.\"\n",
      "\t- Call to action\n",
      "\t\t- \"Get started now!\"\n",
      "\t\t- \"Find out how it works!\"\n",
      "\t\t- \"See if DocuAI is right for you!\"\n",
      "- Message from the founder\n",
      "\t- \"I created DocuAI Chatbot to help small business owners navigate the complexities of document management with ease.\"\n",
      "- The current situation\n",
      "\t- Title grabbing attention\n",
      "\t\t- \"Does this sound familiar?\"\n",
      "\t\t- \"Are you overwhelmed by your documents?\"\n",
      "\t- Title-paragraph blocks\n",
      "\t\t- \"You spend hours trying to find important information in lengthy contracts, feeling frustrated and lost.\"\n",
      "\t\t- \"Every time you receive a new document, anxiety creeps in as you wonder if you’ll miss something crucial.\"\n",
      "\t\t- \"You wish you could just ask a question and get a clear answer, but instead, you’re stuck with confusion.\"\n",
      "\t\t- \"Managing multiple document formats feels like a never-ending battle, leaving you exhausted and unsure.\"\n",
      "- Believes deconstruction block\n",
      "\t- Believes deconstruction - headline\n",
      "\t\t- \"You are not alone in this struggle.\"\n",
      "\t- Believes deconstruction - paragraph\n",
      "\t\t- \"Many small business owners feel overwhelmed by their documents. Traditional methods of document review can be time-consuming and often lead to missed details. Studies show that using AI can significantly improve efficiency and accuracy in document management.\"\n",
      "- Message from the founder\n",
      "\t- \"I understand the challenges you face, and I believe DocuAI can make a real difference.\"\n",
      "- Desired outcome\n",
      "\t- Title grabbing attention\n",
      "\t\t- \"And now, imagine a different reality...\"\n",
      "\t\t- \"Picture your life with stress-free document management.\"\n",
      "\t- Title-paragraph blocks\n",
      "\t\t- \"You confidently navigate your documents, quickly finding the answers you need without frustration.\"\n",
      "\t\t- \"Every new document feels manageable, and you know you won’t miss important details.\"\n",
      "\t\t- \"You spend less time on paperwork and more time growing your business.\"\n",
      "\t\t- \"Your decision-making is sharper, and you feel empowered to tackle any document challenge.\"\n",
      "- New paradigm block\n",
      "\t- New paradigm - headline\n",
      "\t\t- \"Introducing DocuAI Chatbot: A new way to manage your documents.\"\n",
      "\t- New paradigm - paragraph\n",
      "\t\t- \"This is not just another tool; it’s a smart assistant designed to understand your questions and provide clear answers. With advanced AI technology, DocuAI Chatbot transforms how you interact with your documents, making the process faster and more intuitive.\"\n",
      "- Solution\n",
      "\t- Solution 3-Steps blocks\n",
      "\t\t\t- \"Step 1: Ask your question in plain language and get instant answers.\"\n",
      "\t\t\t- \"Step 2: Access information from various document formats seamlessly.\"\n",
      "\t\t\t- \"Step 3: Enjoy peace of mind knowing you have clarity on your documents.\"\n",
      "- Message from the founder\n",
      "\t- \"I believe that with the right tools, you can take control of your document management.\"\n",
      "- Connection block\n",
      "\t\t- \"I created DocuAI Chatbot because I saw how many small business owners struggle with document management.\"\n",
      "\t\t- \"After years of working with entrepreneurs, I realized that a simple, effective solution was needed to help them navigate their documents with confidence.\"\n",
      "- Last call to action\n",
      "\t\t- \"Now is the time to simplify your document management.\"\n",
      "\t\t- \"Don’t let confusion hold you back any longer.\"\n",
      "\t\t- \"Start your journey with DocuAI today!\"\n",
      "```\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(colored(f\"Landing Page:\", 'green'))\n",
    "print(colored(f\"\\nMessage: {landing_page}\", 'cyan'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
